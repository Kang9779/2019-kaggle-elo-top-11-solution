{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functionUtils import *\n",
    "from sklearn.model_selection import KFold,StratifiedKFold,GroupKFold,RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from feature_selector import FeatureSelector\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from scipy.stats import ks_2samp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import datetime\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "fea_path = './datasets/'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  I 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(fea_path+'df_data.csv',dtype={'first_active_month':np.str})\n",
    "df_train_test_additional_features = pd.read_csv(fea_path+'df_train_test_features_additional.csv')\n",
    "df_additional_features = pd.read_csv(fea_path+'df_additional_features.csv')\n",
    "\n",
    "df_data = df_data.merge(df_train_test_additional_features,on='card_id',how='left')\n",
    "df_data = df_data.merge(df_additional_features,on='card_id',how='left')\n",
    "\n",
    "del df_additional_features,df_train_test_additional_features\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './datasets/feature2/'\n",
    "sublist = os.listdir(path)\n",
    "\n",
    "for sub in sublist:\n",
    "    df = pd.read_csv(path+sub)\n",
    "    df_data = df_data.merge(df,on='card_id',how='left')\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tsne_fea = pd.read_csv('./datasets/df_tsne_fea.csv')\n",
    "df_data = df_data.merge(df_tsne_fea,on='card_id',how='left')\n",
    "df_cate_statics = pd.read_csv('./datasets/df_cate_statics.csv')\n",
    "df_data = df_data.merge(df_cate_statics,on='card_id',how='left')\n",
    "\n",
    "del df_cate_statics\n",
    "gc.collect()\n",
    "\n",
    "del df_tsne_fea\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cate_merchantCate_fm = pd.read_csv('./datasets/cate_fm/df_hist_new_cate_merchantCate_fm_feat.csv')\n",
    "df_cate_merchant_fm = pd.read_csv('./datasets/cate_fm/df_hist_new_cate_merchant_fm_feat.csv')\n",
    "\n",
    "df_data = df_data.merge(df_cate_merchantCate_fm,on='card_id',how='left')\n",
    "df_data = df_data.merge(df_cate_merchant_fm,on='card_id',how='left')\n",
    "\n",
    "del df_cate_merchantCate_fm,df_cate_merchant_fm\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_card_merchant_statics = pd.read_csv(fea_path+'df_card_merchant_statics.csv')\n",
    "df_card_merchant_vec = pd.read_csv(fea_path+'df_card_merchant_vec.csv')\n",
    "df_card_city_statics = pd.read_csv(fea_path+'df_card_city_statics.csv')\n",
    "\n",
    "df_data = df_data.merge(df_card_merchant_vec,on='card_id',how='left')\n",
    "df_data = df_data.merge(df_card_merchant_statics,on='card_id',how='left')\n",
    "df_data = df_data.merge(df_card_city_statics,on='card_id',how='left')\n",
    "\n",
    "del df_card_merchant_statics,df_card_merchant_vec,df_card_city_statics\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_nmf_card_merCate_features = pd.read_csv(fea_path+'df_nmf_card_merCate_features.csv')\n",
    "df_nmf_card_city_features = pd.read_csv(fea_path+'df_nmf_card_city_features.csv')\n",
    "df_card_merchant_features = pd.read_csv(fea_path+'df_card_merchant_features.csv')\n",
    "df_cardid_vec = pd.read_csv(fea_path+'df_cardid_vec.csv')\n",
    "# # df_card_merchant_vec1 = pd.read_csv('./datasets/df_card_merchant_vec1.csv')\n",
    "# # df_f1_f2_f3_vec = pd.read_csv('./datasets/df_f1_f2_f3_vec.csv')\n",
    "\n",
    "df_data = df_data.merge(df_nmf_card_merCate_features,on='card_id',how='left')\n",
    "df_data = df_data.merge(df_nmf_card_city_features,on='card_id',how='left')\n",
    "df_data = df_data.merge(df_card_merchant_features,on='card_id',how='left')\n",
    "df_data = df_data.merge(df_cardid_vec,on='card_id',how='left')\n",
    "\n",
    "del df_nmf_card_merCate_features,df_nmf_card_city_features,df_card_merchant_features,df_cardid_vec\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_data[df_data.is_test==0]\n",
    "df_test = df_data[df_data.is_test==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape,df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['target']\n",
    "df_train['is_outlier'] = (df_train.target<-30).astype(np.int)\n",
    "dropCols = ['card_id','first_active_month','is_outlier','is_test','target','purchase_date','merchant_id']\n",
    "tr_features = [_f for _f in df_train.columns if _f not in dropCols and df_train[_f].dtype!='object']\n",
    "print(len(tr_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fs = FeatureSelector(data = df_train[tr_features], labels = df_train['target'].values)\n",
    "\n",
    "fs.identify_missing(missing_threshold = 0.12)\n",
    "fs.identify_collinear(correlation_threshold = 0.98)\n",
    "fs.identify_zero_importance(task = 'regression', eval_metric = 'rmse', n_iterations = 10, early_stopping = True)\n",
    "fs.identify_low_importance(cumulative_importance = 0.99)\n",
    "fs.identify_single_unique()\n",
    "\n",
    "tr_removed = fs.remove(methods = 'all')\n",
    "\n",
    "tr_features = list(tr_removed.columns)\n",
    "\n",
    "len(tr_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def modelKFoldReg(df_train,df_test,model):\n",
    "    \n",
    "    NFOLDS = 5\n",
    "    kfold = StratifiedKFold(n_splits=NFOLDS,shuffle=False,random_state=2018)\n",
    "    ntrain = df_train.shape[0]\n",
    "    ntest = df_test.shape[0]\n",
    "    oof_train_pred = np.zeros((ntrain,))\n",
    "    oof_test_pred = np.zeros((ntest,))\n",
    "    oof_test_pred_skf = np.empty((NFOLDS, ntest))\n",
    "#     for foldIndex,(dev_index,val_index) in enumerate(kfold.split(df_train)):\n",
    "    for foldIndex,(dev_index,val_index) in enumerate(kfold.split(df_train,df_train['is_outlier'])):\n",
    "        print(\"............第%s折...........\"%(foldIndex+1))\n",
    "        x_dev = df_train[tr_features].iloc[dev_index]\n",
    "        y_dev = df_train[label].iloc[dev_index]\n",
    "        x_val = df_train[tr_features].iloc[val_index]\n",
    "        y_val = df_train[label].iloc[val_index]\n",
    "        model.fit(x_dev, y_dev,eval_set=[(x_dev,y_dev),(x_val,y_val)],\n",
    "#                   sample_weight=list(w_train[dev_index]),eval_sample_weight=list(w_train[val_index]),\n",
    "                  early_stopping_rounds=100,verbose=100)\n",
    "        oof_test_pred_skf[foldIndex,:] = model.predict(df_test[tr_features],num_iteration=model.best_iteration_)\n",
    "        oof_train_pred[val_index] = model.predict(x_val,num_iteration=model.best_iteration_)\n",
    "    oof_test_pred[:] = oof_test_pred_skf.mean(axis=0)\n",
    "        \n",
    "    score = np.sqrt((np.sum(np.square(oof_train_pred - df_train[label].values.reshape(-1,)))/ntrain))\n",
    "    return model,score,oof_test_pred,oof_train_pred\n",
    "\n",
    "# lgb_params={\n",
    "#     'learning_rate': 0.01,\n",
    "#     'objective':'regression',\n",
    "#     'n_estimators':2000,\n",
    "#     'metric':'rmse',\n",
    "#     'num_leaves': 50,\n",
    "#     \"feature_fraction\": 0.91,\n",
    "#     \"bagging_freq\": 1,\n",
    "#     \"bagging_fraction\": 0.92 ,\n",
    "#     \"bagging_seed\": 11,\n",
    "#     'verbose': 1,\n",
    "#     \"subsample\": 0.8,\n",
    "#     'lambda_l1':0.5,\n",
    "# #     'categorical_feature':[0,1,2],\n",
    "#     \"colsample_bytree\": 0.6,\n",
    "#     \"random_state\":30,\n",
    "#     'max_depth': 8,\n",
    "#     'device': 'gpu',\n",
    "#     'gpu_platform_id':1,\n",
    "#     'gpu_device_id': 1,\n",
    "# }\n",
    "lgb_params ={\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'n_estimators':2000,\n",
    "    'learning_rate': 0.01,\n",
    "    'subsample':0.78,\n",
    "    'max_depth':8,\n",
    "    'top_rate': 0.906,\n",
    "    'num_leaves': 63,\n",
    "    'min_child_weight': 41.9612,\n",
    "    'other_rate': 0.072,\n",
    "    'reg_alpha': 9.677,\n",
    "    'colsample_bytree': 0.566,\n",
    "    'min_split_gain': 8.820,\n",
    "    'reg_lambda':9.253,\n",
    "    'min_data_in_leaf': 21,\n",
    "    'verbose': -1,\n",
    "    'seed':20,\n",
    "    'bagging_seed':42,\n",
    "    'device': 'gpu',\n",
    "    'gpu_platform_id':1,\n",
    "    'gpu_device_id': 1,\n",
    "}\n",
    "    \n",
    "#样本权重\n",
    "# w_train = (0.05 * (df_train['target'].values < -30).astype('float32') + 1).ravel()\n",
    "\n",
    "lgb_est = lgb.LGBMRegressor(**lgb_params)\n",
    "lgb_est,score,lgb_test_pred,lgb_train_pred = modelKFoldReg(df_train,df_test,lgb_est)\n",
    "# df_test['target'] = lgb_test_pred\n",
    "# df_sub = df_test[['card_id','target']]\n",
    "# # df_sub.to_csv('./submission/df_lgb_sub_%.5f.csv'%score,index=None)\n",
    "# print(df_sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"score = %s\"%score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['oof_lgb_pred_%.5f'%score] = lgb_train_pred\n",
    "df_test['oof_lgb_pred_%.5f'%score] = lgb_test_pred\n",
    "df_train[['card_id','oof_lgb_pred_%.5f'%score]].to_csv('./datasets/stacking/level1/df_lgb_train_pred_%.5f.csv'%score,index=False)\n",
    "df_test[['card_id','oof_lgb_pred_%.5f'%score]].to_csv('./datasets/stacking/level1/df_lgb_test_pred_%.5f.csv'%score,index=False)\n",
    "\n",
    "df_train.drop(columns=['oof_lgb_pred_%.5f'%score],inplace=True)\n",
    "df_test.drop(columns=['oof_lgb_pred_%.5f'%score],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,28))\n",
    "lgb.plot_importance(lgb_est,max_num_features=150, height=0.8, ax=ax)\n",
    "ax.grid(False)\n",
    "plt.title(\"LGBM - Feature Importance\", fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fea_importance = lgb_est.feature_importances_\n",
    "df_features = pd.DataFrame({'features':tr_features,'importance':fea_importance})\n",
    "df_features.sort_values(by=['importance'],ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropimp = []\n",
    "for col in df_features[df_features.importance<5].features.tolist():\n",
    "    tr_features.remove(col)\n",
    "    dropimp.append(col)\n",
    "    \n",
    "df_data.drop(columns=dropimp,inplace=True)\n",
    "print(len(tr_features))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranker model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost  as xgb\n",
    "def modelKFoldRanker(df_train,df_test,model):\n",
    "    \n",
    "    NFOLDS = 5\n",
    "    kfold = StratifiedKFold(n_splits=NFOLDS,shuffle=False,random_state=2018)\n",
    "    ntrain = df_train.shape[0]\n",
    "    ntest = df_test.shape[0]\n",
    "    oof_train_pred = np.zeros((ntrain,))\n",
    "    oof_test_pred = np.zeros((ntest,))\n",
    "    oof_test_pred_skf = np.empty((NFOLDS, ntest))\n",
    "#     for foldIndex,(dev_index,val_index) in enumerate(kfold.split(df_train)):\n",
    "    for foldIndex,(dev_index,val_index) in enumerate(kfold.split(df_train,df_train['is_outlier'])):\n",
    "        print(\"............第%s折...........\"%(foldIndex+1))\n",
    "        x_dev = df_train[tr_features].iloc[dev_index]\n",
    "        y_dev = df_train[label].iloc[dev_index]\n",
    "        x_val = df_train[tr_features].iloc[val_index]\n",
    "        y_val = df_train[label].iloc[val_index]\n",
    "        \n",
    "        print('x_dev'+str(x_dev.shape))\n",
    "        print('x_val'+str(x_val.shape))\n",
    "        q_dev = list((df_train['target'].iloc[dev_index]>-33).astype(np.int).values)\n",
    "        q_val = list((df_train['target'].iloc[val_index]>-33).astype(np.int).values)\n",
    "        print('q_dev ='+str(len(q_dev)))\n",
    "        print('q_val = '+str(len(q_val)))\n",
    "\n",
    "        model.fit(x_dev, y_dev,group=q_dev,eval_set=[(x_val,y_val)],eval_group=[q_val],\n",
    "                  early_stopping_rounds=100,verbose=100)\n",
    "        oof_test_pred_skf[foldIndex,:] = model.predict(df_test[tr_features],num_iteration=model.best_iteration_)\n",
    "        oof_train_pred[val_index] = model.predict(x_val,num_iteration=model.best_iteration_)\n",
    "    oof_test_pred[:] = oof_test_pred_skf.mean(axis=0)\n",
    "        \n",
    "#     score = np.sqrt((np.sum(np.square(oof_train_pred - df_train[label].values.reshape(-1,)))/ntrain))\n",
    "    return oof_test_pred,oof_train_pred\n",
    "\n",
    "ranker_params = {\n",
    "    'max_depth':8,\n",
    "    'learning_rate':0.01,\n",
    "    'n_estimators':2000,\n",
    "    'objective':'rank:pairwise',\n",
    "    'class_weight':'balanced',\n",
    "    'subsample':0.7,\n",
    "    'random_state':42,\n",
    "    'min_child_weight': 41.9612,\n",
    "    'other_rate': 0.072,\n",
    "    'reg_alpha': 9.677,\n",
    "    'colsample_bytree': 0.566,\n",
    "    'min_split_gain': 8.820,\n",
    "    'reg_lambda':9.253,\n",
    "    'min_data_in_leaf': 21,\n",
    "    'verbose': -1,\n",
    "    'seed':20,\n",
    "    'bagging_seed':42,\n",
    "    'device': 'gpu',\n",
    "    'gpu_platform_id':1,\n",
    "    'gpu_device_id': 1,\n",
    "}\n",
    "label = ['ranker']\n",
    "df_train['ranker'] = df_train['target'].rank(method='min')\n",
    "\n",
    "df_train['qid'] = (df_train['target']<-33).astype(np.int)\n",
    "df_train.sort_values(by=['qid'],ascending=True)\n",
    "q_dev = [199710,2207]\n",
    "\n",
    "lgb_ranker = lgb.LGBMRanker(**ranker_params)\n",
    "# q_dev = list((df_train['target']>-33).astype(np.int).values)\n",
    "\n",
    "lgb_ranker.fit(df_train[tr_features],df_train[label],group=q_dev,early_stopping_rounds=100,verbose=100)\n",
    "\n",
    "# oof_test_pred,oof_train_pred = modelKFoldRanker(df_train,df_test,lgb_ranker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(LGBMRanker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 参数优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    NFOLDS = 5\n",
    "    kfold = StratifiedKFold(n_splits=NFOLDS,shuffle=False,random_state=2018)\n",
    "    ntrain = df_train.shape[0]\n",
    "    oof_train_pred = np.zeros((ntrain,))\n",
    "    \n",
    "    lgb_params ={\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': trial.suggest_categorical('boosting', ['gbdt', 'dart', 'goss']),\n",
    "        'n_estimators':2000,\n",
    "        'learning_rate': 0.012157093610965607,\n",
    "        'subsample': 0.9855,\n",
    "        'max_depth':12,\n",
    "        'top_rate': 0.9232941199074832,\n",
    "        'num_leaves': 63,\n",
    "        'min_child_weight': 43.00279828226643,\n",
    "        'other_rate': 0.057739300172860754,\n",
    "        'reg_alpha': 13.043379756014204,\n",
    "        'colsample_bytree': 0.566,\n",
    "        'min_split_gain': 8.820,\n",
    "        'reg_lambda':19.619748271518752,\n",
    "        'min_data_in_leaf': 21,\n",
    "        'verbose': -1,\n",
    "        'seed':20,\n",
    "        'bagging_seed':42,\n",
    "        'device': 'gpu',\n",
    "        'gpu_platform_id':1,\n",
    "        'gpu_device_id': 1,\n",
    "    }\n",
    "    if lgb_params['boosting_type'] == 'dart':\n",
    "        lgb_params['drop_rate'] = trial.suggest_loguniform('drop_rate', 1e-8, 1.0)\n",
    "        lgb_params['skip_drop'] = trial.suggest_loguniform('skip_drop', 1e-8, 1.0)\n",
    "    if lgb_params['boosting_type'] == 'goss':\n",
    "        lgb_params['top_rate'] = trial.suggest_uniform('top_rate', 0.0, 1.0)\n",
    "        lgb_params['other_rate'] = trial.suggest_uniform('other_rate', 0.0, 1.0 - lgb_params['top_rate'])\n",
    "    lgb_params['learning_rate'] = trial.suggest_uniform('learning_rate',0.01,0.05)\n",
    "    lgb_params['subsample'] = trial.suggest_uniform('subsample',0.5,1.0)\n",
    "    lgb_params['max_depth'] = trial.suggest_int('max_depth',5,12)\n",
    "    lgb_params['min_child_weight'] =trial.suggest_uniform('min_child_weight',35,50)\n",
    "    lgb_params['reg_alpha'] =trial.suggest_uniform('reg_alpha',5,20)\n",
    "    lgb_params['reg_lambda'] =trial.suggest_uniform('reg_lambda',5,20)\n",
    "\n",
    "    lgb_est = lgb.LGBMRegressor(**lgb_params)\n",
    "    \n",
    "    for foldIndex,(dev_index,val_index) in enumerate(kfold.split(df_train,df_train['is_outlier'])):\n",
    "        print(\"............第%s折...........\"%(foldIndex+1))\n",
    "        x_dev = df_train[tr_features].iloc[dev_index]\n",
    "        y_dev = df_train[label].iloc[dev_index]\n",
    "        x_val = df_train[tr_features].iloc[val_index]\n",
    "        y_val = df_train[label].iloc[val_index]\n",
    "        lgb_est.fit(x_dev, y_dev,eval_set=[(x_dev,y_dev),(x_val,y_val)],\n",
    "                  early_stopping_rounds=100,verbose=100)\n",
    "        oof_train_pred[val_index] = lgb_est.predict(x_val,num_iteration=lgb_est.best_iteration_)\n",
    "        \n",
    "    rmse = np.sqrt((np.sum(np.square(oof_train_pred - df_train[label].values.reshape(-1,)))/ntrain))\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    study = optuna.create_study()\n",
    "    study.optimize(objective, n_trials=5)\n",
    "\n",
    "    print('Number of finished trials: {}'.format(len(study.trials)))\n",
    "\n",
    "    print('Best trial:')\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print('  Value: {}'.format(trial.value))\n",
    "\n",
    "    print('  Params: ')\n",
    "    for key, value in trial.params.items():\n",
    "        print('    {}: {}'.format(key, value))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
