{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,BatchNormalization\n",
    "from keras.optimizers import RMSprop \n",
    "from sklearn.model_selection import KFold,StratifiedKFold,GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import BayesianRidge,LinearRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import keras\n",
    "import datetime\n",
    "import gc\n",
    "import os\n",
    "DATA_PATH = './datasets/'\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(DATA_PATH+'df_data.csv',dtype={'first_active_month':np.str})\n",
    "df_train_test_additional_features = pd.read_csv(DATA_PATH+'df_train_test_features_additional.csv')\n",
    "df_additional_features = pd.read_csv(DATA_PATH+'df_additional_features.csv')\n",
    "\n",
    "df_data = df_data.merge(df_train_test_additional_features,on='card_id',how='left')\n",
    "df_data = df_data.merge(df_additional_features,on='card_id',how='left')\n",
    "\n",
    "path = './datasets/feature2/'\n",
    "sublist = os.listdir(path)\n",
    "for sub in sublist:\n",
    "    df = pd.read_csv(path+sub)\n",
    "    df_data = df_data.merge(df,on='card_id',how='left')\n",
    "df_data.fillna(-999,inplace=True)\n",
    "df_data.replace([np.inf,-1*np.inf],-999,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_data[df_data.is_test==0]\n",
    "df_test = df_data[df_data.is_test==1]\n",
    "df_train['is_outlier'] = (df_train.target<-30).astype(np.int)\n",
    "\n",
    "label = ['target']\n",
    "dropCols = ['card_id','first_active_month','is_outlier','is_test','target','purchase_date','merchant_id']\n",
    "tr_features = [_f for _f in df_train.columns if _f not in dropCols and df_train[_f].dtype!='object']\n",
    "print(len(tr_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_data[tr_features].values)\n",
    "\n",
    "X_train = scaler.transform(df_train[tr_features].values)\n",
    "y_train = df_train[label].values\n",
    "\n",
    "X_test = scaler.transform(df_test[tr_features].values)\n",
    "\n",
    "del df_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,y_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler,EarlyStopping\n",
    "\n",
    "batch_size = 5120\n",
    "epochs = 100\n",
    "def modelKFoldReg(X_train,y_train,X_test,model):\n",
    "    NFOLDS = 5\n",
    "    kfold = KFold(n_splits=NFOLDS,shuffle=False,random_state=2018)\n",
    "\n",
    "    ntrain = X_train.shape[0]\n",
    "    ntest = X_test.shape[0]\n",
    "    oof_train_pred = np.zeros((ntrain,))\n",
    "    oof_test_pred = np.zeros((ntest,))\n",
    "    oof_test_pred_skf = np.empty((NFOLDS, ntest))\n",
    "    for foldIndex,(dev_index,val_index) in enumerate(kfold.split(X_train)):\n",
    "        print(\"............第%s折...........\"%(foldIndex+1))\n",
    "        x_dev = X_train[dev_index]\n",
    "        y_dev = y_train[dev_index]\n",
    "        x_val = X_train[val_index]\n",
    "        y_val = y_train[val_index]\n",
    "        model.fit(x_dev, y_dev,batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  verbose=1,\n",
    "                  validation_data=(x_val, y_val),\n",
    "                  callbacks=[earlyStopping]\n",
    "                 )\n",
    "        oof_test_pred_skf[foldIndex,:] = model.predict(X_test).reshape(-1,)\n",
    "        oof_train_pred[val_index] = model.predict(x_val).reshape(-1,)\n",
    "    oof_test_pred[:] = oof_test_pred_skf.mean(axis=0)\n",
    "    score = np.sqrt((np.sum(np.square(oof_train_pred - y_train.reshape(-1,)))/ntrain))\n",
    "    return model,score,oof_test_pred,oof_train_pred\n",
    "\n",
    "def nn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse',optimizer=RMSprop(),metrics=['mse'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss',patience=10,verbose=1)\n",
    "\n",
    "model = nn_model()\n",
    "model,score,oof_test_pred,oof_train_pred = modelKFoldReg(X_train,y_train,X_test,model)\n",
    "\n",
    "print(\"score = %s\"%score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['oof_nn_pred_%.5f'%score] = oof_train_pred\n",
    "df_test['oof_nn_pred_%.5f'%score] = oof_test_pred\n",
    "\n",
    "df_train[['card_id','oof_nn_pred_%.5f'%score]].to_csv('./datasets/stacking/df_nn_train_pred_%.5f.csv'%score,index=False)\n",
    "df_test[['card_id','oof_nn_pred_%.5f'%score]].to_csv('./datasets/stacking/df_nn_test_pred_%.5f.csv'%score,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
