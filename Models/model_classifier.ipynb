{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functionUtils import *\n",
    "from sklearn.model_selection import KFold,StratifiedKFold,GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from scipy.stats import ks_2samp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import datetime\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as catb\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "fea_path = './datasets/'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(fea_path+'df_data.csv',dtype={'first_active_month':np.str})\n",
    "df_train_test_additional_features = pd.read_csv(fea_path+'df_train_test_features_additional.csv')\n",
    "df_additional_features = pd.read_csv(fea_path+'df_additional_features.csv')\n",
    "\n",
    "df_data = df_data.merge(df_train_test_additional_features,on='card_id',how='left')\n",
    "df_data = df_data.merge(df_additional_features,on='card_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './datasets/feature2/'\n",
    "sublist = os.listdir(path)\n",
    "\n",
    "for sub in sublist:\n",
    "    df = pd.read_csv(path+sub)\n",
    "    df_data = df_data.merge(df,on='card_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cate_merchantCate_fm = pd.read_csv('./datasets/cate_fm/df_hist_new_cate_merchantCate_fm_feat.csv')\n",
    "df_cate_merchant_fm = pd.read_csv('./datasets/cate_fm/df_hist_new_cate_merchant_fm_feat.csv')\n",
    "\n",
    "df_data = df_data.merge(df_cate_merchantCate_fm,on='card_id',how='left')\n",
    "df_data = df_data.merge(df_cate_merchant_fm,on='card_id',how='left')\n",
    "\n",
    "del df_cate_merchantCate_fm,df_cate_merchant_fm\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_card_merchant_statics = pd.read_csv(fea_path+'df_card_merchant_statics.csv')\n",
    "df_card_merchant_vec = pd.read_csv(fea_path+'df_card_merchant_vec.csv')\n",
    "df_card_city_statics = pd.read_csv(fea_path+'df_card_city_statics.csv')\n",
    "\n",
    "df_data = df_data.merge(df_card_merchant_vec,on='card_id',how='left')\n",
    "df_data = df_data.merge(df_card_merchant_statics,on='card_id',how='left')\n",
    "df_data = df_data.merge(df_card_city_statics,on='card_id',how='left')\n",
    "\n",
    "del df_card_merchant_statics,df_card_merchant_vec,df_card_city_statics\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nmf_card_merCate_features = pd.read_csv(fea_path+'df_nmf_card_merCate_features.csv')\n",
    "df_nmf_card_city_features = pd.read_csv(fea_path+'df_nmf_card_city_features.csv')\n",
    "df_card_merchant_features = pd.read_csv(fea_path+'df_card_merchant_features.csv')\n",
    "df_cardid_vec = pd.read_csv(fea_path+'df_cardid_vec.csv')\n",
    "# # df_card_merchant_vec1 = pd.read_csv('./datasets/df_card_merchant_vec1.csv')\n",
    "# # df_f1_f2_f3_vec = pd.read_csv('./datasets/df_f1_f2_f3_vec.csv')\n",
    "\n",
    "df_data = df_data.merge(df_nmf_card_merCate_features,on='card_id',how='left')\n",
    "df_data = df_data.merge(df_nmf_card_city_features,on='card_id',how='left')\n",
    "df_data = df_data.merge(df_card_merchant_features,on='card_id',how='left')\n",
    "df_data = df_data.merge(df_cardid_vec,on='card_id',how='left')\n",
    "\n",
    "del df_nmf_card_merCate_features,df_nmf_card_city_features,df_card_merchant_features,df_cardid_vec\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_data[df_data.is_test==0]\n",
    "df_test = df_data[df_data.is_test==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['is_outlier']\n",
    "df_train['is_outlier'] = (df_train.target<-30).astype(np.int)\n",
    "\n",
    "dropCols = ['card_id','first_active_month','is_outlier','is_test','target','purchase_date','merchant_id']\n",
    "tr_features = [_f for _f in df_train.columns if _f not in dropCols and df_train[_f].dtype!='object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def modelKFlodClf(df_train,df_test,clf):\n",
    "    NFOLDS = 5\n",
    "    kfold = StratifiedKFold(n_splits=NFOLDS,shuffle=False,random_state=20)\n",
    "\n",
    "    ntrain = df_train.shape[0]\n",
    "    ntest = df_test.shape[0]\n",
    "    oof_train_pred = np.zeros((ntrain,))\n",
    "    oof_test_pred = np.zeros((ntest,))\n",
    "    oof_test_pred_skf = np.empty((NFOLDS, ntest))\n",
    "    for foldIndex,(dev_index,val_index) in enumerate(kfold.split(df_train,df_train['is_outlier'])):\n",
    "        print(\"............第%s折...........\"%(foldIndex+1))\n",
    "        x_dev = df_train[tr_features].iloc[dev_index]\n",
    "        y_dev = df_train[label].iloc[dev_index]\n",
    "        x_val = df_train[tr_features].iloc[val_index]\n",
    "        y_val = df_train[label].iloc[val_index]\n",
    "        clf.fit(x_dev, y_dev,eval_set=[(x_dev,y_dev),(x_val,y_val)],early_stopping_rounds=50,verbose=100)\n",
    "        oof_test_pred_skf[foldIndex,:] = clf.predict_proba(df_test[tr_features],num_iteration=clf.best_iteration_)[:,0]\n",
    "        oof_train_pred[val_index] = clf.predict_proba(x_val,num_iteration=clf.best_iteration_)[:,0]\n",
    "    oof_test_pred[:] = oof_test_pred_skf.mean(axis=0)\n",
    "    return oof_train_pred.reshape(-1,1),oof_test_pred.reshape(-1,1)\n",
    "\n",
    "lgb_clf_params = {\n",
    "    'num_leaves': 31,\n",
    "    'min_data_in_leaf': 30,\n",
    "    'objective': 'binary',\n",
    "    'n_estimators':2000,\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.01,\n",
    "    \"min_child_samples\": 20,\n",
    "    'class_weight':'balanced',#平衡样本\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \"feature_fraction\": 0.9,\n",
    "#     \"bagging_freq\": 1,\n",
    "#     \"bagging_fraction\": 0.9,\n",
    "#     \"bagging_seed\": 11,\n",
    "    \"metric\": ['auc', 'binary_logloss'],\n",
    "    \"lambda_l1\": 10,\n",
    "    \"verbosity\": -1,\n",
    "    \"nthread\": 16,\n",
    "    \"random_state\": 2019\n",
    "}\n",
    "\n",
    "lgb_clf = lgb.LGBMClassifier(**lgb_clf_params)\n",
    "lgb_train_pred,lgb_test_pred = modelKFlodClf(df_train,df_test,lgb_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['lgb_outlier_pred'] = 1 - lgb_train_pred\n",
    "df_test['lgb_outlier_pred'] = 1 - lgb_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def modelKFoldClf(df_train,df_test,model):\n",
    "    \n",
    "    NFOLDS = 5\n",
    "    kfold = StratifiedKFold(n_splits=NFOLDS,shuffle=False,random_state=20)\n",
    "\n",
    "    ntrain = df_train.shape[0]\n",
    "    ntest = df_test.shape[0]\n",
    "    oof_train_pred = np.zeros((ntrain,))\n",
    "    oof_test_pred = np.zeros((ntest,))\n",
    "    oof_test_pred_skf = np.empty((NFOLDS, ntest))\n",
    "    for foldIndex,(dev_index,val_index) in enumerate(kfold.split(df_train,df_train['is_outlier'])):\n",
    "        print(\"............第%s折...........\"%(foldIndex+1))\n",
    "        x_dev = df_train[tr_features].iloc[dev_index]\n",
    "        y_dev = df_train[label].iloc[dev_index]\n",
    "        x_val = df_train[tr_features].iloc[val_index]\n",
    "        y_val = df_train[label].iloc[val_index]\n",
    "        model.fit(x_dev, y_dev,eval_set=[(x_dev,y_dev),(x_val,y_val)],use_best_model=True,early_stopping_rounds=100,verbose=100)\n",
    "        oof_test_pred_skf[foldIndex,:] = model.predict_proba(df_test[tr_features])[:,0]\n",
    "        oof_train_pred[val_index] = model.predict_proba(x_val)[:,0]\n",
    "    oof_test_pred[:] = oof_test_pred_skf.mean(axis=0)\n",
    "    score = np.sqrt((np.sum(np.square(oof_train_pred - df_train[label].values.reshape(-1,)))/ntrain))\n",
    "    return oof_train_pred.reshape(-1,1),oof_test_pred.reshape(-1,1)\n",
    "\n",
    "ratio = sum(df_train['is_outlier']==0)/sum(df_train['is_outlier']==1)\n",
    "\n",
    "print(\"ratio = \"+str(ratio))\n",
    "\n",
    "cat_params = {\n",
    "    'n_estimators':5000,\n",
    "    'learning_rate':0.01,\n",
    "    'max_depth':8,\n",
    "    'loss_function':'Logloss',\n",
    "#     'eval_metric':'F1',\n",
    "    'eval_metric':'AUC',\n",
    "    'scale_pos_weight':ratio,\n",
    "    'logging_level':'Verbose',\n",
    "    'random_state':40,\n",
    "    'bagging_temperature':0.8,\n",
    "#     'l2_leaf_reg':45,\n",
    "    'od_type':'Iter',\n",
    "    'thread_count':16\n",
    "}\n",
    "\n",
    "cat_est = catb.CatBoostClassifier(**cat_params)\n",
    "oof_train_pred,oof_test_pred = modelKFoldClf(df_train,df_test,cat_est)\n",
    "cat_est.predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['cat_outlier_pred'] = 1 - oof_train_pred\n",
    "df_test['cat_outlier_pred'] = 1 - oof_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.sort_values(by=['cat_outlier_pred'],ascending=False)[['card_id','is_outlier','cat_outlier_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio = 90.48935206162211\n",
      "............第1折...........\n",
      "[0]\tvalidation_0-auc:0.910632\tvalidation_0-logloss:0.687383\tvalidation_1-auc:0.828046\tvalidation_1-logloss:0.687427\n",
      "Multiple eval metrics have been passed: 'validation_1-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-logloss hasn't improved in 50 rounds.\n",
      "[100]\tvalidation_0-auc:0.970868\tvalidation_0-logloss:0.393896\tvalidation_1-auc:0.895837\tvalidation_1-logloss:0.398036\n",
      "[200]\tvalidation_0-auc:0.979397\tvalidation_0-logloss:0.288058\tvalidation_1-auc:0.897713\tvalidation_1-logloss:0.294999\n",
      "[300]\tvalidation_0-auc:0.985142\tvalidation_0-logloss:0.235168\tvalidation_1-auc:0.899367\tvalidation_1-logloss:0.244545\n",
      "[400]\tvalidation_0-auc:0.989436\tvalidation_0-logloss:0.202224\tvalidation_1-auc:0.900085\tvalidation_1-logloss:0.213832\n",
      "[500]\tvalidation_0-auc:0.992818\tvalidation_0-logloss:0.178758\tvalidation_1-auc:0.900276\tvalidation_1-logloss:0.19204\n",
      "[600]\tvalidation_0-auc:0.99515\tvalidation_0-logloss:0.160533\tvalidation_1-auc:0.900351\tvalidation_1-logloss:0.175308\n",
      "[700]\tvalidation_0-auc:0.996742\tvalidation_0-logloss:0.145451\tvalidation_1-auc:0.900601\tvalidation_1-logloss:0.16149\n",
      "[800]\tvalidation_0-auc:0.997868\tvalidation_0-logloss:0.13202\tvalidation_1-auc:0.900219\tvalidation_1-logloss:0.149312\n",
      "[900]\tvalidation_0-auc:0.998626\tvalidation_0-logloss:0.11997\tvalidation_1-auc:0.899368\tvalidation_1-logloss:0.1385\n",
      "[1000]\tvalidation_0-auc:0.999174\tvalidation_0-logloss:0.108125\tvalidation_1-auc:0.898861\tvalidation_1-logloss:0.127829\n",
      "[1100]\tvalidation_0-auc:0.999499\tvalidation_0-logloss:0.097922\tvalidation_1-auc:0.898054\tvalidation_1-logloss:0.1187\n",
      "[1200]\tvalidation_0-auc:0.999695\tvalidation_0-logloss:0.088916\tvalidation_1-auc:0.897427\tvalidation_1-logloss:0.110641\n",
      "[1300]\tvalidation_0-auc:0.999831\tvalidation_0-logloss:0.080351\tvalidation_1-auc:0.896958\tvalidation_1-logloss:0.103132\n",
      "[1400]\tvalidation_0-auc:0.999902\tvalidation_0-logloss:0.073457\tvalidation_1-auc:0.896295\tvalidation_1-logloss:0.097109\n",
      "[1500]\tvalidation_0-auc:0.99995\tvalidation_0-logloss:0.066706\tvalidation_1-auc:0.895879\tvalidation_1-logloss:0.091252\n",
      "[1600]\tvalidation_0-auc:0.999975\tvalidation_0-logloss:0.060426\tvalidation_1-auc:0.895225\tvalidation_1-logloss:0.085903\n",
      "[1700]\tvalidation_0-auc:0.999988\tvalidation_0-logloss:0.054801\tvalidation_1-auc:0.894543\tvalidation_1-logloss:0.081142\n",
      "[1800]\tvalidation_0-auc:0.999995\tvalidation_0-logloss:0.049299\tvalidation_1-auc:0.894135\tvalidation_1-logloss:0.076538\n",
      "[1900]\tvalidation_0-auc:0.999998\tvalidation_0-logloss:0.044583\tvalidation_1-auc:0.893723\tvalidation_1-logloss:0.072645\n",
      "[2000]\tvalidation_0-auc:1\tvalidation_0-logloss:0.040429\tvalidation_1-auc:0.893362\tvalidation_1-logloss:0.069305\n",
      "[2100]\tvalidation_0-auc:1\tvalidation_0-logloss:0.036554\tvalidation_1-auc:0.89275\tvalidation_1-logloss:0.066221\n",
      "[2200]\tvalidation_0-auc:1\tvalidation_0-logloss:0.032965\tvalidation_1-auc:0.892298\tvalidation_1-logloss:0.063434\n",
      "[2300]\tvalidation_0-auc:1\tvalidation_0-logloss:0.029836\tvalidation_1-auc:0.891716\tvalidation_1-logloss:0.061113\n",
      "[2400]\tvalidation_0-auc:1\tvalidation_0-logloss:0.026884\tvalidation_1-auc:0.89119\tvalidation_1-logloss:0.058957\n",
      "[2500]\tvalidation_0-auc:1\tvalidation_0-logloss:0.024306\tvalidation_1-auc:0.890881\tvalidation_1-logloss:0.057094\n",
      "[2600]\tvalidation_0-auc:1\tvalidation_0-logloss:0.022123\tvalidation_1-auc:0.890608\tvalidation_1-logloss:0.055587\n",
      "[2700]\tvalidation_0-auc:1\tvalidation_0-logloss:0.020048\tvalidation_1-auc:0.890435\tvalidation_1-logloss:0.054188\n",
      "[2800]\tvalidation_0-auc:1\tvalidation_0-logloss:0.018208\tvalidation_1-auc:0.890247\tvalidation_1-logloss:0.053002\n",
      "[2900]\tvalidation_0-auc:1\tvalidation_0-logloss:0.01647\tvalidation_1-auc:0.890058\tvalidation_1-logloss:0.051977\n",
      "[3000]\tvalidation_0-auc:1\tvalidation_0-logloss:0.014937\tvalidation_1-auc:0.889795\tvalidation_1-logloss:0.051105\n",
      "[3100]\tvalidation_0-auc:1\tvalidation_0-logloss:0.013508\tvalidation_1-auc:0.890061\tvalidation_1-logloss:0.050277\n",
      "[3200]\tvalidation_0-auc:1\tvalidation_0-logloss:0.012295\tvalidation_1-auc:0.889975\tvalidation_1-logloss:0.049667\n",
      "[3300]\tvalidation_0-auc:1\tvalidation_0-logloss:0.011189\tvalidation_1-auc:0.890105\tvalidation_1-logloss:0.049129\n",
      "[3400]\tvalidation_0-auc:1\tvalidation_0-logloss:0.010196\tvalidation_1-auc:0.890047\tvalidation_1-logloss:0.048711\n",
      "[3500]\tvalidation_0-auc:1\tvalidation_0-logloss:0.009334\tvalidation_1-auc:0.890036\tvalidation_1-logloss:0.048393\n",
      "[3600]\tvalidation_0-auc:1\tvalidation_0-logloss:0.008506\tvalidation_1-auc:0.890234\tvalidation_1-logloss:0.04811\n",
      "[3700]\tvalidation_0-auc:1\tvalidation_0-logloss:0.007801\tvalidation_1-auc:0.890495\tvalidation_1-logloss:0.047929\n",
      "[3800]\tvalidation_0-auc:1\tvalidation_0-logloss:0.007175\tvalidation_1-auc:0.890581\tvalidation_1-logloss:0.047806\n",
      "[3900]\tvalidation_0-auc:1\tvalidation_0-logloss:0.006576\tvalidation_1-auc:0.890803\tvalidation_1-logloss:0.04773\n",
      "Stopping. Best iteration:\n",
      "[3926]\tvalidation_0-auc:1\tvalidation_0-logloss:0.006434\tvalidation_1-auc:0.890775\tvalidation_1-logloss:0.047718\n",
      "\n",
      "............第2折...........\n",
      "[0]\tvalidation_0-auc:0.911128\tvalidation_0-logloss:0.687319\tvalidation_1-auc:0.812654\tvalidation_1-logloss:0.687407\n",
      "Multiple eval metrics have been passed: 'validation_1-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-logloss hasn't improved in 50 rounds.\n",
      "[100]\tvalidation_0-auc:0.971964\tvalidation_0-logloss:0.390824\tvalidation_1-auc:0.891364\tvalidation_1-logloss:0.397241\n",
      "[200]\tvalidation_0-auc:0.980005\tvalidation_0-logloss:0.285084\tvalidation_1-auc:0.892856\tvalidation_1-logloss:0.295527\n",
      "[300]\tvalidation_0-auc:0.985301\tvalidation_0-logloss:0.233496\tvalidation_1-auc:0.893855\tvalidation_1-logloss:0.24682\n",
      "[400]\tvalidation_0-auc:0.989476\tvalidation_0-logloss:0.200568\tvalidation_1-auc:0.894004\tvalidation_1-logloss:0.216185\n",
      "[500]\tvalidation_0-auc:0.992534\tvalidation_0-logloss:0.178615\tvalidation_1-auc:0.893992\tvalidation_1-logloss:0.195851\n",
      "[600]\tvalidation_0-auc:0.994768\tvalidation_0-logloss:0.160287\tvalidation_1-auc:0.893219\tvalidation_1-logloss:0.17903\n",
      "[700]\tvalidation_0-auc:0.996405\tvalidation_0-logloss:0.14528\tvalidation_1-auc:0.892769\tvalidation_1-logloss:0.165339\n",
      "[800]\tvalidation_0-auc:0.997596\tvalidation_0-logloss:0.13103\tvalidation_1-auc:0.892331\tvalidation_1-logloss:0.152227\n",
      "[900]\tvalidation_0-auc:0.998378\tvalidation_0-logloss:0.119471\tvalidation_1-auc:0.89167\tvalidation_1-logloss:0.141689\n",
      "[1000]\tvalidation_0-auc:0.998949\tvalidation_0-logloss:0.108426\tvalidation_1-auc:0.890863\tvalidation_1-logloss:0.131598\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def modelKFoldClf(df_train,df_test,model):\n",
    "    \n",
    "    NFOLDS = 5\n",
    "    kfold = StratifiedKFold(n_splits=NFOLDS,shuffle=False,random_state=2018)\n",
    "\n",
    "    ntrain = df_train.shape[0]\n",
    "    ntest = df_test.shape[0]\n",
    "    oof_train_pred = np.zeros((ntrain,))\n",
    "    oof_test_pred = np.zeros((ntest,))\n",
    "    oof_test_pred_skf = np.empty((NFOLDS, ntest))\n",
    "    for foldIndex,(dev_index,val_index) in enumerate(kfold.split(df_train,df_train['is_outlier'])):\n",
    "        print(\"............第%s折...........\"%(foldIndex+1))\n",
    "        x_dev = df_train[tr_features].iloc[dev_index]\n",
    "        y_dev = df_train[label].iloc[dev_index]\n",
    "        x_val = df_train[tr_features].iloc[val_index]\n",
    "        y_val = df_train[label].iloc[val_index]\n",
    "        model.fit(x_dev, y_dev,eval_set=[(x_dev,y_dev),(x_val,y_val)],early_stopping_rounds=50,verbose=100)\n",
    "        oof_test_pred_skf[foldIndex,:] = model.predict_proba(df_test[tr_features])[:,0]\n",
    "        oof_train_pred[val_index] = model.predict_proba(x_val)[:,0]\n",
    "    oof_test_pred[:] = oof_test_pred_skf.mean(axis=0)\n",
    "    return oof_train_pred.reshape(-1,1),oof_test_pred.reshape(-1,1)\n",
    "\n",
    "ratio = sum(df_train['is_outlier']==0)/sum(df_train['is_outlier']==1)\n",
    "print(\"ratio = \"+str(ratio))\n",
    "\n",
    "xgb_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'booster': 'gbtree',\n",
    "    'learning_rate': 0.01,\n",
    "    'n_estimators':5000,\n",
    "    'scale_pos_weight':ratio,\n",
    "    'max_depth': 8,\n",
    "    \"eval_metric\": ['auc', 'logloss'],\n",
    "    'gamma' : 1.45,\n",
    "    'alpha': 0.1,\n",
    "    'lambda': 0.3,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.054,\n",
    "    'colsample_bylevel': 0.50,\n",
    "    'random_state': 2018\n",
    "}\n",
    "xgb_est = xgb.XGBClassifier(**xgb_params)\n",
    "oof_train_pred,oof_test_pred = modelKFoldClf(df_train,df_test,xgb_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['xgb_outlier_pred'] = 1 - oof_train_pred\n",
    "df_test['xgb_outlier_pred'] = 1 - oof_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.sort_values(by=['xgb_outlier_pred'],ascending=False)[['card_id','is_outlier','xgb_outlier_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['card_id','xgb_outlier_pred']].to_csv('./datasets/class/df_xgb_train.csv',index=False)\n",
    "df_test[['card_id','xgb_outlier_pred']].to_csv('./datasets/class/df_xgb_test.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_test = df_test.shape[0]*sum(df_train['is_outlier']==1)/df_train.shape[0]\n",
    "print(\"测试集约有:%s异常值\"%abnormal_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_cols = [_f for _f in df_train.columns if 'outlier_pred' in _f]\n",
    "df_class_train = df_train[['card_id','is_outlier']+outlier_cols]\n",
    "df_class_test = df_test[['card_id']+outlier_cols]\n",
    "\n",
    "df_lgb_train = pd.read_csv('./datasets/class/lgb_classifier_train_0.0446_0.8994.csv')\n",
    "df_lgb_test = pd.read_csv('./datasets/class/lgb_classifier_test_0.0446_0.8994.csv')\n",
    "\n",
    "df_cat_train = pd.read_csv('./datasets/class/catboost_classifier_train_0.8934.csv')\n",
    "df_cat_test = pd.read_csv('./datasets/class/catboost_classifier_test_0.8934.csv')\n",
    "\n",
    "# df_lgb1_train = pd.read_csv('./datasets/class/lightgbm_classifier_train_0.8994_0.0446.csv')\n",
    "# df_lgb1_test = pd.read_csv('./datasets/class/lightgbm_classifier_test_0.8994_0.0446.csv')\n",
    "\n",
    "\n",
    "df_class_train = df_class_train.merge(df_lgb_train,on='card_id',how='left')\n",
    "df_class_test = df_class_test.merge(df_lgb_test,on='card_id',how='left')\n",
    "\n",
    "df_class_train = df_class_train.merge(df_cat_train,on='card_id',how='left')\n",
    "df_class_test = df_class_test.merge(df_cat_test,on='card_id',how='left')\n",
    "\n",
    "# df_class_train = df_class_train.merge(df_lgb1_train,on='card_id',how='left')\n",
    "# df_class_test = df_class_test.merge(df_lgb1_test,on='card_id',how='left')\n",
    "\n",
    "\n",
    "##分类器文件保存\n",
    "df_class_train.to_csv('./datasets/class/df_class_train.csv',index=False)\n",
    "df_class_test.to_csv('./datasets/class/df_class_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "NFOLDS = 5\n",
    "# kfold = KFold(n_splits=NFOLDS,shuffle=False,random_state=5)\n",
    "kfold = StratifiedKFold(n_splits=NFOLDS,shuffle=False,random_state=20)\n",
    "label = ['is_outlier']\n",
    "tr_features = [_f for _f in df_class_train.columns if _f not in ['card_id','is_outlier']]\n",
    "\n",
    "ntrain = df_class_train.shape[0]\n",
    "ntest = df_class_test.shape[0]\n",
    "oof_train_pred = np.zeros((ntrain,))\n",
    "oof_test_pred = np.zeros((ntest,))\n",
    "oof_test_pred_skf = np.empty((NFOLDS, ntest))\n",
    "for foldIndex,(dev_index,val_index) in enumerate(kfold.split(df_class_train,df_class_train['is_outlier'])):\n",
    "    clf = LogisticRegression(class_weight='balanced',random_state=42)\n",
    "    x_dev = df_class_train[tr_features].iloc[dev_index]\n",
    "    y_dev = df_class_train[label].iloc[dev_index]\n",
    "    x_val = df_class_train[tr_features].iloc[val_index]\n",
    "    y_val = df_class_train[label].iloc[val_index]\n",
    "    clf.fit(x_dev.values,y_dev.values)\n",
    "    oof_test_pred_skf[foldIndex,:] = clf.predict_proba(df_class_test[tr_features].values)[:,1]\n",
    "    oof_train_pred[val_index] = clf.predict_proba(x_val.values)[:,1]\n",
    "\n",
    "oof_test_pred[:] = oof_test_pred_skf.mean(axis=0)\n",
    "\n",
    "score = np.sqrt((np.sum(np.square(oof_train_pred - df_class_train[label].values.reshape(-1,)))/ntrain))\n",
    "\n",
    "df_Log_sub = pd.DataFrame(data=df_class_test['card_id'].values,columns=['card_id'])\n",
    "df_Log_sub['log_outlier_pred'] = oof_test_pred\n",
    "print(\"score = %s\"%score)\n",
    "df_Log_sub.sort_values(by=['log_outlier_pred'],ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = 100\n",
    "outlier_cols = [_f for _f in df_class_train.columns if _f not in ['card_id','is_outlier']]\n",
    "\n",
    "aggs = set(df_class_train.card_id)\n",
    "\n",
    "for col in outlier_cols:\n",
    "    df = df_class_train.sort_values(by=col,ascending=False)[['card_id',col]].iloc[:topk,]\n",
    "    aggs = set(aggs) & set(df['card_id'])\n",
    "\n",
    "print(len(aggs))\n",
    "df = df_class_train[df_class_train['card_id'].isin(list(aggs))][['card_id','is_outlier']]\n",
    "accuracy = df[df.is_outlier==1].shape[0]/len(aggs)\n",
    "\n",
    "print(\"Accuracy: %s\"%accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_class_train[df_class_train['card_id'].isin(list(aggs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### testSets\n",
    "df_temp = pd.read_csv('./classify.csv').sort_values(by=['outlier_rate'],ascending=False)\n",
    "temp_list = list(df_temp.iloc[:topk,]['card_id'])\n",
    "\n",
    "outlier_cols = [_f for _f in df_class_test.columns if _f not in ['card_id','target']]\n",
    "aggs = set(temp_list)\n",
    "\n",
    "for col in outlier_cols:\n",
    "    df = df_class_test.sort_values(by=col,ascending=False)[['card_id',col]].iloc[:topk,]\n",
    "    aggs = set(aggs) & set(df['card_id'])\n",
    "aggs = set(aggs) & set(df_Log_sub['card_id'])\n",
    "print(len(aggs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_sub = pd.read_csv('./submission/df_stackingII_blend_sub.csv')\n",
    "df_best_sub[df_best_sub['card_id'].isin(list(aggs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_best_sub.ix[df_best_sub['card_id'].isin(list(aggs)),['target']] = -33.21928095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_sub.to_csv('./submission/df_best_sub_with_21outliers.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_best_sub.target,bins=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
