{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_181\"; Java(TM) SE Runtime Environment (build 1.8.0_181-b13); Java HotSpot(TM) 64-Bit Server VM (build 25.181-b13, mixed mode)\n",
      "  Starting server from /home/sjtu123/.local/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmpatkdlbsm\n",
      "  JVM stdout: /tmp/tmpatkdlbsm/h2o_sjtu123_started_from_python.out\n",
      "  JVM stderr: /tmp/tmpatkdlbsm/h2o_sjtu123_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n",
      "Warning: Your H2O cluster version is too old (3 months and 29 days)! Please download and install the latest version from http://h2o.ai/download/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Asia/Shanghai</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.22.0.1</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>3 months and 29 days !!!</td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_sjtu123_bvz1yu</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>10.47 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>20</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>20</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.5 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         01 secs\n",
       "H2O cluster timezone:       Asia/Shanghai\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.22.0.1\n",
       "H2O cluster version age:    3 months and 29 days !!!\n",
       "H2O cluster name:           H2O_from_python_sjtu123_bvz1yu\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    10.47 Gb\n",
       "H2O cluster total cores:    20\n",
       "H2O cluster allowed cores:  20\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.5 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook, tnrange\n",
    "from sklearn.model_selection import KFold,StratifiedKFold,GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import BayesianRidge,LinearRegression\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import datetime\n",
    "import gc\n",
    "import h2o\n",
    "import os\n",
    "DATA_PATH = './datasets/'\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "h2o.init()#开启h2o集群\n",
    "\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv(DATA_PATH+'df_data.csv',dtype={'first_active_month':np.str})\n",
    "df_train_test_additional_features = pd.read_csv(DATA_PATH+'df_train_test_features_additional.csv')\n",
    "df_additional_features = pd.read_csv(DATA_PATH+'df_additional_features.csv')\n",
    "\n",
    "df_data = df_data.merge(df_train_test_additional_features,on='card_id',how='left')\n",
    "df_data = df_data.merge(df_additional_features,on='card_id',how='left')\n",
    "\n",
    "path = './datasets/feature2/'\n",
    "sublist = os.listdir(path)\n",
    "for sub in sublist:\n",
    "    df = pd.read_csv(path+sub)\n",
    "    df_data = df_data.merge(df,on='card_id',how='left')\n",
    "\n",
    "del df_additional_features,df_train_test_additional_features,df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tsne_fea = pd.read_csv('./datasets/df_tsne_fea.csv')\n",
    "df_data = df_data.merge(df_tsne_fea,on='card_id',how='left')\n",
    "df_cate_statics = pd.read_csv('./datasets/df_cate_statics.csv')\n",
    "df_data = df_data.merge(df_cate_statics,on='card_id',how='left')\n",
    "\n",
    "del df_cate_statics,df_tsne_fea\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_card_merchant_statics = pd.read_csv(DATA_PATH+'df_card_merchant_statics.csv')\n",
    "df_card_merchant_vec = pd.read_csv(DATA_PATH+'df_card_merchant_vec.csv')\n",
    "df_card_city_statics = pd.read_csv(DATA_PATH+'df_card_city_statics.csv')\n",
    "\n",
    "df_data = df_data.merge(df_card_merchant_vec,on='card_id',how='left')\n",
    "df_data = df_data.merge(df_card_merchant_statics,on='card_id',how='left')\n",
    "df_data = df_data.merge(df_card_city_statics,on='card_id',how='left')\n",
    "\n",
    "del df_card_merchant_statics,df_card_merchant_vec,df_card_city_statics\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.fillna(-999,inplace=True)\n",
    "df_data.replace([np.inf,-1*np.inf],-999,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1525\n"
     ]
    }
   ],
   "source": [
    "df_train = df_data[df_data.is_test==0]\n",
    "df_test = df_data[df_data.is_test==1]\n",
    "df_train['is_outlier'] = (df_train.target<-30).astype(np.int)\n",
    "del df_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['target']\n",
    "dropCols = ['card_id','first_active_month','is_outlier','is_test','target','purchase_date','merchant_id']\n",
    "tr_features = [_f for _f in df_train.columns if _f not in dropCols and df_train[_f].dtype!='object']\n",
    "print(len(tr_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "df_train = h2o.H2OFrame.from_python(df_train)\n",
    "df_test = h2o.H2OFrame.from_python(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "score = 3.656091680051238\n",
      "CPU times: user 1min 32s, sys: 2.58 s, total: 1min 35s\n",
      "Wall time: 5h 53min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "gbm_reg_params = {\n",
    "    'learn_rate':0.01,\n",
    "    'max_depth':8,\n",
    "    'sample_rate':0.8,\n",
    "    'col_sample_rate':0.9,\n",
    "    'learn_rate_annealing':0.999,\n",
    "    'nfolds':5,\n",
    "    'ntrees':5000,\n",
    "    'seed':20,\n",
    "#     'fold_assignment':\"stratified\",\n",
    "#     'fold_column':'is_outlier',\n",
    "    'stopping_rounds':50,\n",
    "    'stopping_metric':'rmse',\n",
    "    'keep_cross_validation_fold_assignment':True,\n",
    "    'keep_cross_validation_predictions':True,    \n",
    "}\n",
    "h2o_gbm = H2OGradientBoostingEstimator(**gbm_reg_params)\n",
    "\n",
    "# h2o_gbm.fit(X=df_train[tr_features],y=df_train[label])\n",
    "h2o_gbm.train(tr_features, 'target', training_frame=df_train, validation_frame=df_train)\n",
    "\n",
    "gbm_test_pred = h2o_gbm.predict(test_data=df_test[tr_features]).as_data_frame()['predict'].values\n",
    "gbm_train_pred = h2o_gbm.cross_validation_holdout_predictions().as_data_frame()['predict'].values\n",
    "\n",
    "y_target = df_train[label].as_data_frame()[label].values.reshape(-1,)\n",
    "\n",
    "score = np.sqrt((np.sum(np.square(gbm_train_pred - y_target))/df_train.shape[0]))\n",
    "\n",
    "print(\"score = %s\"%score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "df_train['oof_gbm_pred_%.5f'%score] = h2o.H2OFrame.from_python(gbm_train_pred)\n",
    "df_test['oof_gbm_pred_%.5f'%score] = h2o.H2OFrame.from_python(gbm_test_pred)\n",
    "h2o.download_csv(data=df_train[['card_id','oof_gbm_pred_%.5f'%score]],filename='./datasets/stacking/level1/h2ogbm_train_pred_%.5f.csv'%score)\n",
    "h2o.download_csv(data=df_test[['card_id','oof_gbm_pred_%.5f'%score]],filename='./datasets/stacking/levle1/h2ogbm_test_pred_%.5f.csv'%score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "\n",
    "rf_reg_params = {\n",
    "    'ntrees':8000,\n",
    "    'max_depth':8,\n",
    "    'col_sample_rate_per_tree':0.9,\n",
    "    'sample_rate':0.9,\n",
    "    'score_each_iteration':True,\n",
    "    'stopping_metric':\"rmse\",\n",
    "    'stopping_rounds':100,\n",
    "    'keep_cross_validation_fold_assignment':True,\n",
    "    'keep_cross_validation_predictions':True,\n",
    "#     'fold_assignment':\"stratified\",\n",
    "#     'fold_column':'is_outlier',\n",
    "    'nfolds':5,    \n",
    "    'seed':30,\n",
    "}\n",
    "\n",
    "h2o_rf = H2ORandomForestEstimator(**rf_reg_params)\n",
    "h2o_rf.train(tr_features, 'target', training_frame=df_train, validation_frame=df_train)\n",
    "\n",
    "rf_test_pred = h2o_rf.predict(test_data=df_test[tr_features]).as_data_frame()['predict'].values\n",
    "rf_train_pred = h2o_rf.cross_validation_holdout_predictions().as_data_frame()['predict'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o_rf.cross_validation_metrics_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target = df_train[label].as_data_frame()[label].values.reshape(-1,)\n",
    "score = np.sqrt((np.sum(np.square(rf_train_pred - y_target))/df_train.shape[0]))\n",
    "print(\"score = %s\"%score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['oof_rf_pred_%.5f'%score] = h2o.H2OFrame.from_python(rf_train_pred)\n",
    "df_test['oof_rf_pred_%.5f'%score] = h2o.H2OFrame.from_python(rf_test_pred)\n",
    "h2o.download_csv(data=df_train[['card_id','oof_rf_pred_%.5f'%score]],filename='./datasets/stacking/h2orf_train_pred_%.5f.csv'%score)\n",
    "h2o.download_csv(data=df_test[['card_id','oof_rf_pred_%.5f'%score]],filename='./datasets/stacking/h2orf_test_pred_%.5f.csv'%score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
