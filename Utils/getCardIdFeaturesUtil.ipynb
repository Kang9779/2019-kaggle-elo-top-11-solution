{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functionUtils import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from workalendar.america import Brazil\n",
    "from datetime import date,timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import workalendar\n",
    "import datetime\n",
    "import gc\n",
    "DATA_PATH = './datasets/'\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(DATA_PATH+'train.csv')\n",
    "df_test = pd.read_csv(DATA_PATH+'test.csv')\n",
    "df_historical = pd.read_csv(DATA_PATH+'historical_transactions.csv',dtype={'purchase_date':np.str},low_memory=True)\n",
    "df_new_merchant = pd.read_csv(DATA_PATH+'new_merchant_transactions.csv',dtype={'purchase_date':np.str},low_memory=True)\n",
    "\n",
    "df_train['is_test'] = 0\n",
    "df_test['is_test'] = 1\n",
    "#用户在历史和之后的记录中是否出现过\n",
    "for df in [df_train,df_test]:\n",
    "    df['is_in_new_monthlag1'] = df['card_id'].isin(df_new_merchant[df_new_merchant.month_lag==1].card_id).astype(int)\n",
    "    df['is_in_new_monthlag2'] = df['card_id'].isin(df_new_merchant[df_new_merchant.month_lag==2].card_id).astype(int)\n",
    "df_data = pd.concat([df_train,df_test])\n",
    "df_data = pd.get_dummies(df_data,columns=['feature_1','feature_2','feature_3'],prefix=['feature_1','feature_2','feature_3'])\n",
    "df_transactions = pd.concat([df_historical,df_new_merchant])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions['purchase_amount'] = np.round(df_transactions['purchase_amount']/0.00150265118+497.06,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## id类特征\n",
    "df_temp = df_historical.card_id.value_counts().reset_index()\n",
    "df_temp.rename(columns={'index':'card_id','card_id':'hist_card_id_counts'},inplace=True)\n",
    "df_temp['hist_card_id_ratio'] = df_temp['hist_card_id_counts']/df_historical.shape[0]\n",
    "df_data = df_data.merge(df_temp,on='card_id',how='left')\n",
    "\n",
    "df_temp = df_new_merchant.card_id.value_counts().reset_index()\n",
    "df_temp.rename(columns={'index':'card_id','card_id':'new_card_id_counts'},inplace=True)\n",
    "df_temp['new_card_id_ratio'] = df_temp['new_card_id_counts']/df_new_merchant.shape[0]\n",
    "df_data = df_data.merge(df_temp,on='card_id',how='left')\n",
    "\n",
    "df_data['hist/new_card_counts_ratio'] = df_data['hist_card_id_counts']/df_data['new_card_id_counts']\n",
    "\n",
    "df_data[['hist_card_id_counts','hist_card_id_ratio','new_card_id_counts','new_card_id_ratio','hist/new_card_counts_ratio']].fillna(0,inplace=True)\n",
    "\n",
    "del df_temp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 user features:时间特征&统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "598"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dateHandle = pd.to_datetime(df_data['first_active_month'])\n",
    "df_data['active_year'] = dateHandle.dt.year\n",
    "df_data['active_month'] = dateHandle.dt.month\n",
    "df_data['active_to_base_time'] = (datetime.date(2018,2,28) - dateHandle.dt.date).dt.days\n",
    "\n",
    "#hist第一次刷卡时间\n",
    "df_temp = df_historical.groupby('card_id')['purchase_date'].min().reset_index()\n",
    "df_temp.rename(columns={'purchase_date':'hist_first_purchase_date'},inplace=True)\n",
    "df_data = df_data.merge(df_temp,on='card_id',how='left')\n",
    "#最后一次刷卡时间\n",
    "df_temp = df_historical.groupby('card_id')['purchase_date'].max().reset_index()\n",
    "df_temp.rename(columns={'purchase_date':'hist_last_purchase_date'},inplace=True)\n",
    "df_data = df_data.merge(df_temp,on='card_id',how='left')\n",
    "\n",
    "#new第一次刷卡时间\n",
    "df_temp = df_new_merchant.groupby('card_id')['purchase_date'].min().reset_index()\n",
    "df_temp.rename(columns={'purchase_date':'new_first_purchase_date'},inplace=True)\n",
    "df_data = df_data.merge(df_temp,on='card_id',how='left')\n",
    "#最后一次刷卡时间\n",
    "df_temp = df_new_merchant.groupby('card_id')['purchase_date'].max().reset_index()\n",
    "df_temp.rename(columns={'purchase_date':'new_last_purchase_date'},inplace=True)\n",
    "df_data = df_data.merge(df_temp,on='card_id',how='left')\n",
    "\n",
    "#hist-new 购买时长\n",
    "df_data['hist_first_to_base_time'] = (pd.to_datetime(df_data['hist_first_purchase_date']).dt.date -datetime.date(2018,2,28)).dt.days\n",
    "df_data['hist_last_to_base_time'] = (pd.to_datetime(df_data['hist_last_purchase_date']).dt.date -datetime.date(2018,2,28)).dt.days\n",
    "df_data['hist_last_to_first_time'] = (pd.to_datetime(df_data['hist_last_purchase_date']).dt.date - pd.to_datetime(df_data['hist_first_purchase_date']).dt.date).dt.days\n",
    "df_data['hist_first_active_time'] = (pd.to_datetime(df_data['hist_first_purchase_date']).dt.date - pd.to_datetime(df_data['first_active_month']).dt.date).dt.days\n",
    "df_data['hist_last_active_time'] = (pd.to_datetime(df_data['hist_last_purchase_date']).dt.date - pd.to_datetime(df_data['first_active_month']).dt.date).dt.days\n",
    "\n",
    "df_data['new_first_to_base_time'] = (pd.to_datetime(df_data['new_first_purchase_date']).dt.date - datetime.date(2018,2,28)).dt.days\n",
    "df_data['new_last_to_base_time'] = (pd.to_datetime(df_data['new_last_purchase_date']).dt.date - datetime.date(2018,2,28)).dt.days\n",
    "df_data['new_first_to_active_time'] = (pd.to_datetime(df_data['new_first_purchase_date']).dt.date - pd.to_datetime(df_data['first_active_month']).dt.date).dt.days\n",
    "df_data['new_last_to_active_time'] = (pd.to_datetime(df_data['new_last_purchase_date']).dt.date - pd.to_datetime(df_data['first_active_month']).dt.date).dt.days\n",
    "df_data['new_last_to_first_time'] = (pd.to_datetime(df_data['new_last_purchase_date']).dt.date - pd.to_datetime(df_data['new_first_purchase_date']).dt.date).dt.days\n",
    "\n",
    "#hist最后一次购买距离new第一次购买的时间差\n",
    "df_data['new_to_hist_time'] = (pd.to_datetime(df_data['new_first_purchase_date']).dt.date - \n",
    "                               pd.to_datetime(df_data['hist_last_purchase_date']).dt.date).dt.days\n",
    "#单位时间内的刷卡次数\n",
    "df_data['hist_per_time_purchaseCounts'] = df_data['hist_card_id_counts']/df_data['hist_last_to_first_time']\n",
    "df_data['new_per_time_purchaseCounts'] = df_data['new_card_id_counts']/df_data['new_last_to_first_time']\n",
    "\n",
    "df_data.drop(columns=['hist_last_purchase_date','hist_first_purchase_date','new_first_purchase_date','new_last_purchase_date'],inplace=True)\n",
    "df_data.replace([np.inf,-np.inf],0,inplace=True)\n",
    "df_data.fillna(-1,inplace=True)\n",
    "del df_train,df_test,df_historical,df_new_merchant,df_temp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "659913438c1244c5912f7dc29cd9f20b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory usage of dataframe is 9957.63 MB\n",
      "Memory usage after optimization is: 2489.41 MB\n",
      "Decreased by 75.0%\n",
      "CPU times: user 1h 20min 22s, sys: 2min 54s, total: 1h 23min 16s\n",
      "Wall time: 1h 17min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def dateUtils(df=None,timeCol='purchase_date'):\n",
    "    dateHandle = pd.to_datetime(df[timeCol])\n",
    "    df['week'] = dateHandle.dt.week\n",
    "    df['year'] = dateHandle.dt.year\n",
    "    df['month'] = dateHandle.dt.month\n",
    "    df['dayofweek'] = dateHandle.dt.dayofweek\n",
    "    df['weekend'] = (dateHandle.dt.weekday >=5).astype(int)\n",
    "    df['hour'] = dateHandle.dt.hour\n",
    "    df['month_gap'] = (dateHandle.dt.date - datetime.date(2018,2,28)).dt.days//30\n",
    "    df['day_gap'] = (dateHandle.dt.date - datetime.date(2018,2,28)).dt.days\n",
    "    #cardid用户连续购买之间的时间差\n",
    "    df['purchase_time'] = dateHandle\n",
    "    df['purchase_time_diff_days'] = df.groupby('card_id')['purchase_time'].apply(lambda series:series.diff(1)).dt.days\n",
    "    df['purchase_time_diff_days'].fillna(df.purchase_time_diff_days.mean(),inplace=True)\n",
    "    df['purchase_time_diff_seconds'] = df.groupby('card_id')['purchase_time'].apply(lambda series:series.diff(1)).dt.seconds\n",
    "    df['purchase_time_diff_seconds'].fillna(df.purchase_time_diff_seconds.mean(),inplace=True)\n",
    "    df.drop(columns=['purchase_time'],inplace=True)\n",
    "    def getdate2Holiday(d):\n",
    "        cal = Brazil()\n",
    "        holiday = cal.holidays(d.year)\n",
    "        dis,flag= 0,0\n",
    "        year,month,day = d.year,d.month,d.day\n",
    "        d = datetime.date(year,month,day)\n",
    "        for i,h in enumerate(holiday):\n",
    "            if holiday[i][0]>d:\n",
    "                flag = 1\n",
    "                dis = (holiday[i][0] - d).days\n",
    "                return dis\n",
    "        if flag==0:\n",
    "            dis = (holiday[-1][0] - d).days\n",
    "        return dis\n",
    "    df['date2Holiday'] = df['purchase_date'].apply(lambda x:getdate2Holiday(pd.to_datetime(x)))\n",
    "    \n",
    "    return df\n",
    "#缺失值处理\n",
    "#C2:区域；C3分期等级；C1为-1城市编码对应Y\n",
    "df_transactions['category_2'].fillna(6,inplace=True)\n",
    "df_transactions['category_3'].fillna('B',inplace=True)\n",
    "df_transactions['merchant_id'].fillna(df_transactions['merchant_id'].value_counts().index[0],inplace=True)\n",
    "df_transactions['installments'].replace(-1,1,inplace=True)\n",
    "df_transactions['installments'].replace(999,0,inplace=True)\n",
    "\n",
    "#交互特征\n",
    "df_transactions['city_C1'] = ((df_transactions['city_id']< 0) + 0).astype(np.str) + '_' + df_transactions['category_1'].astype(np.str)\n",
    "df_transactions['C2_state'] = df_transactions['category_2'].astype(np.str) + '_' + df_transactions['state_id'].astype(np.str) \n",
    "df_transactions['C2_state_subsector'] = df_transactions['category_2'].astype(np.str) + '_' + df_transactions['state_id'].astype(np.str) + '_' + df_transactions['subsector_id'].astype(np.str)\n",
    "df_transactions['subsector_city'] = df_transactions['subsector_id'].astype(np.str) + '_' + ((df_transactions['city_id'] < 0) + 0).astype(np.str)\n",
    "df_transactions['auth_C3'] = df_transactions['authorized_flag'].astype(np.str) + '_' + df_transactions['category_3'].astype(np.str)\n",
    "\n",
    "cateCols = ['city_C1','C2_state','C2_state_subsector','subsector_city','auth_C3']\n",
    "df_transactions = label_encoding(df_transactions,cateCols)\n",
    "\n",
    "for cate in ['A','B','C']:\n",
    "    df_transactions['category_3_%s'%cate] = (df_transactions['category_3']==cate) + 0\n",
    "for cate in [1,2,3,4,5,6]:\n",
    "    df_transactions['category_2_%s'%cate] = (df_transactions['category_2']==cate) + 0\n",
    "for cate in ['Y','N']:\n",
    "    df_transactions['authorized_flag_%s'%cate] = (df_transactions['authorized_flag']==cate) + 0\n",
    "\n",
    "df_transactions['category_1'] = df_transactions['category_1'].map({'Y':1,'N':0})\n",
    "df_transactions['category_3'] = df_transactions['category_3'].map({'A':0,'B':1,'C':2})\n",
    "df_transactions['authorized_flag'] = df_transactions['authorized_flag'].map({'Y':1,'N':0})\n",
    "\n",
    "df_transactions.sort_values(by=['card_id','purchase_date'],ascending=True,inplace=True)\n",
    "df_transactions = dateUtils(df_transactions,timeCol='purchase_date')\n",
    "df_transactions = reduce_mem_usage(df_transactions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions.sort_values(by=['card_id','purchase_date'],ascending=True,inplace=True)\n",
    "# df_transactions['purchase_diff'] = df_transactions.groupby('card_id')['purchase_amount'].apply(lambda series:series.diff(1)).values\n",
    "# df_transactions['purchase_diff'].fillna(0,inplace=True)\n",
    "df_hist_transactions = df_transactions[df_transactions.month_lag<=0]\n",
    "df_new_transactions = df_transactions[df_transactions.month_lag>0]\n",
    "for df in [df_hist_transactions,df_new_transactions]:\n",
    "    df['purchase_diff'] = df.groupby('card_id')['purchase_amount'].apply(lambda series:series.diff(1)).values\n",
    "    df['purchase_diff'].fillna(0,inplace=True)\n",
    "df_hist_auth_Y_transactions = df_hist_transactions[df_hist_transactions.authorized_flag==1]\n",
    "df_hist_auth_N_transactions = df_hist_transactions[df_hist_transactions.authorized_flag==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_upperOutlier(series):\n",
    "#     return (series-series.mean())>2.04*series.std()\n",
    "# def find_lowerOutlier(series):\n",
    "#     return (series-series.mean())<-2.04*series.std()\n",
    "# def cap_values(series):\n",
    "#     maxOutliers = find_upperOutlier(series)\n",
    "#     minOutliers = find_lowerOutlier(series)\n",
    "    \n",
    "#     max_val = series[(~maxOutliers) & (~minOutliers)].max()\n",
    "#     min_val = series[(~maxOutliers) & (~minOutliers)].min()\n",
    "    \n",
    "#     series[maxOutliers] = max_val\n",
    "#     series[minOutliers] = min_val\n",
    "#     return series\n",
    "# #指数平均处理purchase_amount\n",
    "# def calc_rollWeight_mean(series,alpha=0.98,adjust=True):\n",
    "#     return series.ewm(alpha=alpha,adjust=adjust,span=7).mean()\n",
    "# def targetPro(df_feature,label='purchase_amount',group='card_id'):\n",
    "#     df_feature['purchase_rollweight_mean'] = df_feature.groupby(group).apply(lambda series:calc_rollWeight_mean(series[label])).values\n",
    "#     return df_feature\n",
    "# for df_feature in [df_hist_auth_Y_transactions,df_hist_auth_N_transactions,df_new_transactions]:\n",
    "#     df_feature['purchase_is_outlier'] = df_feature.groupby('card_id').apply(lambda series:find_upperOutlier(series['purchase_amount'])).values\n",
    "#     df_feature['purchase_is_outlier'] = df_feature['purchase_is_outlier'].astype(np.int)\n",
    "#     df_feature['purchase_capped'] = df_feature.groupby(['card_id']).apply(lambda series:cap_values(series['purchase_amount'])).values\n",
    "#     df_feature = targetPro(df_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#用户月消费记录\n",
    "def getMonthPurchase(df_data,df_feature,group='month_gap',fea='purchase_amount',name='hist'):\n",
    "    df_purchase = df_feature.groupby(['card_id','month_gap'])['purchase_amount'].sum().reset_index()\n",
    "    df_purchase.rename(columns={'purchase_amount':'purchase_amount_sum_month'},inplace=True)\n",
    "    df_purchase.sort_values(by=['month_gap'],inplace=True,ascending=True)\n",
    "\n",
    "    df_temp = df_purchase[['card_id','month_gap','purchase_amount_sum_month']]\n",
    "    df_temp.index = df_temp.card_id\n",
    "    df_temp = df_temp.set_index(['month_gap'],append=True)\n",
    "    df_temp = pd.Series(df_temp['purchase_amount_sum_month'].values.reshape(len(df_temp['purchase_amount_sum_month'])),index=df_temp.index)\n",
    "    df_temp = df_temp.unstack()\n",
    "    df_temp.reset_index(inplace=True)\n",
    "    cols = ['card_id']\n",
    "    for index in list(df_purchase['month_gap'].unique()):\n",
    "        cols.append('%s_month%s_purchase'%(name,index))\n",
    "    df_temp.columns = cols\n",
    "    df_temp.fillna(0,inplace=True)\n",
    "    df_data = df_data.merge(df_temp,on='card_id',how='left')\n",
    "    \n",
    "    del df_purchase,df_temp,cols\n",
    "    gc.collect()\n",
    "    \n",
    "    return df_data\n",
    "\n",
    "#周消费记录\n",
    "def getWeekPurchase(df_data,df_feature,group='week',fea='purchase_amount',name='hist'):\n",
    "    df_purchase = df_feature.groupby(['card_id','week'])['purchase_amount'].sum().reset_index()\n",
    "    df_purchase.rename(columns={'purchase_amount':'purchase_sum_week'},inplace=True)\n",
    "    df_purchase.sort_values(by=['week'],inplace=True,ascending=True)\n",
    "    df_count = df_purchase.groupby(['card_id'])['purchase_sum_week'].count().reset_index()\n",
    "    df_count.rename(columns={'purchase_sum_week':'%s_purchase_counts'%name},inplace=True)\n",
    "\n",
    "    df_temp = df_purchase[['card_id','week','purchase_sum_week']]\n",
    "    df_temp.index = df_temp.card_id\n",
    "    df_temp = df_temp.set_index(['week'],append=True)\n",
    "    df_temp = pd.Series(df_temp['purchase_sum_week'].values.reshape(len(df_temp['purchase_sum_week'])),index=df_temp.index)\n",
    "    df_temp = df_temp.unstack()\n",
    "    df_temp.reset_index(inplace=True)\n",
    "    cols = ['card_id']\n",
    "    for index in list(df_purchase['week'].unique()):\n",
    "        cols.append('%s_week%s_purchase'%(name,index))\n",
    "    df_temp.columns = cols\n",
    "    df_temp = df_temp.merge(df_count,on='card_id',how='left')\n",
    "    df_temp.fillna(0,inplace=True)\n",
    "    df_data = df_data.merge(df_temp,on='card_id',how='left')\n",
    "    return df_data\n",
    "#用户月分期记录\n",
    "def getMonthInstallments(df_data,df_feature,group='month_gap',fea='installments',name='hist'):\n",
    "    df_purchase = df_feature.groupby(['card_id','month_gap'])['installments'].sum().reset_index()\n",
    "    df_purchase.rename(columns={'installments':'installments_sum_month'},inplace=True)\n",
    "    df_purchase.sort_values(by=['month_gap'],inplace=True,ascending=True)\n",
    "\n",
    "    df_temp = df_purchase[['card_id','month_gap','installments_sum_month']]\n",
    "    df_temp.index = df_temp.card_id\n",
    "    df_temp = df_temp.set_index(['month_gap'],append=True)\n",
    "    df_temp = pd.Series(df_temp['installments_sum_month'].values.reshape(len(df_temp['installments_sum_month'])),index=df_temp.index)\n",
    "    df_temp = df_temp.unstack()\n",
    "    df_temp.reset_index(inplace=True)\n",
    "    cols = ['card_id']\n",
    "    for index in list(df_purchase['month_gap'].unique()):\n",
    "        cols.append('%s_month%s_installments'%(name,index))\n",
    "    df_temp.columns = cols\n",
    "    df_temp.fillna(0,inplace=True)\n",
    "    df_data = df_data.merge(df_temp,on='card_id',how='left')\n",
    "    del df_purchase,df_temp,cols\n",
    "    gc.collect()\n",
    "    return df_data\n",
    "def getWeekInstallments(df_data,df_feature,group='week',fea='installments',name='hist'):\n",
    "    df_purchase = df_feature.groupby(['card_id','week'])['installments'].sum().reset_index()\n",
    "    df_purchase.rename(columns={'installments':'installments_sum_week'},inplace=True)\n",
    "    df_purchase.sort_values(by=['week'],inplace=True,ascending=True)\n",
    "\n",
    "    df_temp = df_purchase[['card_id','week','installments_sum_week']]\n",
    "    df_temp.index = df_temp.card_id\n",
    "    df_temp = df_temp.set_index(['week'],append=True)\n",
    "    df_temp = pd.Series(df_temp['installments_sum_week'].values.reshape(len(df_temp['installments_sum_week'])),index=df_temp.index)\n",
    "    df_temp = df_temp.unstack()\n",
    "    df_temp.reset_index(inplace=True)\n",
    "    cols = ['card_id']\n",
    "    for index in list(df_purchase['week'].unique()):\n",
    "        cols.append('%s_week%s_installments'%(name,index))\n",
    "    df_temp.columns = cols\n",
    "    df_temp.fillna(0,inplace=True)\n",
    "    df_data = df_data.merge(df_temp,on='card_id',how='left')\n",
    "    del df_purchase,df_temp,cols\n",
    "    gc.collect()\n",
    "    return df_data\n",
    "\n",
    "df_data = getMonthPurchase(df_data,df_hist_auth_Y_transactions,name='hist_auth_Y')\n",
    "df_data = getMonthPurchase(df_data,df_hist_auth_N_transactions,name='hist_auth_N')\n",
    "df_data = getMonthPurchase(df_data,df_new_transactions,name='new')\n",
    "# df_data = getMonthInstallments(df_data,df_hist_transactions,name='hist')\n",
    "# df_data = getMonthInstallments(df_data,df_new_transactions,name='new')\n",
    "\n",
    "\n",
    "# df_data = getWeekPurchase(df_data,df_hist_auth_Y_transactions,name='hist_auth_Y')\n",
    "# df_data = getWeekPurchase(df_data,df_hist_auth_N_transactions,name='hist_auth_N')\n",
    "# df_data = getWeekPurchase(df_data,df_new_transactions,name='new')\n",
    "# df_data = getWeekInstallments(df_data,df_hist_transactions,name='hist')\n",
    "# df_data = getWeekInstallments(df_data,df_new_transactions,name='new')\n",
    "\n",
    "df_data.replace([np.inf,-np.inf],np.nan,inplace=True)\n",
    "df_data.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>is_in_new_monthlag1</th>\n",
       "      <th>is_in_new_monthlag2</th>\n",
       "      <th>is_test</th>\n",
       "      <th>target</th>\n",
       "      <th>feature_1_1</th>\n",
       "      <th>feature_1_2</th>\n",
       "      <th>feature_1_3</th>\n",
       "      <th>feature_1_4</th>\n",
       "      <th>...</th>\n",
       "      <th>new_month-7_purchase</th>\n",
       "      <th>new_month-6_purchase</th>\n",
       "      <th>new_month-5_purchase</th>\n",
       "      <th>new_month-4_purchase</th>\n",
       "      <th>new_month-3_purchase</th>\n",
       "      <th>new_month-2_purchase</th>\n",
       "      <th>new_month-1_purchase</th>\n",
       "      <th>new_month0_purchase</th>\n",
       "      <th>new_month1_purchase</th>\n",
       "      <th>new_month2_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>2017-06</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.820283</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1042.569946</td>\n",
       "      <td>1549.329956</td>\n",
       "      <td>26.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.99</td>\n",
       "      <td>29.689999</td>\n",
       "      <td>29.980000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>2016-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>2017-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>140.880005</td>\n",
       "      <td>241.100006</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159749</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1305.390015</td>\n",
       "      <td>3328.050049</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id first_active_month  is_in_new_monthlag1  \\\n",
       "0  C_ID_92a2005557            2017-06                    1   \n",
       "1  C_ID_3d0044924f            2017-01                    1   \n",
       "2  C_ID_d639edf6cd            2016-08                    0   \n",
       "3  C_ID_186d6a6901            2017-09                    1   \n",
       "4  C_ID_cdbd2c0db2            2017-11                    1   \n",
       "\n",
       "   is_in_new_monthlag2  is_test    target  feature_1_1  feature_1_2  \\\n",
       "0                    1        0 -0.820283            0            0   \n",
       "1                    1        0  0.392913            0            0   \n",
       "2                    1        0  0.688056            0            1   \n",
       "3                    1        0  0.142495            0            0   \n",
       "4                    1        0 -0.159749            1            0   \n",
       "\n",
       "   feature_1_3  feature_1_4         ...           new_month-7_purchase  \\\n",
       "0            0            0         ...                            0.0   \n",
       "1            0            1         ...                            0.0   \n",
       "2            0            0         ...                            0.0   \n",
       "3            0            1         ...                            0.0   \n",
       "4            0            0         ...                            0.0   \n",
       "\n",
       "   new_month-6_purchase  new_month-5_purchase  new_month-4_purchase  \\\n",
       "0                   0.0                   0.0                   0.0   \n",
       "1                   0.0                   0.0                   0.0   \n",
       "2                   0.0                   0.0                   0.0   \n",
       "3                   0.0                   0.0                   0.0   \n",
       "4                   0.0                   0.0                   0.0   \n",
       "\n",
       "   new_month-3_purchase  new_month-2_purchase  new_month-1_purchase  \\\n",
       "0                   0.0                   0.0                  0.00   \n",
       "1                   0.0                   0.0                 23.99   \n",
       "2                   0.0                   0.0                  0.00   \n",
       "3                   0.0                   0.0                  0.00   \n",
       "4                   0.0                   0.0                  0.00   \n",
       "\n",
       "   new_month0_purchase  new_month1_purchase  new_month2_purchase  \n",
       "0          1042.569946          1549.329956                26.59  \n",
       "1            29.689999            29.980000                 0.00  \n",
       "2             0.000000            31.000000                 0.00  \n",
       "3           140.880005           241.100006                 0.00  \n",
       "4          1305.390015          3328.050049                 0.00  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropCols = set(df_data.columns) - set(originalCols)\n",
    "df_data.drop(columns=dropCols,inplace=True)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "originalCols = list(df_data.columns)\n",
    "###持卡人不同授权类型的购买总量\n",
    "def getAuthorizedPurchase(df_data,df_features,name='hist'):\n",
    "    df_temp = df_features.groupby(['card_id','authorized_flag'])['purchase_amount'].sum().reset_index()\n",
    "    df_temp = df_temp.pivot(index='card_id',columns='authorized_flag',values='purchase_amount')\n",
    "    cols = []\n",
    "    for col in df_temp.columns:\n",
    "        cols.append(name + df_temp.columns.name+'_'+ np.str(col)+'_purchasesum')\n",
    "    df_temp.columns = cols\n",
    "    df_temp.columns.name=None\n",
    "    df_temp.reset_index(inplace=True)\n",
    "    df_temp.fillna(0,inplace=True)\n",
    "    if name=='hist':\n",
    "        df_temp['%s_Auth_purchase_sum'%name] = df_temp[cols[0]] + df_temp[cols[1]]\n",
    "        df_temp[cols[0]+'_ratio'] = df_temp[cols[0]]/df_temp['%s_Auth_purchase_sum'%name]\n",
    "        df_temp[cols[1]+'_ratio'] = df_temp[cols[1]]/df_temp['%s_Auth_purchase_sum'%name]\n",
    "        df_temp.drop(columns=['%s_Auth_purchase_sum'%name],inplace=True)\n",
    "    df_data = df_data.merge(df_temp,on='card_id',how='left')\n",
    "    del df_temp\n",
    "    gc.collect()\n",
    "    return df_data\n",
    "#### 用户对商家的回购率\n",
    "def getUserRepurchaseRatio(df_data,df_fea,group=['card_id','merchant_id'],fea='purchase_amount',name='repurchase_mechant_ratio'):\n",
    "    df_temp = df_features.groupby(group)[fea].count().reset_index().rename(\n",
    "        columns={fea:'purchase_amount_counts'})\n",
    "    df_temp['repurchase_flag'] = (df_temp['purchase_amount_counts']>1) + 0\n",
    "    df = df_temp.groupby(['card_id'])['purchase_amount_counts'].sum().reset_index().rename(columns={'purchase_amount_counts':'purchase_records'})\n",
    "    df_temp['repurchase_counts'] = df_temp['repurchase_flag'] * df_temp['purchase_amount_counts']\n",
    "    df_temp = df_temp.merge(df,on='card_id',how='left')\n",
    "    df_temp['repurchase_ratio'] = df_temp['repurchase_counts']/df_temp['purchase_records']\n",
    "    df_temp = df_temp.groupby('card_id')['repurchase_ratio'].max().reset_index().rename(columns={'repurchase_ratio':name})\n",
    "    df_data = df_data.merge(df_temp,on='card_id',how='left')\n",
    "    del df,df_temp\n",
    "    gc.collect()\n",
    "    return df_data\n",
    "\n",
    "for flag,df_features in zip(['hist_auth_Y','hist_auth_N','new'],[df_hist_auth_Y_transactions,df_hist_auth_N_transactions,df_new_transactions]):\n",
    "    print(\".................%s......................\"%flag)\n",
    "    if 'hist' in flag:\n",
    "        month_lag = [-1,-3,-5,-7,-13]\n",
    "    else:\n",
    "        month_lag = [1,2]\n",
    "    for index in month_lag:\n",
    "        df = df_features[df_features.month_lag>=index]\n",
    "        #各个阶段的purchase_amount(强特)\n",
    "        df_data = getMeanStaticsFeatures(df_data,df,['card_id'],'purchase_amount',name='%s_purchaseAmountMean_%s'%(flag,index))\n",
    "        df_data = getMaxStaticsFeatures(df_data,df,['card_id'],'purchase_amount',name='%s_purchaseAmountMax_%s'%(flag,index))\n",
    "        df_data = getMedianStaticsFeatures(df_data,df,['card_id'],'purchase_amount',name='%s_purchaseAmountMedian_%s'%(flag,index))\n",
    "        df_data = getSumStaticsFeatures(df_data,df,['card_id'],'purchase_amount',name='%s_purchaseAmountSum_%s'%(flag,index))\n",
    "        df_data = getStdStaticsFeatures(df_data,df,['card_id'],'purchase_amount',name='%s_purcahseAmountStd_%s'%(flag,index))\n",
    "        df_data = getCountsStaticsFeatures(df_data,df,['card_id'],'purchase_amount',name='%s_purcahseAmountCount_%s'%(flag,index))\n",
    "        \n",
    "        df_data['%s_per_time_purchaseAmountSum_%s'%(flag,index)] = df_data['%s_purchaseAmountSum_%s'%(flag,index)]/(np.abs(index))      \n",
    "        df_data['%s_per_time_purcahseAmountCount_%s'%(flag,index)] = df_data['%s_purcahseAmountCount_%s'%(flag,index)]/(np.abs(index))\n",
    "\n",
    "        #分期数\n",
    "        df_data = getMeanStaticsFeatures(df_data,df,['card_id'],'installments',name='%s_installmentsMean_%s'%(flag,index))\n",
    "        df_data = getMaxStaticsFeatures(df_data,df,['card_id'],'installments',name='%s_installmentsMax_%s'%(flag,index))\n",
    "        df_data = getSumStaticsFeatures(df_data,df,['card_id'],'installments',name='%s_installmentsSum_%s'%(flag,index))\n",
    "        df_data = getCountsStaticsFeatures(df_data,df,['card_id'],'installments',name='%s_installmentsCount_%s'%(flag,index))\n",
    "        \n",
    "        df_data['%s_per_time_installmentsSum_%s'%(flag,index)] = df_data['%s_installmentsSum_%s'%(flag,index)]/(np.abs(index))\n",
    "        df_data['%s_per_time_installmentsCount_%s'%(flag,index)] = df_data['%s_installmentsCount_%s'%(flag,index)]/(np.abs(index))\n",
    "\n",
    "        #purchase_diff(强特)\n",
    "        df_data = getMeanStaticsFeatures(df_data,df,['card_id'],'purchase_diff',name='%s_purchaseDiffMean_%s'%(flag,index))\n",
    "        df_data = getMaxStaticsFeatures(df_data,df,['card_id'],'purchase_diff',name='%s_purchaseDiffMax_%s'%(flag,index))\n",
    "        df_data = getMedianStaticsFeatures(df_data,df,['card_id'],'purchase_diff',name='%s_purchaseDiffMedian_%s'%(flag,index))\n",
    "        df_data = getMinStaticsFeatures(df_data,df,['card_id'],'purchase_diff',name='%s_purchaseDiffMin_%s'%(flag,index))\n",
    "        df_data = getStdStaticsFeatures(df_data,df,['card_id'],'purchase_diff',name='%s_purcahseDiffStd_%s'%(flag,index))\n",
    "        \n",
    "        #day_diff\n",
    "#         df_data = getMaxStaticsFeatures(df_data,df_features,['card_id'],'day_diff',name='%s_dayDiffMax_%s'%(flag,index))\n",
    "#         df_data = getMinStaticsFeatures(df_data,df_features,['card_id'],'day_diff',name='%s_dayDiffMin_%s'%(flag,index))\n",
    "#         df_data = getCategoryFrequenceMax(df_data,df_features,['card_id'],'day_diff',name='%s_dayDiffFrequenceMax_%s'%(flag,index))\n",
    "          \n",
    "        #信用卡分期类别特征\n",
    "        for cate in ['category_3_A','category_3_B','category_3_C']:\n",
    "            df_data = getSumStaticsFeatures(df_data,df,['card_id'],cate,name='%s_%s_sum_%s'%(flag,cate,index))\n",
    "\n",
    "    if 'hist' in flag:\n",
    "        histflag = 'hist'\n",
    "    else:\n",
    "        histflag = 'new'\n",
    "    #信用卡授权统计\n",
    "    for cate in ['Y','N']:\n",
    "        df_data = getSumStaticsFeatures(df_data,df_features,['card_id'],'authorized_flag_%s'%cate,\n",
    "                                        name='%s_authorized_flag_%s_sum_%s'%(flag,cate,index))\n",
    "        df_data['%s_per_time_authorized_flag_%s_sum_%s'%(flag,cate,index)] = (\n",
    "            df_data['%s_authorized_flag_%s_sum_%s'%(flag,cate,index)]/df_data['%s_last_to_first_time'%histflag])\n",
    "    \n",
    "    ##date2Holiday\n",
    "    df_data = getMaxStaticsFeatures(df_data,df_features,['card_id'],'date2Holiday',name='%s_date2HolidayMax'%flag)\n",
    "    df_data = getMinStaticsFeatures(df_data,df_features,['card_id'],'date2Holiday',name='%s_date2HolidayMin'%flag)\n",
    "    df_data = getMeanStaticsFeatures(df_data,df_features,['card_id'],'date2Holiday',name='%s_date2Holiday'%flag)\n",
    "\n",
    "    #AuthorizedPurchase\n",
    "    df_data = getAuthorizedPurchase(df_data,df_features,name='%s_'%flag)\n",
    "    #purchase_is_outlier\n",
    "#     df_data = getSumStaticsFeatures(df_data,df_features,['card_id'],'purchase_is_outlier',name='%s_purchaseOutlier_sum'%flag)\n",
    "    #month\n",
    "    df_data = getCategoryCounts(df_data,df_features,['card_id'],'month',name='%s_activeMonthCount'%flag)\n",
    "    df_data = getCategoryFrequenceMax(df_data,df_features,['card_id'],'month',name='%s_activeMonthMax'%flag)\n",
    "    df_data = getCategoryFrequenceMaxRatio(df_data,df_features,['card_id'],'month',name='%s_activeMonthMaxRatio'%flag)\n",
    "    df_data['%s_per_time_activeMonthCount'%flag] = (df_data['%s_activeMonthCount'%flag]/\n",
    "                                                    df_data['%s_last_to_first_time'%histflag])\n",
    "    #month_lag\n",
    "    df_data = getMinStaticsFeatures(df_data,df_features,['card_id'],'month_lag',name='%s_monthLagMin'%flag)\n",
    "    df_data = getMaxStaticsFeatures(df_data,df_features,['card_id'],'month_lag',name='%s_monthLagMax'%flag)\n",
    "    #month_gap\n",
    "    df_data = getCategoryCounts(df_data,df_features,['card_id'],'month_gap',\n",
    "                                name='%s_monthGap_categoryCounts'%flag)\n",
    "    df_data = getCategoryCountsRatio(df_data,df_features,['card_id'],'month_gap',\n",
    "                                     name='%s_monthGap_categoryCountsRatio'%flag)\n",
    "\n",
    "    #day_gap\n",
    "    df_data = getMaxStaticsFeatures(df_data,df_features,['card_id'],'day_gap',name='%s_dayGapMax'%flag)\n",
    "    df_data = getMinStaticsFeatures(df_data,df_features,['card_id'],'day_gap',name='%s_dayGapMin'%flag)\n",
    "    #回购率\n",
    "    df_data = getUserRepurchaseRatio(df_data,df_features,name='%s_repurchase_merchant_ratio'%flag)\n",
    "    df_data = getUserRepurchaseRatio(df_data,df_features,group=['card_id','merchant_category_id'],name='%s_repurchase_merCate_ratio'%flag)\n",
    "    #purchase shift比例\n",
    "    df_features['%s_purchase_shift'%flag] = df_features.groupby(['card_id'])['purchase_amount'].apply(lambda series:series.shift(1)).values\n",
    "    df_features['%s_purchase_shift'%flag].fillna(0,inplace=True)\n",
    "    df_features['%s_purchase_shift_ratio'%flag] = df_features['%s_purchase_shift'%flag]/df_features['purchase_amount']\n",
    "    df_temp = df_features.groupby(['card_id'])['%s_purchase_shift_ratio'%flag].max().reset_index()\n",
    "    df_data = df_data.merge(df_temp,on='card_id',how='left')\n",
    "    #hour\n",
    "    df_data = getMeanStaticsFeatures(df_data,df_features,['card_id'],'hour',name='%s_HourMean_'%(flag))\n",
    "    df_data = getSumStaticsFeatures(df_data,df_features,['card_id'],'hour',name='%s_HourSum_'%(flag))\n",
    "    df_data = getCountsStaticsFeatures(df_data,df_features,['card_id'],'hour',name='%s_HourCounts_'%(flag))\n",
    "    #weekend\n",
    "    df_data = getSumStaticsFeatures(df_data,df_features,['card_id'],'weekend',name='%s_weekendSum_'%(flag))\n",
    "    #dayofweek\n",
    "    df_data = getMeanStaticsFeatures(df_data,df_features,['card_id'],'dayofweek',name='%s_dayofweekMean_'%flag)\n",
    "    df_data = getCategoryCounts(df_data,df_features,['card_id'],'dayofweek',name='%s_dayofWeekCounts_'%flag)\n",
    "    \n",
    "    for cate in [1,2,3,4,5,6]:\n",
    "        df_data = getSumStaticsFeatures(df_data,df_features,['card_id'],'category_2_%s'%cate,\n",
    "                                        name='%s_category_2_%s_sum'%(flag,cate))\n",
    "        df_data['%s_per_time_category_2_%s_sum'%(flag,cate)] = (\n",
    "            df_data['%s_category_2_%s_sum'%(flag,cate)]/df_data['%s_last_to_first_time'%histflag])\n",
    "        \n",
    "    categoryCols = cateCols + ['authorized_flag','merchant_id','city_id','category_1','category_2','category_3',\n",
    "                               'merchant_category_id','subsector_id']\n",
    "    #purchase_time_diff\n",
    "    df_data = getMinStaticsFeatures(df_data,df_features,['card_id'],'purchase_time_diff_days',name='%s_purchase_time_diff_days_min_'%(flag))\n",
    "    df_data = getMinStaticsFeatures(df_data,df_features,['card_id'],'purchase_time_diff_seconds',name='%s_purchase_time_diff_seconds_min_'%(flag))\n",
    "    \n",
    "    for fea in ['purchase_time_diff_seconds','purchase_time_diff_days']:\n",
    "        df_data = getCategoryFrequenceMax(df_data,df_features,['card_id'],fea,\n",
    "                                          name='%s_%s_frequenceMax'%(flag,fea))\n",
    "        df_data = getCategoryCounts(df_data,df_features,['card_id'],fea,\n",
    "                                    name='%s_%s_categoryCounts'%(flag,fea))\n",
    "        df_data = getCategoryFrequenceMaxRatio(df_data,df_features,['card_id'],fea,\n",
    "                                               name='%s_%s_frequenceMaxRatio'%(flag,fea))\n",
    "        df_data = getCategoryCountsRatio(df_data,df_features,['card_id'],fea,\n",
    "                                         name='%s_%s_categoryCountsRatio'%(flag,fea))\n",
    "    for fea in categoryCols:\n",
    "        df_data = getCategoryFrequenceMax(df_data,df_features,['card_id'],fea,\n",
    "                                          name='%s_%s_frequenceMax'%(flag,fea))\n",
    "        df_data = getCategoryCounts(df_data,df_features,['card_id'],fea,\n",
    "                                    name='%s_%s_categoryCounts'%(flag,fea))\n",
    "        df_data = getCategoryFrequenceMaxRatio(df_data,df_features,['card_id'],fea,\n",
    "                                               name='%s_%s_frequenceMaxRatio'%(flag,fea))\n",
    "        df_data = getCategoryCountsRatio(df_data,df_features,['card_id'],fea,\n",
    "                                         name='%s_%s_categoryCountsRatio'%(flag,fea))\n",
    "\n",
    "#month_lag=0的消费平均消费水平\n",
    "df_temp = df_hist_transactions[df_hist_transactions.month_lag==0]\n",
    "df_temp = df_temp.groupby(['card_id'])['purchase_amount'].mean().reset_index().rename(\n",
    "    columns={'purchase_amount':'hist_purchaseAmountMean_0'}) \n",
    "df_data = df_data.merge(df_temp,on='card_id',how='left')\n",
    "\n",
    "del df_temp,df_features,df_hist_transactions,df_new_transactions\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_data['avg_purchase_ratio_-1'] = df_data['hist_auth_Y_purchaseAmountMean_-1']/df_data['hist_purchaseAmountMean_0']\n",
    "df_data['avg_purchase_ratio_-3'] = df_data['hist_auth_Y_purchaseAmountMean_-3']/df_data['hist_purchaseAmountMean_0']\n",
    "df_data['avg_purchase_ratio_-5'] = df_data['hist_auth_Y_purchaseAmountMean_-5']/df_data['hist_purchaseAmountMean_0']\n",
    "df_data['avg_purchase_ratio_-7'] = df_data['hist_auth_Y_purchaseAmountMean_-7']/df_data['hist_purchaseAmountMean_0']\n",
    "df_data['avg_purchase_ratio_-13'] = df_data['hist_auth_Y_purchaseAmountMean_-13']/df_data['hist_purchaseAmountMean_0']\n",
    "df_data['avg_purchase_ratio_1'] = df_data['new_purchaseAmountMean_1']/df_data['hist_purchaseAmountMean_0']\n",
    "df_data['avg_purchase_ratio_2'] = df_data['new_purchaseAmountMean_2']/df_data['hist_purchaseAmountMean_0']\n",
    "\n",
    "df_data.replace([np.inf,-np.inf],np.nan,inplace=True)\n",
    "df_data.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1391.48 MB\n",
      "Memory usage after optimization is: 505.74 MB\n",
      "Decreased by 63.7%\n",
      "Memory usage of dataframe is 2489.41 MB\n",
      "Memory usage after optimization is: 2489.41 MB\n",
      "Decreased by 0.0%\n"
     ]
    }
   ],
   "source": [
    "#保存用户统计特征\n",
    "df_data = reduce_mem_usage(df_data)\n",
    "df_transactions = reduce_mem_usage(df_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.to_csv('./datasets/df_data.csv',index=False)\n",
    "df_transactions.to_csv('./datasets/df_transactions.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_uid = pd.read_csv('./datasets/df_data.csv',usecols=['card_id'])\n",
    "df_transactions = pd.read_csv('./datasets/df_transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11369e9c49b4fbf95fe211e1adba6fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".................hist......................\n",
      ".................new......................\n"
     ]
    }
   ],
   "source": [
    "cateCols = ['city_C1','C2_state','C2_state_subsector','subsector_city','auth_C3']\n",
    "categoryCols = cateCols + ['authorized_flag','merchant_id','city_id','category_1','category_2','category_3',\n",
    "                           'merchant_category_id','subsector_id']\n",
    "df_transactions = label_encoding(df_transactions,['merchant_id'])\n",
    "df_hist_transactions = df_transactions[df_transactions.month_lag<=0]\n",
    "df_new_transactions = df_transactions[df_transactions.month_lag>0]\n",
    "\n",
    "for flag,df_features in zip(['hist','new'],[df_hist_transactions,df_new_transactions]):\n",
    "    print(\".................%s......................\"%flag)\n",
    "    #categoryCols\n",
    "    for fea in categoryCols:\n",
    "        df_uid = getMeanStaticsFeatures(df_uid,df_features,['card_id'],fea,name='%s_%s_Mean'%(flag,fea))\n",
    "        df_uid = getMaxStaticsFeatures(df_uid,df_features,['card_id'],fea,name='%s_%s_Max'%(flag,fea))\n",
    "        df_uid = getMedianStaticsFeatures(df_uid,df_features,['card_id'],fea,name='%s_%s_Median'%(flag,fea))\n",
    "        df_uid = getSumStaticsFeatures(df_uid,df_features,['card_id'],fea,name='%s_%s_Sum'%(flag,fea))\n",
    "        df_uid = getStdStaticsFeatures(df_uid,df_features,['card_id'],fea,name='%s_%s_Std'%(flag,fea))\n",
    "        df_uid = getCountsStaticsFeatures(df_uid,df_features,['card_id'],fea,name='%s_%s_Count'%(flag,fea))\n",
    "        \n",
    "df_uid.to_csv('./datasets/df_cate_statics.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_hist = df_hist_transactions.groupby(['card_id','date2Holiday'])['purchase_amount'].sum().reset_index()\n",
    "df_hist = df_hist.groupby('card_id')['purchase_amount'].max().reset_index().rename(columns={'purchase_amount':'hist_holiday_purchase_Max'})\n",
    "\n",
    "df_new = df_new_transactions.groupby(['card_id','date2Holiday'])['purchase_amount'].sum().reset_index()\n",
    "df_new = df_new.groupby('card_id')['purchase_amount'].max().reset_index().rename(columns={'purchase_amount':'new_holiday_purchase_Max'})\n",
    "\n",
    "df_temp = pd.merge(df_hist,df_new,on='card_id',how='left')\n",
    "df_temp['new/hist_holiday_purchase_Max_ratio'] = df_temp['new_holiday_purchase_Max']/df_temp['hist_holiday_purchase_Max']\n",
    "df_temp.to_csv('./datasets/feature2/df_new_hist_holiday_purchase_Max_ratio.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merchant_id\n"
     ]
    }
   ],
   "source": [
    "#new/hist \n",
    "for col in ['merchant_id','merchant_category_id','city_id','subsector_id']:\n",
    "    print(col)\n",
    "    df_hist_temp = df_hist_transactions.groupby('card_id')[col].unique().apply(lambda x:len(x)).reset_index().rename(columns={col:'hist_%s_counts'%col})\n",
    "    df_new_temp = df_new_transactions.groupby('card_id')[col].unique().apply(lambda x:len(x)).reset_index().rename(columns={col:'new_%s_counts'%col})\n",
    "    df_temp = pd.merge(df_hist_temp,df_new_temp,on='card_id',how='left')\n",
    "    df_temp['new/hist_%s_counts_ratio'%col] = df_temp['new_%s_counts'%col]/df_temp['hist_%s_counts'%col]\n",
    "    df_temp.drop(columns=['hist_%s_counts'%col,'new_%s_counts'%col],inplace=True)\n",
    "    df_temp.fillna(0,inplace=True)\n",
    "    df_temp.to_csv('./datasets/feature2/df_new_hist_%s_counts_ratio.csv'%col,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['installments','authorized_flag']:\n",
    "    df_hist_temp = df_hist_transactions.groupby('card_id')[col].sum().reset_index().rename(columns={col:'hist_%s_sum'%col})\n",
    "    df_new_temp = df_new_transactions.groupby('card_id')[col].sum().reset_index().rename(columns={col:'new_%s_sum'%col})\n",
    "    df_temp = pd.merge(df_hist_temp,df_new_temp,on='card_id',how='left')\n",
    "    df_temp['new/hist_%s_sum_ratio'%col] = df_temp['new_%s_sum'%col]/df_temp['hist_%s_sum'%col]\n",
    "    df_temp.drop(columns=['hist_%s_sum'%col,'new_%s_sum'%col],inplace=True)\n",
    "    df_temp.fillna(0,inplace=True)\n",
    "    df_temp.to_csv('./datasets/feature2/df_new_hist_%s_sum_ratio.csv'%col,index=False)\n",
    "    \n",
    "del df_hist_temp,df_new_temp,df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist = df_hist_transactions.groupby(['card_id','merchant_category_id'])['purchase_amount'].mean().reset_index()\n",
    "df_hist = df_hist.groupby('card_id')['purchase_amount'].max().reset_index().rename(columns={'purchase_amount':'hist_card_and_merchant_purchase_mean'})\n",
    "df_new = df_new_transactions.groupby(['card_id','merchant_id'])['purchase_amount'].mean().reset_index()\n",
    "df_new = df_new.groupby('card_id')['purchase_amount'].max().reset_index().rename(columns={'purchase_amount':'new_card_and_merchant_purchase_mean'})\n",
    "df_temp = pd.merge(df_hist,df_new,on='card_id',how='left')\n",
    "df_temp['new/hist_card_and_merchant_category_id_purchase_mean_raio'] = df_temp['new_card_and_merchant_purchase_mean']/df_temp['hist_card_and_merchant_purchase_mean']\n",
    "df_temp.drop(columns=['hist_card_and_merchant_purchase_mean','new_card_and_merchant_purchase_mean'],inplace=True)\n",
    "df_temp.fillna(0,inplace=True)\n",
    "df_temp.to_csv('./datasets/feature2/df_new_and_merchant_category_id_purchase_mean_ratio.csv',index=False)\n",
    "\n",
    "df_hist = df_hist_transactions.groupby(['card_id','merchant_category_id'])['purchase_amount'].mean().reset_index()\n",
    "df_hist = df_hist.groupby('card_id')['purchase_amount'].min().reset_index().rename(columns={'purchase_amount':'hist_card_and_merchant_purchase_mean'})\n",
    "df_new = df_new_transactions.groupby(['card_id','merchant_id'])['purchase_amount'].mean().reset_index()\n",
    "df_new = df_new.groupby('card_id')['purchase_amount'].min().reset_index().rename(columns={'purchase_amount':'new_card_and_merchant_purchase_mean'})\n",
    "df_temp = pd.merge(df_hist,df_new,on='card_id',how='left')\n",
    "df_temp['new/hist_card_and_merchant_category_id_purchase_min_raio'] = df_temp['new_card_and_merchant_purchase_mean']/df_temp['hist_card_and_merchant_purchase_mean']\n",
    "df_temp.drop(columns=['hist_card_and_merchant_purchase_mean','new_card_and_merchant_purchase_mean'],inplace=True)\n",
    "df_temp.fillna(0,inplace=True)\n",
    "df_temp.to_csv('./datasets/feature2/df_new_and_merchant_category_id_purchase_min_ratio.csv',index=False)\n",
    "\n",
    "df_hist = df_hist_transactions.groupby(['card_id','merchant_category_id'])['purchase_amount'].mean().reset_index()\n",
    "df_hist = df_hist.groupby('card_id')['purchase_amount'].median().reset_index().rename(columns={'purchase_amount':'hist_card_and_merchant_purchase_mean'})\n",
    "df_new = df_new_transactions.groupby(['card_id','merchant_id'])['purchase_amount'].mean().reset_index()\n",
    "df_new = df_new.groupby('card_id')['purchase_amount'].median().reset_index().rename(columns={'purchase_amount':'new_card_and_merchant_purchase_mean'})\n",
    "df_temp = pd.merge(df_hist,df_new,on='card_id',how='left')\n",
    "df_temp['new/hist_card_and_merchant_category_id_purchase_median_raio'] = df_temp['new_card_and_merchant_purchase_mean']/df_temp['hist_card_and_merchant_purchase_mean']\n",
    "df_temp.drop(columns=['hist_card_and_merchant_purchase_mean','new_card_and_merchant_purchase_mean'],inplace=True)\n",
    "df_temp.fillna(0,inplace=True)\n",
    "df_temp.to_csv('./datasets/feature2/df_new_and_merchant_category_id_purchase_median_ratio.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new/hist (card,merchant) ratio\n",
    "df_hist = df_hist_transactions.groupby(['card_id','merchant_id'])['purchase_amount'].mean().reset_index()\n",
    "df_hist = df_hist.groupby('card_id')['purchase_amount'].max().reset_index().rename(columns={'purchase_amount':'hist_card_and_merchant_purchase_mean'})\n",
    "df_new = df_new_transactions.groupby(['card_id','merchant_id'])['purchase_amount'].mean().reset_index()\n",
    "df_new = df_new.groupby('card_id')['purchase_amount'].max().reset_index().rename(columns={'purchase_amount':'new_card_and_merchant_purchase_mean'})\n",
    "df_temp = pd.merge(df_hist,df_new,on='card_id',how='left')\n",
    "df_temp['new/hist_card_and_merchant_purchase_mean_raio'] = df_temp['new_card_and_merchant_purchase_mean']/df_temp['hist_card_and_merchant_purchase_mean']\n",
    "df_temp.drop(columns=['hist_card_and_merchant_purchase_mean','new_card_and_merchant_purchase_mean'],inplace=True)\n",
    "df_temp.fillna(0,inplace=True)\n",
    "df_temp.to_csv('./datasets/feature2/df_new_and_merchant_purchase_mean_ratio.csv',index=False)\n",
    "\n",
    "\n",
    "df_hist = df_hist_transactions.groupby(['card_id','merchant_id'])['purchase_amount'].mean().reset_index()\n",
    "df_hist = df_hist.groupby('card_id')['purchase_amount'].min().reset_index().rename(columns={'purchase_amount':'hist_card_and_merchant_purchase_mean'})\n",
    "df_new = df_new_transactions.groupby(['card_id','merchant_id'])['purchase_amount'].mean().reset_index()\n",
    "df_new = df_new.groupby('card_id')['purchase_amount'].min().reset_index().rename(columns={'purchase_amount':'new_card_and_merchant_purchase_mean'})\n",
    "df_temp = pd.merge(df_hist,df_new,on='card_id',how='left')\n",
    "df_temp['new/hist_card_and_merchant_purchase_min_raio'] = df_temp['new_card_and_merchant_purchase_mean']/df_temp['hist_card_and_merchant_purchase_mean']\n",
    "df_temp.drop(columns=['hist_card_and_merchant_purchase_mean','new_card_and_merchant_purchase_mean'],inplace=True)\n",
    "df_temp.fillna(0,inplace=True)\n",
    "df_temp.to_csv('./datasets/feature2/df_new_and_merchant_purchase_min_ratio.csv',index=False)\n",
    "\n",
    "\n",
    "df_hist = df_hist_transactions.groupby(['card_id','merchant_id'])['purchase_amount'].mean().reset_index()\n",
    "df_hist = df_hist.groupby('card_id')['purchase_amount'].median().reset_index().rename(columns={'purchase_amount':'hist_card_and_merchant_purchase_mean'})\n",
    "df_new = df_new_transactions.groupby(['card_id','merchant_id'])['purchase_amount'].mean().reset_index()\n",
    "df_new = df_new.groupby('card_id')['purchase_amount'].median().reset_index().rename(columns={'purchase_amount':'new_card_and_merchant_purchase_mean'})\n",
    "df_temp = pd.merge(df_hist,df_new,on='card_id',how='left')\n",
    "df_temp['new/hist_card_and_merchant_purchase_median_raio'] = df_temp['new_card_and_merchant_purchase_mean']/df_temp['hist_card_and_merchant_purchase_mean']\n",
    "df_temp.drop(columns=['hist_card_and_merchant_purchase_mean','new_card_and_merchant_purchase_mean'],inplace=True)\n",
    "df_temp.fillna(0,inplace=True)\n",
    "df_temp.to_csv('./datasets/feature2/df_new_and_merchant_purchase_median_ratio.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new/hist ratio\n",
    "month_lag = [0,-1,-2,-3,-4,-13]\n",
    "for lag in month_lag:\n",
    "    df_feature = df_hist_transactions[df_hist_transactions.month_lag>=lag]\n",
    "    df_hist_temp = df_feature.groupby('card_id')['purchase_amount'].sum().reset_index().rename(columns={'purchase_amount':'hist_purchase_amount_sum'})\n",
    "    df_new_temp = df_new_transactions.groupby('card_id')['purchase_amount'].sum().reset_index().rename(columns={'purchase_amount':'new_purchase_amount_sum'})\n",
    "    df_temp = pd.merge(df_hist_temp,df_new_temp,on='card_id',how='left')\n",
    "    df_temp['new/hist_purchase_amount_sum_ratio_%s'%lag] = df_temp['new_purchase_amount_sum']/df_temp['hist_purchase_amount_sum']\n",
    "    df_temp.drop(columns=['hist_purchase_amount_sum','new_purchase_amount_sum'],inplace=True)\n",
    "    df_data = df_data.merge(df_temp,on='card_id',how='left')\n",
    "    df_data['new/hist_purchase_amount_sum_ratio_%s'%lag].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#不同分期付款购买的金额\n",
    "for flag,df_features in zip(['hist','new'],[df_hist_transactions,df_new_transactions]):\n",
    "    print(\".................%s......................\"%flag)\n",
    "    df_features['install_flag'] = (df_features['installments']>0).astype(np.int)\n",
    "    df_temp = df_features.groupby(['card_id','install_flag'])['purchase_amount'].sum().reset_index()\n",
    "    df_temp = df_temp.pivot(index='card_id',columns='install_flag',values='purchase_amount')\n",
    "    df_temp.columns.name=None\n",
    "    df_temp.columns = ['%s_installments_0'%flag,'%s_installments_1'%flag]\n",
    "    df_temp.reset_index(inplace=True)\n",
    "    df_temp.fillna(0,inplace=True)\n",
    "    df_temp['purchase_amount'] = df_temp['%s_installments_0'%flag] + df_temp['%s_installments_1'%flag]\n",
    "    df_temp['%s_purchase_install_0_ratio'%flag] = df_temp['%s_installments_0'%flag]/df_temp['purchase_amount']\n",
    "    df_temp['%s_purchase_install_1_ratio'%flag] = df_temp['%s_installments_1'%flag]/df_temp['purchase_amount']\n",
    "    df_temp.drop(columns=['purchase_amount'],inplace=True)\n",
    "\n",
    "    df_data = df_data.merge(df_temp,on='card_id',how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#不同分期等级购买的金额\n",
    "for flag,df_features in zip(['hist','new'],[df_hist_transactions,df_new_transactions]):\n",
    "    print(\".................%s......................\"%flag)\n",
    "    df_temp = df_features.groupby(['card_id','category_3'])['purchase_amount'].sum().reset_index()\n",
    "    df_temp = df_temp.pivot(index='card_id',columns='category_3',values='purchase_amount')\n",
    "    df_temp.columns.name=None\n",
    "    cols = []\n",
    "    for col in df_temp.columns:\n",
    "        cols.append('%s_category_3_'%flag + np.str(col))\n",
    "    df_temp.columns = cols\n",
    "    df_temp.fillna(0,inplace=True)\n",
    "    df_temp['purchase_amount'] = 0\n",
    "    for col in cols:\n",
    "        df_temp['purchase_amount'] += df_temp[col]\n",
    "    for col in cols:\n",
    "        df_temp[col+'_ratio'] = df_temp[col]/df_temp['purchase_amount']\n",
    "    df_temp.reset_index(inplace=True)\n",
    "    df_temp.drop(columns=['purchase_amount'],inplace=True)\n",
    "    df_data = df_data.merge(df_temp,on='card_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#不同category_1购买的金额\n",
    "for flag,df_features in zip(['hist','new'],[df_hist_transactions,df_new_transactions]):\n",
    "    print(\".................%s......................\"%flag)\n",
    "    df_temp = df_features.groupby(['card_id','category_1'])['purchase_amount'].sum().reset_index()\n",
    "    df_temp = df_temp.pivot(index='card_id',columns='category_1',values='purchase_amount')\n",
    "    df_temp.columns.name=None\n",
    "    cols = []\n",
    "    for col in df_temp.columns:\n",
    "        cols.append('%s_category_1_'%flag + np.str(col))\n",
    "    df_temp.columns = cols\n",
    "    df_temp['purchase_amount'] = 0\n",
    "    df_temp.fillna(0,inplace=True)\n",
    "    for col in cols:\n",
    "        df_temp['purchase_amount']+=df_temp[col]\n",
    "    for col in cols:\n",
    "        df_temp[col+'_ratio'] = df_temp[col]/df_temp['purchase_amount']\n",
    "        \n",
    "    df_temp.reset_index(inplace=True)\n",
    "    df_temp.drop(columns=['purchase_amount'],inplace=True)\n",
    "\n",
    "    df_data = df_data.merge(df_temp,on='card_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#不同category_2购买的金额\n",
    "for flag,df_features in zip(['hist','new'],[df_hist_transactions,df_new_transactions]):\n",
    "    print(\".................%s......................\"%flag)\n",
    "    df_temp = df_features.groupby(['card_id','category_2'])['purchase_amount'].sum().reset_index()\n",
    "    df_temp = df_temp.pivot(index='card_id',columns='category_2',values='purchase_amount')\n",
    "    df_temp.columns.name=None\n",
    "    cols = []\n",
    "    for col in df_temp.columns:\n",
    "        cols.append('%s_category_2_'%flag + np.str(col))\n",
    "    df_temp.columns = cols\n",
    "    df_temp['purchase_amount'] = 0\n",
    "    df_temp.fillna(0,inplace=True)\n",
    "    for col in cols:\n",
    "        df_temp['purchase_amount']+=df_temp[col]\n",
    "    for col in cols:\n",
    "        df_temp[col+'_ratio'] = df_temp[col]/df_temp['purchase_amount']\n",
    "        \n",
    "    df_temp.reset_index(inplace=True)\n",
    "    df_temp.drop(columns=['purchase_amount'],inplace=True)\n",
    "\n",
    "    df_data = df_data.merge(df_temp,on='card_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#不同subsector_id购买的金额\n",
    "for flag,df_features in zip(['hist','new'],[df_hist_transactions,df_new_transactions]):\n",
    "    print(\".................%s......................\"%flag)\n",
    "    df_temp = df_features.groupby(['card_id','subsector_id'])['purchase_amount'].sum().reset_index()\n",
    "    df_temp = df_temp.pivot(index='card_id',columns='subsector_id',values='purchase_amount')\n",
    "    df_temp.columns.name=None\n",
    "    cols = []\n",
    "    for col in df_temp.columns:\n",
    "        cols.append('%s_subsector_id_'%flag + np.str(col))\n",
    "    df_temp.columns = cols\n",
    "    df_temp['purchase_amount'] = 0\n",
    "    df_temp.fillna(0,inplace=True)\n",
    "    for col in cols:\n",
    "        df_temp['purchase_amount']+=df_temp[col]\n",
    "    for col in cols:\n",
    "        df_temp[col+'_ratio'] = df_temp[col]/df_temp['purchase_amount']\n",
    "        \n",
    "    df_temp.reset_index(inplace=True)\n",
    "    df_temp.drop(columns=['purchase_amount'],inplace=True)\n",
    "\n",
    "    df_data = df_data.merge(df_temp,on='card_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merchant = pd.read_csv('./datasets/merchants.csv',usecols=['category_4','merchant_id'])\n",
    "df_transactions = df_transactions.merge(df_merchant,on='merchant_id',how='left')\n",
    "df_hist_transactions = df_transactions[df_transactions.month_lag<=0]\n",
    "df_new_transactions = df_transactions[df_transactions.month_lag>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#不同category_4购买的金额\n",
    "for flag,df_features in zip(['hist','new'],[df_hist_transactions,df_new_transactions]):\n",
    "    print(\".................%s......................\"%flag)\n",
    "    df_temp = df_features.groupby(['card_id','category_4'])['purchase_amount'].sum().reset_index()\n",
    "    df_temp = df_temp.pivot(index='card_id',columns='category_4',values='purchase_amount')\n",
    "    df_temp.columns.name=None\n",
    "    cols = []\n",
    "    for col in df_temp.columns:\n",
    "        cols.append('%s_category_4_'%flag + np.str(col))\n",
    "    df_temp.columns = cols\n",
    "    df_temp['purchase_amount'] = 0\n",
    "    df_temp.fillna(0,inplace=True)\n",
    "    for col in cols:\n",
    "        df_temp['purchase_amount']+=df_temp[col]\n",
    "    for col in cols:\n",
    "        df_temp[col+'_ratio'] = df_temp[col]/df_temp['purchase_amount']\n",
    "        \n",
    "    df_temp.reset_index(inplace=True)\n",
    "    df_temp.drop(columns=['purchase_amount'],inplace=True)\n",
    "\n",
    "    df_data = df_data.merge(df_temp,on='card_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merchant = pd.read_csv('./datasets/merchants.csv',usecols=['merchant_group_id','merchant_id'])\n",
    "df_transactions = df_transactions.merge(df_merchant,on='merchant_id',how='left')\n",
    "df_hist_transactions = df_transactions[df_transactions.month_lag<=0]\n",
    "df_new_transactions = df_transactions[df_transactions.month_lag>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取词向量\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "def getWord2Vec(df_temp=None,fea=None,embedding_size=10,name=None):  \n",
    "    corpus = df_temp[fea].values\n",
    "    model = Word2Vec(corpus, size=embedding_size, window=3, min_count=1, workers=16)\n",
    "    Q_VEC = np.zeros((len(corpus),embedding_size))\n",
    "    cols = []\n",
    "    for i in range(embedding_size):\n",
    "        cols.append(name+'_vec_%s'%i)\n",
    "    for i in range(df_temp.shape[0]):\n",
    "        Q_VEC[i,:] = np.mean(model.wv[corpus[i]],axis=0)\n",
    "    df_vec = pd.DataFrame(data=Q_VEC,columns=cols)\n",
    "    df_vec['card_id'] = df_temp['card_id'].values\n",
    "    return df_vec\n",
    "#购买次数序列构成的embedding\n",
    "df_temp = df_transactions.groupby(['card_id','month'])['purchase_amount'].count().reset_index()\n",
    "df_temp['purchase_amount'] = df_temp['purchase_amount'].astype(np.str)\n",
    "df_temp = df_temp.groupby(['card_id'])['purchase_amount'].apply(lambda series:list(series)).reset_index()\n",
    "df_temp.rename(columns={'purchase_amount':'purchase_sequence'},inplace=True)\n",
    "df_vec = getWord2Vec(df_temp,fea='purchase_sequence',name='purchase_sequence')\n",
    "\n",
    "df_data = df_data.merge(df_vec,on='card_id',how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................hist......................\n",
      ".................new......................\n"
     ]
    }
   ],
   "source": [
    "for flag,df_features in zip(['hist','new'],[df_hist_transactions,df_new_transactions]):\n",
    "    print(\".................%s......................\"%flag)\n",
    "    df_temp = df_features.groupby(['card_id','month'])['merchant_group_id'].count().reset_index()\n",
    "    df_temp['merchant_group_id'] = df_temp['merchant_group_id'].astype(np.str)\n",
    "    df_temp = df_temp.groupby(['card_id'])['merchant_group_id'].apply(lambda series:list(series)).reset_index()\n",
    "    df_temp.rename(columns={'merchant_group_id':'merchant_group_id_sequence'},inplace=True)\n",
    "    df_vec = getWord2Vec(df_temp,fea='merchant_group_id_sequence',name='%s_merchant_group_id_sequence'%flag)\n",
    "    df_data = df_data.merge(df_vec,on='card_id',how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 864.63 MB\n",
      "Memory usage after optimization is: 710.64 MB\n",
      "Decreased by 17.8%\n"
     ]
    }
   ],
   "source": [
    "df_data = reduce_mem_usage(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>is_in_new_monthlag1</th>\n",
       "      <th>is_in_new_monthlag2</th>\n",
       "      <th>is_test</th>\n",
       "      <th>target</th>\n",
       "      <th>feature_1_1</th>\n",
       "      <th>feature_1_2</th>\n",
       "      <th>feature_1_3</th>\n",
       "      <th>feature_1_4</th>\n",
       "      <th>...</th>\n",
       "      <th>new_merchant_group_id_sequence_vec_0</th>\n",
       "      <th>new_merchant_group_id_sequence_vec_1</th>\n",
       "      <th>new_merchant_group_id_sequence_vec_2</th>\n",
       "      <th>new_merchant_group_id_sequence_vec_3</th>\n",
       "      <th>new_merchant_group_id_sequence_vec_4</th>\n",
       "      <th>new_merchant_group_id_sequence_vec_5</th>\n",
       "      <th>new_merchant_group_id_sequence_vec_6</th>\n",
       "      <th>new_merchant_group_id_sequence_vec_7</th>\n",
       "      <th>new_merchant_group_id_sequence_vec_8</th>\n",
       "      <th>new_merchant_group_id_sequence_vec_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>2017-06</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.820312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345947</td>\n",
       "      <td>-0.062195</td>\n",
       "      <td>0.024551</td>\n",
       "      <td>-0.624512</td>\n",
       "      <td>0.142944</td>\n",
       "      <td>0.300781</td>\n",
       "      <td>0.077881</td>\n",
       "      <td>-0.437988</td>\n",
       "      <td>-0.202759</td>\n",
       "      <td>-0.130493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392822</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.911133</td>\n",
       "      <td>0.741211</td>\n",
       "      <td>0.072083</td>\n",
       "      <td>-0.093323</td>\n",
       "      <td>-0.099060</td>\n",
       "      <td>-0.074829</td>\n",
       "      <td>-0.267090</td>\n",
       "      <td>-0.425781</td>\n",
       "      <td>-0.154419</td>\n",
       "      <td>0.180054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>2016-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.687988</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.324219</td>\n",
       "      <td>1.047852</td>\n",
       "      <td>0.030182</td>\n",
       "      <td>0.047150</td>\n",
       "      <td>-0.334473</td>\n",
       "      <td>-0.287598</td>\n",
       "      <td>-0.154297</td>\n",
       "      <td>-0.343750</td>\n",
       "      <td>-0.038757</td>\n",
       "      <td>0.212402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>2017-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142456</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891113</td>\n",
       "      <td>0.693359</td>\n",
       "      <td>0.063538</td>\n",
       "      <td>-0.142822</td>\n",
       "      <td>-0.139404</td>\n",
       "      <td>-0.051788</td>\n",
       "      <td>-0.203369</td>\n",
       "      <td>-0.373291</td>\n",
       "      <td>-0.091736</td>\n",
       "      <td>0.136108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159790</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345947</td>\n",
       "      <td>-0.191528</td>\n",
       "      <td>-0.007568</td>\n",
       "      <td>-0.826660</td>\n",
       "      <td>0.118042</td>\n",
       "      <td>0.407715</td>\n",
       "      <td>0.225952</td>\n",
       "      <td>-0.532715</td>\n",
       "      <td>-0.259521</td>\n",
       "      <td>-0.088623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 919 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id first_active_month  is_in_new_monthlag1  \\\n",
       "0  C_ID_92a2005557            2017-06                    1   \n",
       "1  C_ID_3d0044924f            2017-01                    1   \n",
       "2  C_ID_d639edf6cd            2016-08                    0   \n",
       "3  C_ID_186d6a6901            2017-09                    1   \n",
       "4  C_ID_cdbd2c0db2            2017-11                    1   \n",
       "\n",
       "   is_in_new_monthlag2  is_test    target  feature_1_1  feature_1_2  \\\n",
       "0                    1        0 -0.820312            0            0   \n",
       "1                    1        0  0.392822            0            0   \n",
       "2                    1        0  0.687988            0            1   \n",
       "3                    1        0  0.142456            0            0   \n",
       "4                    1        0 -0.159790            1            0   \n",
       "\n",
       "   feature_1_3  feature_1_4                  ...                   \\\n",
       "0            0            0                  ...                    \n",
       "1            0            1                  ...                    \n",
       "2            0            0                  ...                    \n",
       "3            0            1                  ...                    \n",
       "4            0            0                  ...                    \n",
       "\n",
       "   new_merchant_group_id_sequence_vec_0  new_merchant_group_id_sequence_vec_1  \\\n",
       "0                              0.345947                             -0.062195   \n",
       "1                              0.911133                              0.741211   \n",
       "2                              1.324219                              1.047852   \n",
       "3                              0.891113                              0.693359   \n",
       "4                              0.345947                             -0.191528   \n",
       "\n",
       "   new_merchant_group_id_sequence_vec_2  new_merchant_group_id_sequence_vec_3  \\\n",
       "0                              0.024551                             -0.624512   \n",
       "1                              0.072083                             -0.093323   \n",
       "2                              0.030182                              0.047150   \n",
       "3                              0.063538                             -0.142822   \n",
       "4                             -0.007568                             -0.826660   \n",
       "\n",
       "   new_merchant_group_id_sequence_vec_4  new_merchant_group_id_sequence_vec_5  \\\n",
       "0                              0.142944                              0.300781   \n",
       "1                             -0.099060                             -0.074829   \n",
       "2                             -0.334473                             -0.287598   \n",
       "3                             -0.139404                             -0.051788   \n",
       "4                              0.118042                              0.407715   \n",
       "\n",
       "   new_merchant_group_id_sequence_vec_6  new_merchant_group_id_sequence_vec_7  \\\n",
       "0                              0.077881                             -0.437988   \n",
       "1                             -0.267090                             -0.425781   \n",
       "2                             -0.154297                             -0.343750   \n",
       "3                             -0.203369                             -0.373291   \n",
       "4                              0.225952                             -0.532715   \n",
       "\n",
       "   new_merchant_group_id_sequence_vec_8  new_merchant_group_id_sequence_vec_9  \n",
       "0                             -0.202759                             -0.130493  \n",
       "1                             -0.154419                              0.180054  \n",
       "2                             -0.038757                              0.212402  \n",
       "3                             -0.091736                              0.136108  \n",
       "4                             -0.259521                             -0.088623  \n",
       "\n",
       "[5 rows x 919 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_data.to_csv('./datasets/df_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##additional features\n",
    "cols = ['card_id','first_active_month','feature_1','feature_2','feature_3']\n",
    "df_train = pd.read_csv('./datasets/train.csv',usecols=cols+['target'])\n",
    "df_test = pd.read_csv('./datasets/test.csv',usecols=cols)\n",
    "df = pd.concat([df_train,df_test])\n",
    "df['first_active_month'] = pd.to_datetime(df['first_active_month'])\n",
    "df['quarter'] = df['first_active_month'].dt.quarter\n",
    "df['elapsed_time'] = (datetime.datetime.today() - df['first_active_month']).dt.days\n",
    "\n",
    "df['days_feature1'] = df['elapsed_time'] * df['feature_1']\n",
    "df['days_feature2'] = df['elapsed_time'] * df['feature_2']\n",
    "df['days_feature3'] = df['elapsed_time'] * df['feature_3']\n",
    "\n",
    "df['days_feature1_ratio'] = df['feature_1'] / df['elapsed_time']\n",
    "df['days_feature2_ratio'] = df['feature_2'] / df['elapsed_time']\n",
    "df['days_feature3_ratio'] = df['feature_3'] / df['elapsed_time']\n",
    "\n",
    "df['feature_sum'] = df['feature_1'] + df['feature_2'] + df['feature_3']\n",
    "df['feature_mean'] = df['feature_sum']/3\n",
    "df['feature_max'] = df[['feature_1', 'feature_2', 'feature_3']].max(axis=1)\n",
    "df['feature_min'] = df[['feature_1', 'feature_2', 'feature_3']].min(axis=1)\n",
    "df['feature_var'] = df[['feature_1', 'feature_2', 'feature_3']].std(axis=1)\n",
    "\n",
    "df.drop(columns=['first_active_month','target'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./datasets/df_train_test_features_additional.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......historical......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e804deac02aa431ab98ff2d8688a10dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory usage after optimization is: 4358.90 MB\n",
      "Decreased by 72.7%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809a95c682ac487abbfb9e0ae2f2b855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory usage after optimization is: 157.40 MB\n",
      "Decreased by 34.2%\n",
      "....new_merchant.......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2550efdf230347f294ffd4f3ed8e3645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory usage after optimization is: 275.20 MB\n",
      "Decreased by 74.5%\n",
      "Memory usage after optimization is: 130.82 MB\n",
      "Decreased by 38.6%\n",
      "......additional........\n",
      "...done.....\n"
     ]
    }
   ],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df\n",
    "def historical_transactions(num_rows=None):\n",
    "    print('......historical......')\n",
    "    # load csv\n",
    "    hist_df = pd.read_csv('./datasets/historical_transactions.csv', nrows=num_rows)\n",
    "\n",
    "    # fillna\n",
    "    hist_df['category_2'].fillna(1.0,inplace=True)\n",
    "    hist_df['category_3'].fillna('A',inplace=True)\n",
    "    hist_df['merchant_id'].fillna('M_ID_00a6ca8a8a',inplace=True)\n",
    "    hist_df['installments'].replace(-1, np.nan,inplace=True)\n",
    "    hist_df['installments'].replace(999, np.nan,inplace=True)\n",
    "\n",
    "    # trim\n",
    "    hist_df['purchase_amount'] = hist_df['purchase_amount'].apply(lambda x: min(x, 0.8))\n",
    "\n",
    "    # Y/N to 1/0\n",
    "    hist_df['authorized_flag'] = hist_df['authorized_flag'].map({'Y': 1, 'N': 0}).astype(int)\n",
    "    hist_df['category_1'] = hist_df['category_1'].map({'Y': 1, 'N': 0}).astype(int)\n",
    "    hist_df['category_3'] = hist_df['category_3'].map({'A':0, 'B':1, 'C':2})\n",
    "    #交互特征\n",
    "    hist_df['city_C1'] = ((hist_df['city_id']< 0) + 0).astype(np.str) + '_' + hist_df['category_1'].astype(np.str)\n",
    "    hist_df['C2_state'] = hist_df['category_2'].astype(np.str) + '_' + hist_df['state_id'].astype(np.str) \n",
    "    hist_df['C2_state_subsector'] = hist_df['category_2'].astype(np.str) + '_' + hist_df['state_id'].astype(np.str) + '_' + hist_df['subsector_id'].astype(np.str)\n",
    "    hist_df['subsector_city'] = hist_df['subsector_id'].astype(np.str) + '_' + ((hist_df['city_id'] < 0) + 0).astype(np.str)\n",
    "    hist_df['auth_C3'] = hist_df['authorized_flag'].astype(np.str) + '_' + hist_df['category_3'].astype(np.str)\n",
    "\n",
    "    cateCols = ['city_C1','C2_state','C2_state_subsector','subsector_city','auth_C3']\n",
    "    hist_df = label_encoding(hist_df,cateCols)\n",
    "\n",
    "    # datetime features\n",
    "    hist_df['purchase_date'] = pd.to_datetime(hist_df['purchase_date'])\n",
    "    hist_df['month'] = hist_df['purchase_date'].dt.month\n",
    "    hist_df['day'] = hist_df['purchase_date'].dt.day\n",
    "    hist_df['hour'] = hist_df['purchase_date'].dt.hour\n",
    "    hist_df['weekofyear'] = hist_df['purchase_date'].dt.weekofyear\n",
    "    hist_df['weekday'] = hist_df['purchase_date'].dt.weekday\n",
    "    hist_df['weekend'] = (hist_df['purchase_date'].dt.weekday >=5).astype(int)\n",
    "\n",
    "\n",
    "    #Christmas : December 25 2017\n",
    "    hist_df['Christmas_Day_2017']=(pd.to_datetime('2017-12-25')-hist_df['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "    #Mothers Day: May 14 2017\n",
    "    hist_df['Mothers_Day_2017']=(pd.to_datetime('2017-06-04')-hist_df['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "    #fathers day: August 13 2017\n",
    "    hist_df['fathers_day_2017']=(pd.to_datetime('2017-08-13')-hist_df['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "    #Childrens day: October 12 2017\n",
    "    hist_df['Children_day_2017']=(pd.to_datetime('2017-10-12')-hist_df['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "    #Valentine's Day : 12th June, 2017\n",
    "    hist_df['Valentine_Day_2017']=(pd.to_datetime('2017-06-12')-hist_df['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "    #Black Friday : 24th November 2017\n",
    "    hist_df['Black_Friday_2017']=(pd.to_datetime('2017-11-24') - hist_df['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "\n",
    "    #2018\n",
    "    #Mothers Day: May 13 2018\n",
    "    hist_df['Mothers_Day_2018']=(pd.to_datetime('2018-05-13')-hist_df['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "\n",
    "    hist_df['month_diff'] = ((datetime.datetime.today() - hist_df['purchase_date']).dt.days)//30\n",
    "    hist_df['month_diff'] += hist_df['month_lag']\n",
    "\n",
    "    # additional features\n",
    "    df_temp = hist_df.groupby(['card_id','merchant_id'])['purchase_amount'].count().reset_index()\n",
    "    df_temp.rename(columns={'purchase_amount':'card_merchant_counts_totals'},inplace=True)\n",
    "    hist_df = hist_df.merge(df_temp,on=['card_id','merchant_id'],how='left')\n",
    "    \n",
    "    hist_df['duration'] = hist_df['purchase_amount']*hist_df['month_diff']\n",
    "    hist_df['duration/Visitcounts'] = hist_df['duration']/hist_df['card_merchant_counts_totals']\n",
    "    hist_df['duration/sqrtVisits'] = hist_df['duration']/np.sqrt(hist_df['card_merchant_counts_totals'])\n",
    "    hist_df['durations_log1p_visits'] = hist_df['duration']*np.log1p(hist_df['card_merchant_counts_totals'])\n",
    "   \n",
    "    hist_df['purchase/Visitcounts'] = hist_df['purchase_amount']/hist_df['card_merchant_counts_totals']\n",
    "    hist_df['purchase/sqrtVisits'] = hist_df['purchase_amount']/np.sqrt(hist_df['card_merchant_counts_totals'])\n",
    "    hist_df['purchase_log1p_visits'] = hist_df['purchase_amount']*np.log1p(hist_df['card_merchant_counts_totals'])\n",
    "   \n",
    "    hist_df['purchase_amount_installments'] = hist_df['purchase_amount'] * hist_df['installments']\n",
    "    hist_df['price'] = hist_df['purchase_amount'] / hist_df['installments']\n",
    "    hist_df['purchase_amount_authorized_flag'] = hist_df['purchase_amount'] * hist_df['authorized_flag']\n",
    "    hist_df['purchase_amount_category_1'] = hist_df['purchase_amount'] * hist_df['category_1']\n",
    "    hist_df['purchase_amount_category_2'] = hist_df['purchase_amount'] * hist_df['category_2']\n",
    "    \n",
    "    hist_df['amount_month_ratio'] = hist_df['purchase_amount']/hist_df['month_diff']\n",
    "    \n",
    "    hist_df['purchase_lag'] = hist_df['purchase_amount']*hist_df['month_lag']\n",
    "    hist_df['purchase/month_lag'] = hist_df['purchase_amount']/hist_df['month_lag']\n",
    "    \n",
    "    hist_df['installments_month_diff'] = hist_df['installments']*hist_df['month_diff']\n",
    "    hist_df['installments_month_diff_ratio'] = hist_df['installments']/hist_df['month_diff']\n",
    "    \n",
    "    hist_df['purchase_amount_weekend'] = hist_df['purchase_amount']*hist_df['weekend']\n",
    "    \n",
    "    df_temp = hist_df.groupby(['card_id'])['purchase_amount'].count().reset_index()\n",
    "    df_temp.rename(columns={'purchase_amount':'card_visit_counts'},inplace=True)\n",
    "    hist_df = hist_df.merge(df_temp,on='card_id',how='left')\n",
    "    \n",
    "    hist_df['duration/CardVisitcounts'] = hist_df['duration']/hist_df['card_visit_counts']\n",
    "    hist_df['duration/sqrtCardVisits'] = hist_df['duration']/np.sqrt(hist_df['card_visit_counts'])\n",
    "    hist_df['durations_log1p_Card_visits'] = hist_df['duration']*np.log1p(hist_df['card_visit_counts'])\n",
    "   \n",
    "    hist_df['purchase/CardVisitcounts'] = hist_df['purchase_amount']/hist_df['card_visit_counts']\n",
    "    hist_df['purchase/sqrtCardVisits'] = hist_df['purchase_amount']/np.sqrt(hist_df['card_visit_counts'])\n",
    "    hist_df['purchase_log1p_Card_visits'] = hist_df['purchase_amount']*np.log1p(hist_df['card_visit_counts'])\n",
    "\n",
    "    hist_df['month_diff_installments_card_merchant_counts'] = hist_df['month_diff']*hist_df['installments']*hist_df['card_merchant_counts_totals']\n",
    "    hist_df['month_diff_installments_card_merchant_counts_ratio'] = hist_df['month_diff']*hist_df['installments']/hist_df['card_merchant_counts_totals']\n",
    "    \n",
    "    hist_df['month_diff_installments_card_counts'] = hist_df['month_diff']*hist_df['card_visit_counts']*hist_df['installments']\n",
    "    hist_df['month_diff_installments_card_counts_ratio'] = hist_df['month_diff']*hist_df['installments']/hist_df['card_visit_counts']\n",
    "\n",
    "    ##加入month_gap\n",
    "    hist_df['month_gap'] = ((datetime.datetime.today() - hist_df['purchase_date']).dt.days)//30\n",
    "    hist_df['purchase_multi_month_gap'] = hist_df['purchase_amount'] * hist_df['month_gap']\n",
    "    hist_df['purchase_visitcounts_ratio'] = hist_df['purchase_multi_month_gap']/hist_df['card_merchant_counts_totals']\n",
    "    hist_df['purchase_sqrtvisits_ratio'] = hist_df['purchase_multi_month_gap']/hist_df['card_merchant_counts_totals']\n",
    "    hist_df['purchase_log1pvisits_ratio'] = hist_df['purchase_multi_month_gap']/hist_df['card_merchant_counts_totals']\n",
    "    \n",
    "    hist_df['purchase_card_visits_ratio'] = hist_df['purchase_multi_month_gap']/hist_df['card_visit_counts']\n",
    "    hist_df['purchase_sqrt_card_visits_ratio']  = hist_df['purchase_multi_month_gap']/hist_df['card_visit_counts']\n",
    "    hist_df['purchase_log1p_card_visits_ratio'] = hist_df['purchase_multi_month_gap']/hist_df['card_visit_counts']\n",
    "    \n",
    "    # reduce memory usage\n",
    "    hist_df = reduce_mem_usage(hist_df)\n",
    "\n",
    "    col_unique =['subsector_id', 'merchant_id', 'merchant_category_id']\n",
    "    col_seas = ['month', 'hour', 'weekofyear', 'weekday', 'day']\n",
    "\n",
    "    aggs = {}\n",
    "    for col in ['Christmas_Day_2017','Mothers_Day_2017','fathers_day_2017','Children_day_2017','Valentine_Day_2017','Mothers_Day_2018']:\n",
    "        hist_df['purchase_amount_%s'%col] = hist_df['purchase_amount'] * hist_df[col]\n",
    "        aggs[col] = ['min','max','sum','mean','median']\n",
    "        \n",
    "    for col in col_unique:\n",
    "        aggs[col] = ['nunique']\n",
    "\n",
    "    for col in col_seas:\n",
    "        aggs[col] = ['nunique', 'mean', 'min', 'max']\n",
    "\n",
    "    aggs['purchase_amount'] = ['sum','max','min','mean','var','skew']\n",
    "    aggs['installments'] = ['sum','max','mean','var','skew']\n",
    "    aggs['purchase_date'] = ['max','min']\n",
    "    aggs['month_lag'] = ['max','min','mean','var','skew']\n",
    "    aggs['month_diff'] = ['max','min','mean','var','skew']\n",
    "    aggs['authorized_flag'] = ['mean']\n",
    "    aggs['weekend'] = ['mean'] # overwrite\n",
    "    aggs['weekday'] = ['mean'] # overwrite\n",
    "    aggs['day'] = ['nunique', 'mean', 'min'] # overwrite\n",
    "    aggs['category_1'] = ['mean']\n",
    "    aggs['category_2'] = ['mean']\n",
    "    aggs['category_3'] = ['mean']\n",
    "    aggs['card_id'] = ['size','count']\n",
    "    aggs['price'] = ['sum','mean','max','min','var']\n",
    "    aggs['Christmas_Day_2017'] = ['mean']\n",
    "    aggs['Mothers_Day_2017'] = ['mean']\n",
    "    aggs['fathers_day_2017'] = ['mean']\n",
    "    aggs['Children_day_2017'] = ['mean']\n",
    "    aggs['Valentine_Day_2017'] = ['mean']\n",
    "    aggs['Black_Friday_2017'] = ['mean']\n",
    "    aggs['Mothers_Day_2018'] = ['mean']\n",
    "    \n",
    "    aggs['duration']=['mean','min','max']\n",
    "    aggs['amount_month_ratio']=['mean','min','max']\n",
    "    aggs['installments_month_diff'] = ['mean','min','max']\n",
    "    aggs['installments_month_diff_ratio']=['mean','min','max']\n",
    "    aggs['purchase_lag'] = ['mean','min','max','median']\n",
    "    aggs['purchase/month_lag'] = ['mean','min','max','median']\n",
    "    aggs['purchase_amount_weekend'] = ['mean','min','max','median']\n",
    "    aggs['duration/Visitcounts'] = ['mean','sum','min','max','median']\n",
    "    aggs['durations_log1p_visits'] = ['mean','sum','min','max','median']\n",
    "    aggs['duration/sqrtVisits'] = ['mean','sum','min','max','median']\n",
    "    \n",
    "    aggs['purchase/Visitcounts'] = ['mean','sum','min','max','median']\n",
    "    aggs['purchase_log1p_visits'] = ['mean','sum','min','max','median']\n",
    "    aggs['purchase/sqrtVisits'] = ['mean','sum','min','max','median']\n",
    "    \n",
    "    aggs['purchase_amount_installments'] = ['mean','sum','min','max','median']\n",
    "    aggs['purchase_amount_authorized_flag'] = ['mean','sum','min','max','median']\n",
    "    aggs['purchase_amount_category_1'] = ['mean','sum','min','max','median']\n",
    "    aggs['purchase_amount_category_2'] = ['mean','sum','min','max','median']\n",
    "    \n",
    "    aggs['duration/CardVisitcounts'] = ['mean','max','min','median']\n",
    "    aggs['duration/sqrtCardVisits'] = ['mean','max','min','median']\n",
    "    aggs['durations_log1p_Card_visits'] = ['mean','max','min','median']\n",
    "    \n",
    "    aggs['purchase/CardVisitcounts'] = ['mean','max','min','median']\n",
    "    aggs['purchase/sqrtCardVisits'] = ['mean','max','min','median']\n",
    "    aggs['purchase_log1p_Card_visits'] = ['mean','max','min','median'] \n",
    "    \n",
    "    aggs['month_diff_installments_card_merchant_counts'] = ['max','min','mean','median']\n",
    "    aggs['month_diff_installments_card_merchant_counts_ratio'] = ['max','min','mean','median']\n",
    "    aggs['month_diff_installments_card_counts'] = ['max','min','mean','median']\n",
    "    aggs['month_diff_installments_card_counts_ratio'] = ['max','min','mean','median']\n",
    "    \n",
    "    aggs['month_gap'] = ['mean','min','max']\n",
    "    aggs['purchase_multi_month_gap'] = ['mean','max','min','median']\n",
    "    aggs['purchase_visitcounts_ratio'] = ['mean','max','min','median']\n",
    "    aggs['purchase_sqrtvisits_ratio'] = ['mean','max','min','median']\n",
    "    aggs['purchase_log1pvisits_ratio'] = ['mean','max','min','median']\n",
    "    \n",
    "    aggs['purchase_card_visits_ratio'] = ['mean','max','min','median']\n",
    "    aggs['purchase_sqrt_card_visits_ratio'] = ['mean','max','min','median']\n",
    "    aggs['purchase_log1p_card_visits_ratio'] = ['mean','max','min','median']\n",
    "    \n",
    "    cateCols = ['city_C1','C2_state','C2_state_subsector','subsector_city','auth_C3']\n",
    "    hist_df = label_encoding(hist_df,cateCols)\n",
    "    for col in cateCols:\n",
    "        aggs[col] = ['mean']\n",
    "    \n",
    "    for col in cateCols+['category_2','category_3']:\n",
    "        hist_df[col+'_mean'] = hist_df.groupby([col])['purchase_amount'].transform('mean')\n",
    "        hist_df[col+'_min'] = hist_df.groupby([col])['purchase_amount'].transform('min')\n",
    "        hist_df[col+'_max'] = hist_df.groupby([col])['purchase_amount'].transform('max')\n",
    "        hist_df[col+'_sum'] = hist_df.groupby([col])['purchase_amount'].transform('sum')\n",
    "        aggs[col+'_mean'] = ['mean']\n",
    "\n",
    "    hist_df = hist_df.reset_index().groupby('card_id').agg(aggs)\n",
    "\n",
    "    # change column name\n",
    "    hist_df.columns = pd.Index([e[0] + \"_\" + e[1] for e in hist_df.columns.tolist()])\n",
    "    hist_df.columns = ['hist_'+ c for c in hist_df.columns]\n",
    "\n",
    "    hist_df['hist_purchase_date_diff'] = (hist_df['hist_purchase_date_max']-hist_df['hist_purchase_date_min']).dt.days\n",
    "    hist_df['hist_purchase_date_average'] = hist_df['hist_purchase_date_diff']/hist_df['hist_card_id_size']\n",
    "    hist_df['hist_purchase_date_uptonow'] = (datetime.datetime.today()-hist_df['hist_purchase_date_max']).dt.days\n",
    "    hist_df['hist_purchase_date_uptomin'] = (datetime.datetime.today()-hist_df['hist_purchase_date_min']).dt.days\n",
    "\n",
    "    # reduce memory usage\n",
    "    hist_df = reduce_mem_usage(hist_df)\n",
    "\n",
    "    return hist_df\n",
    "    \n",
    "# preprocessing new_merchant_transactions\n",
    "def new_merchant_transactions(num_rows=None):\n",
    "    print('....new_merchant.......')\n",
    "    # load csv\n",
    "    new_merchant_df = pd.read_csv('./datasets/new_merchant_transactions.csv', nrows=num_rows)\n",
    "\n",
    "    # fillna\n",
    "    new_merchant_df['category_2'].fillna(1.0,inplace=True)\n",
    "    new_merchant_df['category_3'].fillna('A',inplace=True)\n",
    "    new_merchant_df['merchant_id'].fillna('M_ID_00a6ca8a8a',inplace=True)\n",
    "    new_merchant_df['installments'].replace(-1, np.nan,inplace=True)\n",
    "    new_merchant_df['installments'].replace(999, np.nan,inplace=True)\n",
    "\n",
    "    # trim\n",
    "    new_merchant_df['purchase_amount'] = new_merchant_df['purchase_amount'].apply(lambda x: min(x, 0.8))\n",
    "\n",
    "    # Y/N to 1/0\n",
    "    new_merchant_df['authorized_flag'] = new_merchant_df['authorized_flag'].map({'Y': 1, 'N': 0}).astype(int)\n",
    "    new_merchant_df['category_1'] = new_merchant_df['category_1'].map({'Y': 1, 'N': 0}).astype(int)\n",
    "    new_merchant_df['category_3'] = new_merchant_df['category_3'].map({'A':0, 'B':1, 'C':2}).astype(int)\n",
    "\n",
    "    #交互特征\n",
    "    new_merchant_df['city_C1'] = ((new_merchant_df['city_id']< 0) + 0).astype(np.str) + '_' + new_merchant_df['category_1'].astype(np.str)\n",
    "    new_merchant_df['C2_state'] = new_merchant_df['category_2'].astype(np.str) + '_' + new_merchant_df['state_id'].astype(np.str) \n",
    "    new_merchant_df['C2_state_subsector'] = new_merchant_df['category_2'].astype(np.str) + '_' + new_merchant_df['state_id'].astype(np.str) + '_' + new_merchant_df['subsector_id'].astype(np.str)\n",
    "    new_merchant_df['subsector_city'] = new_merchant_df['subsector_id'].astype(np.str) + '_' + ((new_merchant_df['city_id'] < 0) + 0).astype(np.str)\n",
    "    new_merchant_df['auth_C3'] = new_merchant_df['authorized_flag'].astype(np.str) + '_' + new_merchant_df['category_3'].astype(np.str)\n",
    "\n",
    "    cateCols = ['city_C1','C2_state','C2_state_subsector','subsector_city','auth_C3']\n",
    "    new_merchant_df = label_encoding(new_merchant_df,cateCols)\n",
    "    \n",
    "    # datetime features\n",
    "    new_merchant_df['purchase_date'] = pd.to_datetime(new_merchant_df['purchase_date'])\n",
    "    new_merchant_df['month'] = new_merchant_df['purchase_date'].dt.month\n",
    "    new_merchant_df['day'] = new_merchant_df['purchase_date'].dt.day\n",
    "    new_merchant_df['hour'] = new_merchant_df['purchase_date'].dt.hour\n",
    "    new_merchant_df['weekofyear'] = new_merchant_df['purchase_date'].dt.weekofyear\n",
    "    new_merchant_df['weekday'] = new_merchant_df['purchase_date'].dt.weekday\n",
    "    new_merchant_df['weekend'] = (new_merchant_df['purchase_date'].dt.weekday >=5).astype(int)\n",
    "\n",
    "    #fathers day: August 13 2017\n",
    "    new_merchant_df['fathers_day_2017']=(pd.to_datetime('2017-08-13')-new_merchant_df['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "    #Valentine's Day : 12th June, 2017\n",
    "    new_merchant_df['Valentine_Day_2017']=(pd.to_datetime('2017-06-12')-new_merchant_df['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "    #Christmas : December 25 2017\n",
    "    new_merchant_df['Christmas_Day_2017']=(pd.to_datetime('2017-12-25')-new_merchant_df['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "    #Childrens day: October 12 2017\n",
    "    new_merchant_df['Children_day_2017']=(pd.to_datetime('2017-10-12')-new_merchant_df['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "    #Black Friday : 24th November 2017\n",
    "    new_merchant_df['Black_Friday_2017']=(pd.to_datetime('2017-11-24') - new_merchant_df['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "    new_merchant_df['Mothers_Day_2017']=(pd.to_datetime('2017-06-04')-new_merchant_df['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "\n",
    "    #Mothers Day: May 13 2018\n",
    "    new_merchant_df['Mothers_Day_2018']=(pd.to_datetime('2018-05-13')-new_merchant_df['purchase_date']).dt.days.apply(lambda x: x if x > 0 and x < 100 else 0)\n",
    "\n",
    "    new_merchant_df['month_diff'] = ((datetime.datetime.today() - new_merchant_df['purchase_date']).dt.days)//30\n",
    "    new_merchant_df['month_diff'] += new_merchant_df['month_lag']\n",
    "\n",
    "    # additional features\n",
    "    df_temp = new_merchant_df.groupby(['card_id','merchant_id'])['purchase_amount'].count().reset_index()\n",
    "    df_temp.rename(columns={'purchase_amount':'card_merchant_counts_totals'},inplace=True)\n",
    "    new_merchant_df = new_merchant_df.merge(df_temp,on=['card_id','merchant_id'],how='left')\n",
    "    \n",
    "    new_merchant_df['duration'] = new_merchant_df['purchase_amount']*new_merchant_df['month_diff']\n",
    "    new_merchant_df['amount_month_ratio'] = new_merchant_df['purchase_amount']/new_merchant_df['month_diff']\n",
    "    new_merchant_df['installments_month_diff'] = new_merchant_df['installments']*new_merchant_df['month_diff']\n",
    "    new_merchant_df['installments_month_diff_ratio'] = new_merchant_df['installments']/new_merchant_df['month_diff']\n",
    "    \n",
    "    new_merchant_df['duration/Visitcounts'] = new_merchant_df['duration']/new_merchant_df['card_merchant_counts_totals']\n",
    "    new_merchant_df['duration/sqrtVisits'] = new_merchant_df['duration']/np.sqrt(new_merchant_df['card_merchant_counts_totals'])\n",
    "    new_merchant_df['durations_log1p_visits'] = new_merchant_df['duration']*np.log1p(new_merchant_df['card_merchant_counts_totals'])\n",
    "   \n",
    "    new_merchant_df['purchase/Visitcounts'] = new_merchant_df['purchase_amount']/new_merchant_df['card_merchant_counts_totals']\n",
    "    new_merchant_df['purchase/sqrtVisits'] = new_merchant_df['purchase_amount']/np.sqrt(new_merchant_df['card_merchant_counts_totals'])\n",
    "    new_merchant_df['purchase_log1p_visits'] = new_merchant_df['purchase_amount']*np.log1p(new_merchant_df['card_merchant_counts_totals'])\n",
    "   \n",
    "    new_merchant_df['purchase_amount_installments'] = new_merchant_df['purchase_amount'] * new_merchant_df['installments']\n",
    "    new_merchant_df['price'] = new_merchant_df['purchase_amount'] / new_merchant_df['installments']\n",
    "    new_merchant_df['purchase_amount_authorized_flag'] = new_merchant_df['purchase_amount'] * new_merchant_df['authorized_flag']\n",
    "    new_merchant_df['purchase_amount_category_1'] = new_merchant_df['purchase_amount'] * new_merchant_df['category_1']\n",
    "    new_merchant_df['purchase_amount_category_2'] = new_merchant_df['purchase_amount'] * new_merchant_df['category_2']\n",
    "    new_merchant_df['price'] = new_merchant_df['purchase_amount'] / new_merchant_df['installments']\n",
    "\n",
    "    new_merchant_df['amount_month_ratio'] = new_merchant_df['purchase_amount']/new_merchant_df['month_diff']\n",
    "    \n",
    "    new_merchant_df['purchase_lag'] = new_merchant_df['purchase_amount']*new_merchant_df['month_lag']\n",
    "    new_merchant_df['purchase/month_lag'] = new_merchant_df['purchase_amount']/new_merchant_df['month_lag']\n",
    "    \n",
    "    new_merchant_df['installments_month_diff'] = new_merchant_df['installments']*new_merchant_df['month_diff']\n",
    "    new_merchant_df['installments_month_diff_ratio'] = new_merchant_df['installments']/new_merchant_df['month_diff']\n",
    "    \n",
    "    new_merchant_df['purchase_amount_weekend'] = new_merchant_df['purchase_amount']*new_merchant_df['weekend']\n",
    "    \n",
    "    df_temp = new_merchant_df.groupby(['card_id'])['purchase_amount'].count().reset_index()\n",
    "    df_temp.rename(columns={'purchase_amount':'card_visit_counts'},inplace=True)\n",
    "    new_merchant_df = new_merchant_df.merge(df_temp,on='card_id',how='left')\n",
    "    \n",
    "    new_merchant_df['duration/CardVisitcounts'] = new_merchant_df['duration']/new_merchant_df['card_visit_counts']\n",
    "    new_merchant_df['duration/sqrtCardVisits'] = new_merchant_df['duration']/np.sqrt(new_merchant_df['card_visit_counts'])\n",
    "    new_merchant_df['durations_log1p_Card_visits'] = new_merchant_df['duration']*np.log1p(new_merchant_df['card_visit_counts'])\n",
    "   \n",
    "    new_merchant_df['purchase/CardVisitcounts'] = new_merchant_df['purchase_amount']/new_merchant_df['card_visit_counts']\n",
    "    new_merchant_df['purchase/sqrtCardVisits'] = new_merchant_df['purchase_amount']/np.sqrt(new_merchant_df['card_visit_counts'])\n",
    "    new_merchant_df['purchase_log1p_Card_visits'] = new_merchant_df['purchase_amount']*np.log1p(new_merchant_df['card_visit_counts'])\n",
    "\n",
    "    new_merchant_df['month_diff_installments_card_merchant_counts'] =  new_merchant_df['month_diff']* new_merchant_df['installments']* new_merchant_df['card_merchant_counts_totals']\n",
    "    new_merchant_df['month_diff_installments_card_merchant_counts_ratio'] =  new_merchant_df['month_diff']*new_merchant_df['installments']/ new_merchant_df['card_merchant_counts_totals']\n",
    "    \n",
    "    new_merchant_df['month_diff_installments_card_counts'] =  new_merchant_df['month_diff']* new_merchant_df['card_visit_counts']* new_merchant_df['installments']\n",
    "    new_merchant_df['month_diff_installments_card_counts_ratio'] =  new_merchant_df['month_diff']*new_merchant_df['installments']/new_merchant_df['card_visit_counts']\n",
    "\n",
    "    \n",
    "    ##加入month_gap\n",
    "    new_merchant_df['month_gap'] = ((datetime.datetime.today() - new_merchant_df['purchase_date']).dt.days)//30\n",
    "    new_merchant_df['purchase_multi_month_gap'] = new_merchant_df['purchase_amount'] * new_merchant_df['month_gap']\n",
    "    new_merchant_df['purchase_visitcounts_ratio'] = new_merchant_df['purchase_multi_month_gap']/new_merchant_df['card_merchant_counts_totals']\n",
    "    new_merchant_df['purchase_sqrtvisits_ratio'] = new_merchant_df['purchase_multi_month_gap']/new_merchant_df['card_merchant_counts_totals']\n",
    "    new_merchant_df['purchase_log1pvisits_ratio'] = new_merchant_df['purchase_multi_month_gap']/new_merchant_df['card_merchant_counts_totals']\n",
    "    \n",
    "    new_merchant_df['purchase_card_visits_ratio'] = new_merchant_df['purchase_multi_month_gap']/new_merchant_df['card_visit_counts']\n",
    "    new_merchant_df['purchase_sqrt_card_visits_ratio']  = new_merchant_df['purchase_multi_month_gap']/new_merchant_df['card_visit_counts']\n",
    "    new_merchant_df['purchase_log1p_card_visits_ratio'] = new_merchant_df['purchase_multi_month_gap']/new_merchant_df['card_visit_counts']\n",
    "    \n",
    "    # reduce memory usage\n",
    "    new_merchant_df = reduce_mem_usage(new_merchant_df)\n",
    "\n",
    "    col_unique =['subsector_id', 'merchant_id', 'merchant_category_id']\n",
    "    col_seas = ['month', 'hour', 'weekofyear', 'weekday', 'day']\n",
    "\n",
    "    aggs = {}\n",
    "    for col in ['Christmas_Day_2017','Mothers_Day_2017','fathers_day_2017','Children_day_2017','Valentine_Day_2017','Mothers_Day_2018']:\n",
    "        new_merchant_df['purchase_amount_%s'%col] = new_merchant_df['purchase_amount'] * new_merchant_df[col]\n",
    "        aggs[col] = ['min','max','sum','mean','median']\n",
    "        \n",
    "    for col in col_unique:\n",
    "        aggs[col] = ['nunique']\n",
    "\n",
    "    for col in col_seas:\n",
    "        aggs[col] = ['nunique', 'mean', 'min', 'max']\n",
    "\n",
    "    aggs['purchase_amount'] = ['sum','max','min','mean','var','skew']\n",
    "    aggs['installments'] = ['sum','max','mean','var','skew']\n",
    "    aggs['purchase_date'] = ['max','min']\n",
    "    aggs['month_lag'] = ['max','min','mean','var','skew']\n",
    "    aggs['month_diff'] = ['mean','var','skew']\n",
    "    aggs['weekend'] = ['mean']\n",
    "    aggs['month'] = ['mean', 'min', 'max']\n",
    "    aggs['weekday'] = ['mean', 'min', 'max']\n",
    "    aggs['category_1'] = ['mean']\n",
    "    aggs['category_2'] = ['mean']\n",
    "    aggs['category_3'] = ['mean']\n",
    "    aggs['card_id'] = ['size','count']\n",
    "    aggs['price'] = ['mean','max','min','var']\n",
    "    aggs['Christmas_Day_2017'] = ['mean']\n",
    "    aggs['Children_day_2017'] = ['mean']\n",
    "    aggs['Black_Friday_2017'] = ['mean']\n",
    "    aggs['Mothers_Day_2018'] = ['mean']\n",
    "    \n",
    "    aggs['duration']=['mean','min','max']\n",
    "    aggs['amount_month_ratio']=['mean','min','max']\n",
    "    aggs['installments_month_diff'] = ['mean','min','max']\n",
    "    aggs['installments_month_diff_ratio']=['mean','min','max']\n",
    "#     aggs['purchase_exp'] = ['mean','min','max']\n",
    "    aggs['purchase_lag'] = ['mean','min','max','median']\n",
    "    aggs['purchase/month_lag'] = ['mean','min','max','median']\n",
    "    aggs['purchase_amount_weekend'] = ['mean','min','max','median']\n",
    "    \n",
    "    aggs['duration/Visitcounts'] = ['mean','sum','min','max','median']\n",
    "    aggs['durations_log1p_visits'] = ['mean','sum','min','max','median']\n",
    "    aggs['duration/sqrtVisits'] = ['mean','sum','min','max','median']\n",
    "    aggs['purchase/Visitcounts'] = ['mean','sum','min','max','median']\n",
    "    aggs['purchase_log1p_visits'] = ['mean','sum','min','max','median']\n",
    "    aggs['purchase/sqrtVisits'] = ['mean','sum','min','max','median']\n",
    "    \n",
    "    aggs['purchase_amount_installments'] = ['mean','sum','min','max','median']\n",
    "    aggs['purchase_amount_authorized_flag'] = ['mean','sum','min','max','median']\n",
    "    aggs['purchase_amount_category_1'] = ['mean','sum','min','max','median']\n",
    "    aggs['purchase_amount_category_2'] = ['mean','sum','min','max','median']\n",
    "    \n",
    "    aggs['duration/CardVisitcounts'] = ['mean','max','min','median']\n",
    "    aggs['duration/sqrtCardVisits'] = ['mean','max','min','median']\n",
    "    aggs['durations_log1p_Card_visits'] = ['mean','max','min','median']\n",
    "    \n",
    "    aggs['purchase/CardVisitcounts'] = ['mean','max','min','median']\n",
    "    aggs['purchase/sqrtCardVisits'] = ['mean','max','min','median']\n",
    "    aggs['purchase_log1p_Card_visits'] = ['mean','max','min','median'] \n",
    "    \n",
    "    aggs['month_diff_installments_card_merchant_counts'] = ['max','min','mean','median']\n",
    "    aggs['month_diff_installments_card_merchant_counts_ratio'] = ['max','min','mean','median']\n",
    "    aggs['month_diff_installments_card_counts'] = ['max','min','mean','median']\n",
    "    aggs['month_diff_installments_card_counts_ratio'] = ['max','min','mean','median']\n",
    "    \n",
    "    aggs['month_gap'] = ['mean','min','max']\n",
    "    aggs['purchase_multi_month_gap'] = ['mean','max','min','median']\n",
    "    aggs['purchase_visitcounts_ratio'] = ['mean','max','min','median']\n",
    "    aggs['purchase_sqrtvisits_ratio'] = ['mean','max','min','median']\n",
    "    aggs['purchase_log1pvisits_ratio'] = ['mean','max','min','median']\n",
    "    \n",
    "    aggs['purchase_card_visits_ratio'] = ['mean','max','min','median']\n",
    "    aggs['purchase_sqrt_card_visits_ratio'] = ['mean','max','min','median']\n",
    "    aggs['purchase_log1p_card_visits_ratio'] = ['mean','max','min','median']\n",
    "    \n",
    "    for col in cateCols:\n",
    "        aggs[col] = ['mean']\n",
    "        \n",
    "    for col in cateCols+['category_2','category_3']:\n",
    "        new_merchant_df[col+'_mean'] = new_merchant_df.groupby([col])['purchase_amount'].transform('mean')\n",
    "        new_merchant_df[col+'_min'] = new_merchant_df.groupby([col])['purchase_amount'].transform('min')\n",
    "        new_merchant_df[col+'_max'] = new_merchant_df.groupby([col])['purchase_amount'].transform('max')\n",
    "        new_merchant_df[col+'_sum'] = new_merchant_df.groupby([col])['purchase_amount'].transform('sum')\n",
    "        aggs[col+'_mean'] = ['mean']\n",
    "\n",
    "    new_merchant_df = new_merchant_df.reset_index().groupby('card_id').agg(aggs)\n",
    "\n",
    "    # change column name\n",
    "    new_merchant_df.columns = pd.Index([e[0] + \"_\" + e[1] for e in new_merchant_df.columns.tolist()])\n",
    "    new_merchant_df.columns = ['new_'+ c for c in new_merchant_df.columns]\n",
    "\n",
    "    new_merchant_df['new_purchase_date_diff'] = (new_merchant_df['new_purchase_date_max']-new_merchant_df['new_purchase_date_min']).dt.days\n",
    "    new_merchant_df['new_purchase_date_average'] = new_merchant_df['new_purchase_date_diff']/new_merchant_df['new_card_id_size']\n",
    "    new_merchant_df['new_purchase_date_uptonow'] = (datetime.datetime.today()-new_merchant_df['new_purchase_date_max']).dt.days\n",
    "    new_merchant_df['new_purchase_date_uptomin'] = (datetime.datetime.today()-new_merchant_df['new_purchase_date_min']).dt.days\n",
    "\n",
    "    # reduce memory usage\n",
    "    new_merchant_df = reduce_mem_usage(new_merchant_df)\n",
    "\n",
    "    return new_merchant_df\n",
    "\n",
    "# additional features\n",
    "def additional_features(df):\n",
    "    print('......additional........')\n",
    "    date_features=['hist_purchase_date_max','hist_purchase_date_min',\n",
    "                   'new_purchase_date_max', 'new_purchase_date_min']\n",
    "\n",
    "    for f in date_features:\n",
    "        df[f] = df[f].astype(np.int64) * 1e-9\n",
    "\n",
    "    df['card_id_total'] = df['new_card_id_size']+df['hist_card_id_size']\n",
    "    df['card_id_cnt_total'] = df['new_card_id_count']+df['hist_card_id_count']\n",
    "    df['card_id_cnt_ratio'] = df['new_card_id_count']/df['hist_card_id_count']\n",
    "    df['purchase_amount_total'] = df['new_purchase_amount_sum']+df['hist_purchase_amount_sum']\n",
    "    df['purchase_amount_mean'] = df['new_purchase_amount_mean']+df['hist_purchase_amount_mean']\n",
    "    df['purchase_amount_max'] = df['new_purchase_amount_max']+df['hist_purchase_amount_max']\n",
    "    df['purchase_amount_min'] = df['new_purchase_amount_min']+df['hist_purchase_amount_min']\n",
    "    df['purchase_amount_ratio'] = df['new_purchase_amount_sum']/df['hist_purchase_amount_sum']\n",
    "    df['month_diff_mean'] = df['new_month_diff_mean']+df['hist_month_diff_mean']\n",
    "    df['month_diff_ratio'] = df['new_month_diff_mean']/df['hist_month_diff_mean']\n",
    "    df['month_lag_mean'] = df['new_month_lag_mean']+df['hist_month_lag_mean']\n",
    "    df['month_lag_max'] = df['new_month_lag_max']+df['hist_month_lag_max']\n",
    "    df['month_lag_min'] = df['new_month_lag_min']+df['hist_month_lag_min']\n",
    "    df['category_1_mean'] = df['new_category_1_mean']+df['hist_category_1_mean']\n",
    "    df['installments_total'] = df['new_installments_sum']+df['hist_installments_sum']\n",
    "    df['installments_mean'] = df['new_installments_mean']+df['hist_installments_mean']\n",
    "    df['installments_max'] = df['new_installments_max']+df['hist_installments_max']\n",
    "    df['installments_ratio'] = df['new_installments_sum']/df['hist_installments_sum']\n",
    "    df['price_total'] = df['purchase_amount_total'] / df['installments_total']\n",
    "    df['price_mean'] = df['purchase_amount_mean'] / df['installments_mean']\n",
    "    df['price_max'] = df['purchase_amount_max'] / df['installments_max']\n",
    "    df['duration_mean'] = df['new_duration_mean']+df['hist_duration_mean']\n",
    "    df['duration_min'] = df['new_duration_min']+df['hist_duration_min']\n",
    "    df['duration_max'] = df['new_duration_max']+df['hist_duration_max']\n",
    "    df['amount_month_ratio_mean']=df['new_amount_month_ratio_mean']+df['hist_amount_month_ratio_mean']\n",
    "    df['amount_month_ratio_min']=df['new_amount_month_ratio_min']+df['hist_amount_month_ratio_min']\n",
    "    df['amount_month_ratio_max']=df['new_amount_month_ratio_max']+df['hist_amount_month_ratio_max']\n",
    "    df['new_CLV'] = df['new_card_id_count'] * df['new_purchase_amount_sum'] / df['new_month_diff_mean']\n",
    "    df['hist_CLV'] = df['hist_card_id_count'] * df['hist_purchase_amount_sum'] / df['hist_month_diff_mean']\n",
    "    df['CLV_ratio'] = df['new_CLV'] / df['hist_CLV']\n",
    "\n",
    "    return df\n",
    "df_temp = historical_transactions(num_rows=None)\n",
    "df_temp = pd.merge(df_temp,new_merchant_transactions(num_rows=None),on='card_id',how='left')\n",
    "df_temp = additional_features(df_temp)\n",
    "print('...done.....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_temp.replace([np.inf,-np.inf],-9999,inplace=True)\n",
    "df_temp.fillna(0,inplace=True)\n",
    "df_temp.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>hist_Christmas_Day_2017_mean</th>\n",
       "      <th>hist_Mothers_Day_2017_mean</th>\n",
       "      <th>hist_fathers_day_2017_mean</th>\n",
       "      <th>hist_Children_day_2017_mean</th>\n",
       "      <th>hist_Valentine_Day_2017_mean</th>\n",
       "      <th>hist_Mothers_Day_2018_mean</th>\n",
       "      <th>hist_subsector_id_nunique</th>\n",
       "      <th>hist_merchant_id_nunique</th>\n",
       "      <th>hist_merchant_category_id_nunique</th>\n",
       "      <th>...</th>\n",
       "      <th>price_max</th>\n",
       "      <th>duration_mean</th>\n",
       "      <th>duration_min</th>\n",
       "      <th>duration_max</th>\n",
       "      <th>amount_month_ratio_mean</th>\n",
       "      <th>amount_month_ratio_min</th>\n",
       "      <th>amount_month_ratio_max</th>\n",
       "      <th>new_CLV</th>\n",
       "      <th>hist_CLV</th>\n",
       "      <th>CLV_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_00007093c1</td>\n",
       "      <td>12.882812</td>\n",
       "      <td>10.445312</td>\n",
       "      <td>16.765625</td>\n",
       "      <td>15.007812</td>\n",
       "      <td>11.734375</td>\n",
       "      <td>7.468750</td>\n",
       "      <td>13</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020432</td>\n",
       "      <td>-14.351562</td>\n",
       "      <td>-17.43750</td>\n",
       "      <td>1.718750</td>\n",
       "      <td>-0.098328</td>\n",
       "      <td>-0.116699</td>\n",
       "      <td>0.011932</td>\n",
       "      <td>-0.221354</td>\n",
       "      <td>-954.671814</td>\n",
       "      <td>0.000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_0001238066</td>\n",
       "      <td>16.656250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.227661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.375000</td>\n",
       "      <td>17</td>\n",
       "      <td>65</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034485</td>\n",
       "      <td>-13.984375</td>\n",
       "      <td>-18.34375</td>\n",
       "      <td>8.281250</td>\n",
       "      <td>-0.096313</td>\n",
       "      <td>-0.122986</td>\n",
       "      <td>0.057495</td>\n",
       "      <td>-31.970246</td>\n",
       "      <td>-741.518860</td>\n",
       "      <td>0.043115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_0001506ef0</td>\n",
       "      <td>12.453125</td>\n",
       "      <td>9.273438</td>\n",
       "      <td>5.636719</td>\n",
       "      <td>5.894531</td>\n",
       "      <td>9.046875</td>\n",
       "      <td>8.164062</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084473</td>\n",
       "      <td>-15.210938</td>\n",
       "      <td>-18.34375</td>\n",
       "      <td>1.015625</td>\n",
       "      <td>-0.104492</td>\n",
       "      <td>-0.122681</td>\n",
       "      <td>0.007050</td>\n",
       "      <td>-0.241211</td>\n",
       "      <td>-192.726807</td>\n",
       "      <td>0.001252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_0001793786</td>\n",
       "      <td>8.617188</td>\n",
       "      <td>12.812500</td>\n",
       "      <td>14.437500</td>\n",
       "      <td>24.421875</td>\n",
       "      <td>14.921875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>119</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>1.599609</td>\n",
       "      <td>-7.246094</td>\n",
       "      <td>-23.75000</td>\n",
       "      <td>26.406250</td>\n",
       "      <td>-0.027985</td>\n",
       "      <td>-0.092712</td>\n",
       "      <td>0.099976</td>\n",
       "      <td>-10.088623</td>\n",
       "      <td>-815.907043</td>\n",
       "      <td>0.012365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_000183fdda</td>\n",
       "      <td>24.875000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069458</td>\n",
       "      <td>6.167969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.171875</td>\n",
       "      <td>21</td>\n",
       "      <td>73</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049469</td>\n",
       "      <td>-13.437500</td>\n",
       "      <td>-19.12500</td>\n",
       "      <td>8.312500</td>\n",
       "      <td>-0.092224</td>\n",
       "      <td>-0.126465</td>\n",
       "      <td>0.057678</td>\n",
       "      <td>-5.993863</td>\n",
       "      <td>-885.520447</td>\n",
       "      <td>0.006769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 481 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id  hist_Christmas_Day_2017_mean  hist_Mothers_Day_2017_mean  \\\n",
       "0  C_ID_00007093c1                     12.882812                   10.445312   \n",
       "1  C_ID_0001238066                     16.656250                    0.000000   \n",
       "2  C_ID_0001506ef0                     12.453125                    9.273438   \n",
       "3  C_ID_0001793786                      8.617188                   12.812500   \n",
       "4  C_ID_000183fdda                     24.875000                    0.000000   \n",
       "\n",
       "   hist_fathers_day_2017_mean  hist_Children_day_2017_mean  \\\n",
       "0                   16.765625                    15.007812   \n",
       "1                    0.000000                     0.227661   \n",
       "2                    5.636719                     5.894531   \n",
       "3                   14.437500                    24.421875   \n",
       "4                    0.069458                     6.167969   \n",
       "\n",
       "   hist_Valentine_Day_2017_mean  hist_Mothers_Day_2018_mean  \\\n",
       "0                     11.734375                    7.468750   \n",
       "1                      0.000000                   17.375000   \n",
       "2                      9.046875                    8.164062   \n",
       "3                     14.921875                    0.000000   \n",
       "4                      0.000000                   11.171875   \n",
       "\n",
       "   hist_subsector_id_nunique  hist_merchant_id_nunique  \\\n",
       "0                         13                        29   \n",
       "1                         17                        65   \n",
       "2                         12                        28   \n",
       "3                         24                       119   \n",
       "4                         21                        73   \n",
       "\n",
       "   hist_merchant_category_id_nunique    ...      price_max  duration_mean  \\\n",
       "0                                 18    ...       0.020432     -14.351562   \n",
       "1                                 29    ...       0.034485     -13.984375   \n",
       "2                                 19    ...       0.084473     -15.210938   \n",
       "3                                 48    ...       1.599609      -7.246094   \n",
       "4                                 36    ...       0.049469     -13.437500   \n",
       "\n",
       "   duration_min  duration_max  amount_month_ratio_mean  \\\n",
       "0     -17.43750      1.718750                -0.098328   \n",
       "1     -18.34375      8.281250                -0.096313   \n",
       "2     -18.34375      1.015625                -0.104492   \n",
       "3     -23.75000     26.406250                -0.027985   \n",
       "4     -19.12500      8.312500                -0.092224   \n",
       "\n",
       "   amount_month_ratio_min  amount_month_ratio_max    new_CLV    hist_CLV  \\\n",
       "0               -0.116699                0.011932  -0.221354 -954.671814   \n",
       "1               -0.122986                0.057495 -31.970246 -741.518860   \n",
       "2               -0.122681                0.007050  -0.241211 -192.726807   \n",
       "3               -0.092712                0.099976 -10.088623 -815.907043   \n",
       "4               -0.126465                0.057678  -5.993863 -885.520447   \n",
       "\n",
       "   CLV_ratio  \n",
       "0   0.000232  \n",
       "1   0.043115  \n",
       "2   0.001252  \n",
       "3   0.012365  \n",
       "4   0.006769  \n",
       "\n",
       "[5 rows x 481 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cols = [_f for _f in df_temp.columns if 'month' in _f]\n",
    "cols = ['new_purchase_amount_sum','new_purchase_amount_max','new_purchase_amount_min','new_purchase_amount_mean']\n",
    "df_temp.drop(columns=cols,inplace=True)\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 300.21 MB\n",
      "Decreased by 33.4%\n"
     ]
    }
   ],
   "source": [
    "df_temp = reduce_mem_usage(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.to_csv('./datasets/df_additional_features.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.read_csv('./datasets/df_additional_features.csv')\n",
    "\n",
    "feats = list(set(df_temp.columns) - set(['target', 'card_id', 'is_test']))\n",
    "cr = df_temp[feats].corr()\n",
    "\n",
    "interactions = []\n",
    "for col in cr.columns:\n",
    "    inter_col = cr[cr[col] == cr[col].min()].index[0]\n",
    "    interactions.append([col, inter_col])\n",
    "\n",
    "index = 1\n",
    "for inter in interactions:\n",
    "    df_temp['inter_sum_' + str(index)] = df_temp[inter[0]] + df_temp[inter[1]] \n",
    "    df_temp['inter_sub_' + str(index)] = df_temp[inter[0]] - df_temp[inter[1]] \n",
    "    df_temp['inter_mult_' + str(index)] = df_temp[inter[0]] * df_temp[inter[1]] \n",
    "    df_temp['inter_div_' + str(index)] = df_temp[inter[0]] / df_temp[inter[1]] \n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>hist_Christmas_Day_2017_mean</th>\n",
       "      <th>hist_Mothers_Day_2017_mean</th>\n",
       "      <th>hist_fathers_day_2017_mean</th>\n",
       "      <th>hist_Children_day_2017_mean</th>\n",
       "      <th>hist_Valentine_Day_2017_mean</th>\n",
       "      <th>hist_Mothers_Day_2018_mean</th>\n",
       "      <th>hist_subsector_id_nunique</th>\n",
       "      <th>hist_merchant_id_nunique</th>\n",
       "      <th>hist_merchant_category_id_nunique</th>\n",
       "      <th>...</th>\n",
       "      <th>inter_mult_306</th>\n",
       "      <th>inter_div_306</th>\n",
       "      <th>inter_sum_307</th>\n",
       "      <th>inter_sub_307</th>\n",
       "      <th>inter_mult_307</th>\n",
       "      <th>inter_div_307</th>\n",
       "      <th>inter_sum_308</th>\n",
       "      <th>inter_sub_308</th>\n",
       "      <th>inter_mult_308</th>\n",
       "      <th>inter_div_308</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_00007093c1</td>\n",
       "      <td>12.88</td>\n",
       "      <td>10.445</td>\n",
       "      <td>16.77000</td>\n",
       "      <td>15.0100</td>\n",
       "      <td>11.734</td>\n",
       "      <td>7.470</td>\n",
       "      <td>13</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.688</td>\n",
       "      <td>-0.6720</td>\n",
       "      <td>1.656</td>\n",
       "      <td>4.344</td>\n",
       "      <td>-4.032000</td>\n",
       "      <td>-2.232143</td>\n",
       "      <td>-2.852</td>\n",
       "      <td>8.848</td>\n",
       "      <td>-17.538300</td>\n",
       "      <td>-0.512479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_0001238066</td>\n",
       "      <td>16.66</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2277</td>\n",
       "      <td>0.000</td>\n",
       "      <td>17.380</td>\n",
       "      <td>17</td>\n",
       "      <td>65</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.874</td>\n",
       "      <td>-0.7185</td>\n",
       "      <td>0.872</td>\n",
       "      <td>3.746</td>\n",
       "      <td>-3.318033</td>\n",
       "      <td>-1.606820</td>\n",
       "      <td>-0.728</td>\n",
       "      <td>2.898</td>\n",
       "      <td>-1.967105</td>\n",
       "      <td>-0.598456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_0001506ef0</td>\n",
       "      <td>12.45</td>\n",
       "      <td>9.270</td>\n",
       "      <td>5.63700</td>\n",
       "      <td>5.8950</td>\n",
       "      <td>9.050</td>\n",
       "      <td>8.164</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.732</td>\n",
       "      <td>-0.7320</td>\n",
       "      <td>1.768</td>\n",
       "      <td>3.232</td>\n",
       "      <td>-1.830000</td>\n",
       "      <td>-3.415301</td>\n",
       "      <td>-1.994</td>\n",
       "      <td>7.670</td>\n",
       "      <td>-13.713216</td>\n",
       "      <td>-0.587334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_0001793786</td>\n",
       "      <td>8.62</td>\n",
       "      <td>12.810</td>\n",
       "      <td>14.44000</td>\n",
       "      <td>24.4200</td>\n",
       "      <td>14.920</td>\n",
       "      <td>0.000</td>\n",
       "      <td>24</td>\n",
       "      <td>119</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.952</td>\n",
       "      <td>-0.7380</td>\n",
       "      <td>0.007</td>\n",
       "      <td>2.959</td>\n",
       "      <td>-2.188908</td>\n",
       "      <td>-1.004743</td>\n",
       "      <td>-2.458</td>\n",
       "      <td>4.198</td>\n",
       "      <td>-2.895360</td>\n",
       "      <td>-0.261418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_000183fdda</td>\n",
       "      <td>24.88</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.06946</td>\n",
       "      <td>6.1680</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.170</td>\n",
       "      <td>21</td>\n",
       "      <td>73</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.772</td>\n",
       "      <td>-0.6930</td>\n",
       "      <td>3.977</td>\n",
       "      <td>6.749</td>\n",
       "      <td>-7.433118</td>\n",
       "      <td>-3.869408</td>\n",
       "      <td>-1.185</td>\n",
       "      <td>3.717</td>\n",
       "      <td>-3.102966</td>\n",
       "      <td>-0.516524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1541 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id  hist_Christmas_Day_2017_mean  hist_Mothers_Day_2017_mean  \\\n",
       "0  C_ID_00007093c1                         12.88                      10.445   \n",
       "1  C_ID_0001238066                         16.66                       0.000   \n",
       "2  C_ID_0001506ef0                         12.45                       9.270   \n",
       "3  C_ID_0001793786                          8.62                      12.810   \n",
       "4  C_ID_000183fdda                         24.88                       0.000   \n",
       "\n",
       "   hist_fathers_day_2017_mean  hist_Children_day_2017_mean  \\\n",
       "0                    16.77000                      15.0100   \n",
       "1                     0.00000                       0.2277   \n",
       "2                     5.63700                       5.8950   \n",
       "3                    14.44000                      24.4200   \n",
       "4                     0.06946                       6.1680   \n",
       "\n",
       "   hist_Valentine_Day_2017_mean  hist_Mothers_Day_2018_mean  \\\n",
       "0                        11.734                       7.470   \n",
       "1                         0.000                      17.380   \n",
       "2                         9.050                       8.164   \n",
       "3                        14.920                       0.000   \n",
       "4                         0.000                      11.170   \n",
       "\n",
       "   hist_subsector_id_nunique  hist_merchant_id_nunique  \\\n",
       "0                         13                        29   \n",
       "1                         17                        65   \n",
       "2                         12                        28   \n",
       "3                         24                       119   \n",
       "4                         21                        73   \n",
       "\n",
       "   hist_merchant_category_id_nunique      ...        inter_mult_306  \\\n",
       "0                                 18      ...                -2.688   \n",
       "1                                 29      ...                -2.874   \n",
       "2                                 19      ...                -0.732   \n",
       "3                                 48      ...                -2.952   \n",
       "4                                 36      ...                -2.772   \n",
       "\n",
       "   inter_div_306  inter_sum_307  inter_sub_307  inter_mult_307  inter_div_307  \\\n",
       "0        -0.6720          1.656          4.344       -4.032000      -2.232143   \n",
       "1        -0.7185          0.872          3.746       -3.318033      -1.606820   \n",
       "2        -0.7320          1.768          3.232       -1.830000      -3.415301   \n",
       "3        -0.7380          0.007          2.959       -2.188908      -1.004743   \n",
       "4        -0.6930          3.977          6.749       -7.433118      -3.869408   \n",
       "\n",
       "   inter_sum_308  inter_sub_308  inter_mult_308  inter_div_308  \n",
       "0         -2.852          8.848      -17.538300      -0.512479  \n",
       "1         -0.728          2.898       -1.967105      -0.598456  \n",
       "2         -1.994          7.670      -13.713216      -0.587334  \n",
       "3         -2.458          4.198       -2.895360      -0.261418  \n",
       "4         -1.185          3.717       -3.102966      -0.516524  \n",
       "\n",
       "[5 rows x 1541 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
