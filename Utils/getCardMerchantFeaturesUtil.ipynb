{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF,TruncatedSVD\n",
    "from sklearn.random_projection import sparse_random_matrix\n",
    "from functionUtils import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.stats import ks_2samp\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import datetime\n",
    "import gc\n",
    "DATA_PATH = './datasets/'\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建Card-MerchantCategory矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 711.26 MB\n",
      "Memory usage after optimization is: 414.90 MB\n",
      "Decreased by 41.7%\n"
     ]
    }
   ],
   "source": [
    "usecols=['card_id','merchant_category_id','purchase_amount']\n",
    "df_transactions = pd.read_csv('./datasets/df_transactions.csv',usecols=usecols)\n",
    "df_uid = pd.read_csv('./datasets/df_data.csv',usecols=['card_id'])\n",
    "df_transactions = reduce_mem_usage(df_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getCardMerCateSumFeatures(df_uid,df_feature,group='merchant_category_id',fea='purchase_amount'):\n",
    "    df_purchase = df_feature.groupby(['card_id','merchant_category_id'])['purchase_amount'].sum().reset_index()\n",
    "    df_purchase.rename(columns={'purchase_amount':'purchase_amount_sum_merchant'},inplace=True)\n",
    "    df_temp = df_purchase.pivot(index='card_id',columns=group,values='purchase_amount_sum_merchant')\n",
    "    df_temp.columns.name = None\n",
    "    cols = []\n",
    "    for col in df_temp.columns:\n",
    "        cols.append(np.str(col)+'_purcahse_sum')\n",
    "    df_temp.columns = cols\n",
    "    df_temp.reset_index(inplace=True)\n",
    "    df_uid = df_uid.merge(df_temp,on='card_id',how='left')\n",
    "    df_uid.fillna(0,inplace=True)\n",
    "    return df_uid\n",
    "def getCardMerCateCountFeatures(df_uid,df_feature,group='merchant_category_id',fea='purchase_amount',name='card-merCategory'):\n",
    "    df_purchase = df_feature.groupby(['card_id','merchant_category_id'])['purchase_amount'].count().reset_index()\n",
    "    df_purchase.rename(columns={'purchase_amount':'purchase_counts_merchant'},inplace=True)\n",
    "    df_temp = df_purchase.pivot(index='card_id',columns=group,values='purchase_counts_merchant')\n",
    "    df_temp.columns.name = None\n",
    "    cols = []\n",
    "    for col in df_temp.columns:\n",
    "        cols.append(np.str(col)+'_purchase_counts')\n",
    "    df_temp.columns = cols\n",
    "    df_temp.reset_index(inplace=True)\n",
    "    df_uid = df_uid.merge(df_temp,on='card_id',how='left')\n",
    "    df_uid.fillna(0,inplace=True)\n",
    "    return df_uid\n",
    "\n",
    "df_cardMerCateSum = getCardMerCateSumFeatures(df_uid,df_transactions)\n",
    "df_cardMerCateCount = getCardMerCateCountFeatures(df_uid,df_transactions)\n",
    "\n",
    "df_cardMerCateSum = downCast_dtype(df_cardMerCateSum)\n",
    "df_cardMerCateCount = downCast_dtype(df_cardMerCateCount)\n",
    "\n",
    "df_cardMerCateCount.replace([np.inf,-np.inf],0,inplace=True)\n",
    "df_cardMerCateSum.replace([np.inf,-np.inf],0,inplace=True)\n",
    "df_cardMerCateCount.fillna(0,inplace=True)\n",
    "df_cardMerCateSum.fillna(0,inplace=True)\n",
    "\n",
    "##### 矩阵分解SVD或者MF\n",
    "\n",
    "nmf = NMF(n_components=10,init='random',random_state=42)\n",
    "W = nmf.fit_transform(df_cardMerCateCount.iloc[0:,1:].values)\n",
    "cols = []\n",
    "for col in range(10):\n",
    "    cols.append('nmf_%s_count'%col)\n",
    "df_nmf_features = pd.DataFrame(data=W,columns=cols)\n",
    "df_nmf_features['card_id'] = df_cardMerCateCount['card_id'].values\n",
    "\n",
    "svd = TruncatedSVD(n_components=10,algorithm='randomized',n_iter=7,random_state=42)\n",
    "W = svd.fit_transform(df_cardMerCateSum.iloc[0:,1:].values)\n",
    "cols = []\n",
    "for col in range(10):\n",
    "    cols.append('svd_%s_sum'%col)\n",
    "df = pd.DataFrame(data=W,columns=cols)\n",
    "df['card_id'] = df_cardMerCateSum['card_id'].values\n",
    "\n",
    "df_nmf_features = df_nmf_features.merge(df,on='card_id',how='left')\n",
    "df_nmf_features.to_csv('./datasets/df_nmf_card_merCate_features.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建Card-City矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 711.26 MB\n",
      "Memory usage after optimization is: 414.90 MB\n",
      "Decreased by 41.7%\n"
     ]
    }
   ],
   "source": [
    "usecols=['card_id','city_id','purchase_amount']\n",
    "df_transactions = pd.read_csv('./datasets/df_transactions.csv',usecols=usecols)\n",
    "df_uid = pd.read_csv('./datasets/df_data.csv',usecols=['card_id'])\n",
    "df_transactions = reduce_mem_usage(df_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 387.45 MB\n",
      "Memory usage after optimization is: 356.41 MB\n",
      "Decreased by 8.0%\n",
      "Memory usage of dataframe is 769.94 MB\n",
      "Memory usage after optimization is: 196.21 MB\n",
      "Decreased by 74.5%\n"
     ]
    }
   ],
   "source": [
    "def getCardCitySumFeatures(df_uid,df_feature,group='city_id',fea='purchase_amount'):\n",
    "    df_purchase = df_feature.groupby(['card_id','city_id'])['purchase_amount'].sum().reset_index()\n",
    "    df_purchase.rename(columns={'purchase_amount':'purchase_amount_sum_city'},inplace=True)\n",
    "    df_temp = df_purchase.pivot(index='card_id',columns=group,values='purchase_amount_sum_city')\n",
    "    df_temp.columns.name = None\n",
    "    cols = []\n",
    "    for col in df_temp.columns:\n",
    "        cols.append(np.str(col)+'_purcahse_sum')\n",
    "    df_temp.columns = cols\n",
    "    df_temp.reset_index(inplace=True)\n",
    "    df_uid = df_uid.merge(df_temp,on='card_id',how='left')\n",
    "    df_uid.fillna(0,inplace=True)\n",
    "    return df_uid\n",
    "def getCardCityCountFeatures(df_uid,df_feature,group='city_id',fea='purchase_amount',name='card-merCategory'):\n",
    "    df_purchase = df_feature.groupby(['card_id','city_id'])['purchase_amount'].count().reset_index()\n",
    "    df_purchase.rename(columns={'purchase_amount':'purchase_counts_city'},inplace=True)\n",
    "    df_temp = df_purchase.pivot(index='card_id',columns=group,values='purchase_counts_city')\n",
    "    df_temp.columns.name = None\n",
    "    cols = []\n",
    "    for col in df_temp.columns:\n",
    "        cols.append(np.str(col)+'_purchase_counts')\n",
    "    df_temp.columns = cols\n",
    "    df_temp.reset_index(inplace=True)\n",
    "    df_uid = df_uid.merge(df_temp,on='card_id',how='left')\n",
    "    df_uid.fillna(0,inplace=True)\n",
    "    return df_uid\n",
    "df_cardCitySum = getCardCitySumFeatures(df_uid,df_transactions)\n",
    "df_cardCityCount = getCardCityCountFeatures(df_uid,df_transactions)\n",
    "df_cardCitySum = reduce_mem_usage(df_cardCitySum)\n",
    "df_cardCityCount = reduce_mem_usage(df_cardCityCount)\n",
    "\n",
    "nmf = NMF(n_components=10,init='random',random_state=42)\n",
    "W = nmf.fit_transform(df_cardCityCount.iloc[0:,1:].values)\n",
    "cols = []\n",
    "for col in range(10):\n",
    "    cols.append('nmf_city_%s_count'%col)\n",
    "df_nmf_features = pd.DataFrame(data=W,columns=cols)\n",
    "df_nmf_features['card_id'] = df_cardCityCount['card_id'].values\n",
    "\n",
    "svd = TruncatedSVD(n_components=10,algorithm='randomized',n_iter=7,random_state=42)\n",
    "W = svd.fit_transform(df_cardCitySum.iloc[0:,1:].values)\n",
    "cols = []\n",
    "for col in range(10):\n",
    "    cols.append('svd_city_%s_sum'%col)\n",
    "df = pd.DataFrame(data=W,columns=cols)\n",
    "df['card_id'] = df_cardCitySum['card_id'].values\n",
    "\n",
    "df_nmf_features = df_nmf_features.merge(df,on='card_id',how='left')\n",
    "df_nmf_features.to_csv('./datasets/df_nmf_card_city_features.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Card-Merchant 词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 948.35 MB\n",
      "Memory usage after optimization is: 651.99 MB\n",
      "Decreased by 31.2%\n"
     ]
    }
   ],
   "source": [
    "usecols=['card_id','city_id','merchant_id','purchase_amount']\n",
    "df_transactions = pd.read_csv('./datasets/df_transactions.csv',usecols=usecols)\n",
    "df_uid = pd.read_csv('./datasets/df_data.csv',usecols=['card_id'])\n",
    "df_transactions = reduce_mem_usage(df_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a79195b79969>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mdf_transactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'card_merchant'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_transactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'card_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf_transactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'merchant_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mdf_card_merchant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_transactions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'card_merchant'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'card_merchant'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mdf_card_merchant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_card_merchant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'card_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mdf_card_merchant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_mem_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_card_merchant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-a79195b79969>\u001b[0m in \u001b[0;36mgetWord2Vec\u001b[0;34m(df_fea, value, embedding_size, name)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mvec_feas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvec_feas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolsnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mdf_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_vec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf_vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    224\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                        copy=copy, sort=sort)\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    421\u001b[0m             new_data = concatenate_block_managers(\n\u001b[1;32m    422\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m                 copy=self.copy)\n\u001b[0m\u001b[1;32m    424\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m   5410\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5411\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5412\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5413\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5414\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#获取词向量\n",
    "def getWord2Vec(df_fea,value,embedding_size=10,name='cardId'):\n",
    "    def getSeq(x):\n",
    "        name = ''\n",
    "        return name.join([x for x in x.split('_')])\n",
    "    tmp_corpus = df_fea[value].map(lambda x:getSeq(x))\n",
    "    corpus = []\n",
    "    for i in range(len(tmp_corpus)):\n",
    "        words = []\n",
    "        for word in tmp_corpus[i]:\n",
    "            words.append(word)\n",
    "        corpus.append(words)\n",
    "    model = Word2Vec(corpus, size=embedding_size, window=3, min_count=1, workers=4)\n",
    "    df_vec = pd.DataFrame(data=df_fea['card_id'].astype(np.str).values,columns=['card_id'])\n",
    "    nwords = len(tmp_corpus[0])\n",
    "    seq = nwords*embedding_size\n",
    "    vec_feas = np.zeros((len(tmp_corpus),seq))\n",
    "    colsnames = []\n",
    "    for i in range(seq):\n",
    "        colsnames.append(name+np.str(i)+'_vec')\n",
    "    for i in range(len(tmp_corpus)):\n",
    "        words = []\n",
    "        for word in tmp_corpus[i]:\n",
    "            words.append(word)\n",
    "        vec_feas[i,:] = model.wv[words].reshape(1,-1)\n",
    "    df = pd.DataFrame(data=vec_feas,columns=colsnames)\n",
    "    df_vec = pd.concat([df_vec,df],axis=1)\n",
    "    return df_vec\n",
    "\n",
    "df_transactions['card_merchant'] = df_transactions['card_id'].astype(np.str) + '_' + df_transactions['merchant_id'].astype(np.str)\n",
    "df_card_merchant = getWord2Vec(df_transactions,'card_merchant',name='card_merchant')\n",
    "df_card_merchant = df_card_merchant.groupby('card_id').mean().reset_index()\n",
    "df_card_merchant = reduce_mem_usage(df_card_merchant)\n",
    "df_card_merchant.to_csv('./datasets/df_card_merchant_vec.csv',index=False)\n",
    "\n",
    "df_cardid = getWord2Vec(df_uid,'card_id')\n",
    "\n",
    "# df_cardid = df_vec.groupby('card_id').mean().reset_index()\n",
    "df_cardid = reduce_mem_usage(df_cardid)\n",
    "\n",
    "dropCols =[]\n",
    "tr_features = [f for f in df_cardid.columns if df_cardid[f].dtype!='object']\n",
    "for col in tr_features:\n",
    "    if df_cardid[col].std()<0.01:\n",
    "        dropCols.append(col)\n",
    "df_cardid.drop(columns=dropCols,inplace=True)\n",
    "df_cardid.to_csv('./datasets/df_cardid_vec.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Card-Merchant statics（强特)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1422.52 MB\n",
      "Memory usage after optimization is: 918.71 MB\n",
      "Decreased by 35.4%\n"
     ]
    }
   ],
   "source": [
    "usecols=['card_id','merchant_category_id','merchant_id','month_lag','purchase_amount','purchase_date']\n",
    "df_transactions = pd.read_csv('./datasets/df_transactions.csv',usecols=usecols)\n",
    "df_uid = pd.read_csv('./datasets/df_data.csv',usecols=['card_id'])\n",
    "df_transactions = reduce_mem_usage(df_transactions)\n",
    "df_transactions.sort_values(by=['card_id','purchase_date'],ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist_transactions = df_transactions[df_transactions.month_lag<=0]\n",
    "df_new_transactions = df_transactions[df_transactions.month_lag>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........hist.........\n",
      ".........new.........\n",
      "Memory usage of dataframe is 54.64 MB\n",
      "Memory usage after optimization is: 39.12 MB\n",
      "Decreased by 28.4%\n"
     ]
    }
   ],
   "source": [
    "for flag,df_features in zip(['hist','new'],[df_hist_transactions,df_new_transactions]):\n",
    "    print('.........%s.........'%flag)\n",
    "    df_temp = df_features.groupby(['card_id','merchant_id'])['purchase_amount'].mean().reset_index()\n",
    "    df_uid = getMaxStaticsFeatures(df_uid,df_temp,'card_id','purchase_amount',name='%s_card_merchant_mean_max'%flag)\n",
    "    df_uid = getStdStaticsFeatures(df_uid,df_temp,'card_id','purchase_amount',name='%s_card_merchant_mean_std'%flag)\n",
    "    df_uid = getMedianStaticsFeatures(df_uid,df_temp,'card_id','purchase_amount',name='%s_card_merchant_mean_median'%flag)\n",
    "    \n",
    "    df_temp = df_features.groupby(['card_id','merchant_category_id'])['purchase_amount'].mean().reset_index()\n",
    "    df_uid = getMaxStaticsFeatures(df_uid,df_temp,'card_id','purchase_amount',name='%s_card_merchant_category_mean_max'%flag)\n",
    "    df_uid = getStdStaticsFeatures(df_uid,df_temp,'card_id','purchase_amount',name='%s_card_merchant_category_mean_std'%flag)\n",
    "    df_uid = getMedianStaticsFeatures(df_uid,df_temp,'card_id','purchase_amount',name='%s_card_merchant_category__mean_median'%flag)\n",
    "    \n",
    "    df_temp = df_features.groupby(['card_id','merchant_category_id'])['purchase_amount'].std().reset_index()\n",
    "    df_uid = getMaxStaticsFeatures(df_uid,df_temp,'card_id','purchase_amount',name='%s_card_merchant_std_max'%flag)\n",
    "    df_uid = getMedianStaticsFeatures(df_uid,df_temp,'card_id','purchase_amount',name='%s_card_merchant_category__std_median'%flag)\n",
    "    #card-merchant ratio\n",
    "    df_temp = df_features.groupby(['card_id','merchant_category_id'])['purchase_amount'].max().reset_index().rename(columns={'purchase_amount':'%s_merchant_cate_purchase_max'%flag})\n",
    "    df_features = df_features.merge(df_temp,on=['card_id','merchant_category_id'],how='left')\n",
    "    df_features['%s_purchase/purchaseMax'%flag] = df_features['purchase_amount']/df_features['%s_merchant_cate_purchase_max'%flag]\n",
    "    df_uid = getMaxStaticsFeatures(df_uid,df_features,'card_id','%s_purchase/purchaseMax'%flag,name='%s_purchase/purchaseMax_max'%flag)\n",
    "    df_uid = getStdStaticsFeatures(df_uid,df_features,'card_id','%s_purchase/purchaseMax'%flag,name='%s_purchase/purchaseMax_std'%flag)\n",
    "    df_uid = getMedianStaticsFeatures(df_uid,df_features,'card_id','%s_purchase/purchaseMax'%flag,name='%s_purchase/purchaseMax_median'%flag)\n",
    "    \n",
    "    df_temp = df_features.groupby(['card_id','merchant_category_id'])['purchase_amount'].mean().reset_index().rename(columns={'purchase_amount':'%s_merchant_cate_purchase_mean'%flag})\n",
    "    df_features = df_features.merge(df_temp,on=['card_id','merchant_category_id'],how='left')\n",
    "    df_features['%s_purchase/purchaseMean'%flag] = df_features['purchase_amount']/df_features['%s_merchant_cate_purchase_mean'%flag]\n",
    "    df_uid = getMaxStaticsFeatures(df_uid,df_features,'card_id','%s_purchase/purchaseMean'%flag,name='%s_purchase/purchaseMean_max'%flag)\n",
    "    df_uid = getStdStaticsFeatures(df_uid,df_features,'card_id','%s_purchase/purchaseMean'%flag,name='%s_purchase/purchaseMean_std'%flag)\n",
    "    df_uid = getMedianStaticsFeatures(df_uid,df_features,'card_id','%s_purchase/purchaseMean'%flag,name='%s_purchase/purchaseMean_median'%flag)\n",
    "    \n",
    "    df_features['%s_purchase_merchant_shift'%flag] = df_features.groupby(['card_id','merchant_id'])['purchase_amount'].apply(lambda series:series.shift(1)).values\n",
    "    df_features['%s_purchase_merchant_shift'%flag].fillna(0,inplace=True)\n",
    "    df_features['%s_purchase_merchant_shift_ratio'%flag] = df_features['%s_purchase_merchant_shift'%flag]/df_features['purchase_amount']\n",
    "    df_temp = df_features.groupby(['card_id'])['%s_purchase_merchant_shift_ratio'%flag].max().reset_index()\n",
    "    df_uid = df_uid.merge(df_temp,on='card_id',how='left')\n",
    "    \n",
    "    df_features['%s_purchase_merchantCate_shift'%flag] = df_features.groupby(['card_id','merchant_category_id'])['purchase_amount'].apply(lambda series:series.shift(1)).values\n",
    "    df_features['%s_purchase_merchantCate_shift'%flag].fillna(0,inplace=True)\n",
    "    df_features['%s_purchase_merchantCate_shift_ratio'%flag] = df_features['%s_purchase_merchantCate_shift'%flag]/df_features['purchase_amount']\n",
    "    df_temp = df_features.groupby(['card_id'])['%s_purchase_merchantCate_shift_ratio'%flag].max().reset_index()\n",
    "    df_uid = df_uid.merge(df_temp,on='card_id',how='left')\n",
    "    #purchase_amount diff\n",
    "    df_features['%s_card_merchant_category_purchase_diff'%flag] = df_features.groupby(['card_id','merchant_category_id'])['purchase_amount'].apply(lambda series:series.diff(1)).values\n",
    "    df_features['%s_card_merchant_category_purchase_diff'%flag].fillna(0,inplace=True)\n",
    "    df_temp = df_features.groupby(['card_id'])['%s_card_merchant_category_purchase_diff'%flag].max().reset_index().rename(columns={'%s_card_merchant_category_purchase_diff'%flag:'%s_card_merchant_category_purchase_diff_max'%flag})\n",
    "    df_uid = df_uid.merge(df_temp,on='card_id',how='left')\n",
    "    df_temp = df_features.groupby(['card_id'])['%s_card_merchant_category_purchase_diff'%flag].median().reset_index().rename(columns={'%s_card_merchant_category_purchase_diff'%flag:'%s_card_merchant_category_purchase_diff_median'%flag})\n",
    "    df_uid = df_uid.merge(df_temp,on='card_id',how='left')\n",
    "    \n",
    "    df_features['%s_card_merchant_purchase_diff'%flag] = df_features.groupby(['card_id','merchant_id'])['purchase_amount'].apply(lambda series:series.diff(1)).values\n",
    "    df_features['%s_card_merchant_purchase_diff'%flag].fillna(0,inplace=True)\n",
    "    df_temp = df_features.groupby(['card_id'])['%s_card_merchant_purchase_diff'%flag].max().reset_index().rename(columns={'%s_card_smerchant_purchase_diff'%flag:'%s_card_merchant_purchase_diff_max'%flag})\n",
    "    df_uid = df_uid.merge(df_temp,on='card_id',how='left')\n",
    "    df_temp = df_features.groupby(['card_id'])['%s_card_merchant_purchase_diff'%flag].median().reset_index().rename(columns={'%s_card_merchant_purchase_diff'%flag:'%s_card_merchant_purchase_diff_median'%flag})\n",
    "    df_uid = df_uid.merge(df_temp,on='card_id',how='left')\n",
    "\n",
    "gc.collect()\n",
    "df_uid = reduce_mem_usage(df_uid)\n",
    "df_uid.fillna(0,inplace=True)\n",
    "dropCols =[]\n",
    "tr_features = [f for f in df_uid.columns if df_uid[f].dtype!='object']\n",
    "for col in tr_features:\n",
    "    if df_uid[col].std()<0.01:\n",
    "        dropCols.append(col)\n",
    "df_uid.drop(columns=dropCols,inplace=True)\n",
    "df_uid.to_csv('./datasets/df_card_merchant_statics.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Card-City statics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1659.61 MB\n",
      "Memory usage after optimization is: 740.90 MB\n",
      "Decreased by 55.4%\n"
     ]
    }
   ],
   "source": [
    "usecols=['card_id','category_2','subsector_id','state_id','month_lag','purchase_amount','purchase_date']\n",
    "df_transactions = pd.read_csv('./datasets/df_transactions.csv',usecols=usecols)\n",
    "df_uid = pd.read_csv('./datasets/df_data.csv',usecols=['card_id'])\n",
    "df_transactions = reduce_mem_usage(df_transactions)\n",
    "df_transactions.sort_values(by=['card_id','purchase_date'],ascending=True,inplace=True)\n",
    "\n",
    "df_hist_transactions = df_transactions[df_transactions.month_lag<=0]\n",
    "df_new_transactions = df_transactions[df_transactions.month_lag>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........hist.........\n",
      ".........new.........\n",
      "Memory usage of dataframe is 34.77 MB\n",
      "Memory usage after optimization is: 31.67 MB\n",
      "Decreased by 8.9%\n"
     ]
    }
   ],
   "source": [
    "for flag,df_features in zip(['hist','new'],[df_hist_transactions,df_new_transactions]):\n",
    "    print('.........%s.........'%flag)\n",
    "    df_temp = df_hist_transactions.groupby(['card_id','category_2'])['purchase_amount'].mean().reset_index().rename(columns={'purchase_amount':'%s_card_c2_mean'%flag})\n",
    "    df_features = df_features.merge(df_temp,on=['card_id','category_2'],how='left')\n",
    "    df_uid = getMaxStaticsFeatures(df_uid,df_features,'card_id','%s_card_c2_mean'%flag,'%s_card_c2_mean_max'%flag)\n",
    "    df_uid = getMedianStaticsFeatures(df_uid,df_features,'card_id','%s_card_c2_mean'%flag,'%s_card_c2_mean_median'%flag)\n",
    "\n",
    "    df_temp = df_hist_transactions.groupby(['card_id','state_id'])['purchase_amount'].mean().reset_index().rename(columns={'purchase_amount':'%s_card_state_mean'%flag})\n",
    "    df_features = df_features.merge(df_temp,on=['card_id','state_id'],how='left')\n",
    "    df_uid = getMaxStaticsFeatures(df_uid,df_features,'card_id','%s_card_state_mean'%flag,'%s_card_state_mean_max'%flag)\n",
    "    df_uid = getMedianStaticsFeatures(df_uid,df_features,'card_id','%s_card_state_mean'%flag,'%s_card_state_mean_median'%flag)\n",
    "\n",
    "    df_temp = df_hist_transactions.groupby(['card_id','subsector_id'])['purchase_amount'].mean().reset_index().rename(columns={'purchase_amount':'%s_card_subsector_mean'%flag})\n",
    "    df_features = df_features.merge(df_temp,on=['card_id','subsector_id'],how='left')\n",
    "    df_uid = getMaxStaticsFeatures(df_uid,df_features,'card_id','%s_card_subsector_mean'%flag,'%s_card_subsector_mean_max'%flag)\n",
    "    df_uid = getMedianStaticsFeatures(df_uid,df_features,'card_id','%s_card_subsector_mean'%flag,'%s_card_subsector_mean_median'%flag)\n",
    "    \n",
    "    #purchase shift比例\n",
    "    df_features['%s_purchase_c2_shift'%flag] = df_features.groupby(['card_id','category_2'])['purchase_amount'].apply(lambda series:series.shift(1)).values\n",
    "    df_features['%s_purchase_c2_shift'%flag].fillna(0,inplace=True)\n",
    "    df_features['%s_purchase_c2_shift_ratio'%flag] = df_features['%s_purchase_c2_shift'%flag]/df_features['purchase_amount']\n",
    "    df_temp = df_features.groupby(['card_id'])['%s_purchase_c2_shift_ratio'%flag].max().reset_index()\n",
    "    df_uid = df_uid.merge(df_temp,on='card_id',how='left')\n",
    "    \n",
    "    df_features['%s_purchase_subsector_shift'%flag] = df_features.groupby(['card_id','subsector_id'])['purchase_amount'].apply(lambda series:series.shift(1)).values\n",
    "    df_features['%s_purchase_subsector_shift'%flag].fillna(0,inplace=True)\n",
    "    df_features['%s_purchase_subsector_shift_ratio'%flag] = df_features['%s_purchase_subsector_shift'%flag]/df_features['purchase_amount']\n",
    "    df_temp = df_features.groupby(['card_id'])['%s_purchase_subsector_shift_ratio'%flag].max().reset_index()\n",
    "    df_uid = df_uid.merge(df_temp,on='card_id',how='left')\n",
    "    \n",
    "    df_features['%s_card_c2_purchase_diff'%flag] = df_features.groupby(['card_id','category_2'])['purchase_amount'].apply(lambda series:series.diff(1)).values\n",
    "    df_features['%s_card_c2_purchase_diff'%flag].fillna(0,inplace=True)\n",
    "    df_temp = df_features.groupby(['card_id'])['%s_card_c2_purchase_diff'%flag].max().reset_index().rename(columns={'%s_card_c2_purchase_diff'%flag:'%s_card_c2_purchase_diff_max'%flag})\n",
    "    df_uid = df_uid.merge(df_temp,on='card_id',how='left')\n",
    "    df_temp = df_features.groupby(['card_id'])['%s_card_c2_purchase_diff'%flag].median().reset_index().rename(columns={'%s_card_c2_purchase_diff'%flag:'%s_card_c2_purchase_diff_median'%flag})\n",
    "    df_uid = df_uid.merge(df_temp,on='card_id',how='left')\n",
    "    \n",
    "    df_features['%s_card_subsector_purchase_diff'%flag] = df_features.groupby(['card_id','subsector_id'])['purchase_amount'].apply(lambda series:series.diff(1)).values\n",
    "    df_features['%s_card_subsector_purchase_diff'%flag].fillna(0,inplace=True)\n",
    "    df_temp = df_features.groupby(['card_id'])['%s_card_subsector_purchase_diff'%flag].max().reset_index().rename(columns={'%s_card_subsector_purchase_diff'%flag:'%s_card_subsector_purchase_diff_max'%flag})\n",
    "    df_uid = df_uid.merge(df_temp,on='card_id',how='left')\n",
    "    df_temp = df_features.groupby(['card_id'])['%s_card_subsector_purchase_diff'%flag].median().reset_index().rename(columns={'%s_card_subsector_purchase_diff'%flag:'%s_card_subsector_purchase_diff_median'%flag})\n",
    "    df_uid = df_uid.merge(df_temp,on='card_id',how='left')\n",
    "    \n",
    "gc.collect()\n",
    "df_uid = reduce_mem_usage(df_uid)\n",
    "df_uid.fillna(0,inplace=True)\n",
    "df_uid.to_csv('./datasets/df_card_city_statics.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 持卡人对商家的访问序列进行embedding 刻画持卡人的行为向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecols = ['card_id','purchase_date','merchant_id','merchant_category_id','city_id','state_id','category_1','category_2','category_3']\n",
    "df_uid = pd.read_csv('./datasets/df_data.csv',usecols=['card_id'])\n",
    "df_transactions = pd.read_csv('./datasets/df_transactions.csv',usecols=usecols)\n",
    "df_transactions.sort_values(by=['card_id','purchase_date'],ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取词向量\n",
    "def getWord2Vec(df_temp=None,fea=None,embedding_size=10,name=None):  \n",
    "    corpus = df_temp[fea].values\n",
    "    model = Word2Vec(corpus, size=embedding_size, window=3, min_count=1, workers=16)\n",
    "    Q_VEC = np.zeros((len(corpus),embedding_size))\n",
    "    cols = []\n",
    "    for i in range(embedding_size):\n",
    "        cols.append(name+'_vec_%s'%i)\n",
    "    for i in range(df_temp.shape[0]):\n",
    "        Q_VEC[i,:] = np.mean(model.wv[corpus[i]],axis=0)\n",
    "    df_vec = pd.DataFrame(data=Q_VEC,columns=cols)\n",
    "    df_vec['card_id'] = df_temp['card_id'].values\n",
    "    return df_vec\n",
    "\n",
    "def getSequence(series):\n",
    "    return list(series.values)\n",
    "cateCols = ['merchant_id','merchant_category_id','city_id','state_id','category_1','category_2','category_3']\n",
    "for col in cateCols:\n",
    "    print('........%s........'%col)\n",
    "    df_transactions[col] = df_transactions.astype(np.str)\n",
    "    df_temp = df_transactions.groupby('card_id')[col].apply(lambda series:getSequence(series)).reset_index()\n",
    "    df_temp.rename(columns={col:'%s_sequences'%col},inplace=True)\n",
    "    df_vec = getWord2Vec(df_temp,fea='%s_sequences'%col,name='card_%s'%col)\n",
    "    df_uid = df_uid.merge(df_vec,on='card_id',how='left')\n",
    "del df_temp,df_vec\n",
    "gc.collect()\n",
    "df_uid.to_csv('./datasets/df_card_merchant_vec.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecols = ['card_id','purchase_date','authorized_flag','installments','city_C1','C2_state',\n",
    "           'C2_state_subsector','subsector_city','auth_C3','day_gap']\n",
    "df_uid = pd.read_csv('./datasets/df_data.csv',usecols=['card_id'])\n",
    "df_transactions = pd.read_csv('./datasets/df_transactions.csv',usecols=usecols)\n",
    "df_transactions.sort_values(by=['card_id','purchase_date'],ascending=True,inplace=True)\n",
    "df_uid = reduce_mem_usage(df_uid)\n",
    "df_transactions = reduce_mem_usage(df_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取词向量\n",
    "def getWord2Vec(df_temp=None,fea=None,embedding_size=10,name=None):  \n",
    "    corpus = df_temp[fea].values\n",
    "    model = Word2Vec(corpus, size=embedding_size, window=3, min_count=1, workers=16)\n",
    "    Q_VEC = np.zeros((len(corpus),embedding_size))\n",
    "    cols = []\n",
    "    for i in range(embedding_size):\n",
    "        cols.append(name+'_vec_%s'%i)\n",
    "    for i in range(df_temp.shape[0]):\n",
    "        Q_VEC[i,:] = np.mean(model.wv[corpus[i]],axis=0)\n",
    "    df_vec = pd.DataFrame(data=Q_VEC,columns=cols)\n",
    "    df_vec['card_id'] = df_temp['card_id'].values\n",
    "    return df_vec\n",
    "\n",
    "def getSequence(series):\n",
    "    return list(series.values)\n",
    "cateCols = ['authorized_flag','installments','city_C1','C2_state','C2_state_subsector',\n",
    "            'subsector_city','auth_C3','day_gap']\n",
    "for col in cateCols:\n",
    "    print('........%s........'%col)\n",
    "    df_transactions[col] = df_transactions.astype(np.str)\n",
    "    df_temp = df_transactions.groupby('card_id')[col].apply(lambda series:getSequence(series)).reset_index()\n",
    "    df_temp.rename(columns={col:'%s_sequences'%col},inplace=True)\n",
    "    df_vec = getWord2Vec(df_temp,fea='%s_sequences'%col,name='_%s'%col)\n",
    "    df_uid = df_uid.merge(df_vec,on='card_id',how='left')\n",
    "del df_temp,df_vec\n",
    "gc.collect()\n",
    "df_uid.to_csv('./datasets/df_card_merchant_vec1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./datasets/train.csv')\n",
    "df_test = pd.read_csv('./datasets/test.csv')\n",
    "df_data = pd.concat([df_train,df_test])\n",
    "\n",
    "#获取词向量\n",
    "def getWord2Vec(df_temp=None,fea=None,embedding_size=3,name=None):  \n",
    "    corpus = df_temp[fea].values\n",
    "    model = Word2Vec(corpus, size=embedding_size, window=3, min_count=1, workers=16)\n",
    "    Q_VEC = np.zeros((len(corpus),embedding_size))\n",
    "    cols = []\n",
    "    for i in range(embedding_size):\n",
    "        cols.append(name+'_vec_%s'%i)\n",
    "    for i in range(df_temp.shape[0]):\n",
    "        Q_VEC[i,:] = np.mean(model.wv[corpus[i]],axis=0)\n",
    "    df_vec = pd.DataFrame(data=Q_VEC,columns=cols)\n",
    "    df_vec['card_id'] = df_temp['card_id'].values\n",
    "    return df_vec\n",
    "\n",
    "df_data['f1%2'] = df_data['feature_1'] % 2\n",
    "df_data['f1-f3'] = df_data['f1%2'] - df_data['feature_3']\n",
    "\n",
    "df_data['f1_f2_f3'] = df_data['feature_1'].astype(np.str)+'_'+df_data['feature_2'].astype(np.str)+'_'+df_data['feature_3'].astype(np.str)\n",
    "\n",
    "df_data['f1_f2_f3'] = df_data['f1_f2_f3'].apply(lambda x:x.split('_'))\n",
    "\n",
    "df_data['f1_f2'] = df_data['feature_1'].astype(np.str)+'_'+df_data['feature_2'].astype(np.str)\n",
    "df_data['f1_f2'] = df_data['f1_f2'].apply(lambda x:x.split('_'))\n",
    "\n",
    "df_data['f1_f3'] = df_data['feature_1'].astype(np.str)+'_'+df_data['feature_3'].astype(np.str)\n",
    "df_data['f1_f3'] = df_data['f1_f3'].apply(lambda x:x.split('_'))\n",
    "\n",
    "df_data['f2_f3'] = df_data['feature_2'].astype(np.str)+'_'+df_data['feature_3'].astype(np.str)\n",
    "df_data['f2_f3'] = df_data['f2_f3'].apply(lambda x:x.split('_'))\n",
    "\n",
    "df_uid = getWord2Vec(df_data,fea='f1_f2_f3',name='feature123')\n",
    "\n",
    "df_vec = getWord2Vec(df_data,fea='f1_f2',name='feature12')\n",
    "df_uid = df_uid.merge(df_vec,on='card_id',how='left')\n",
    "\n",
    "df_vec = getWord2Vec(df_data,fea='f2_f3',name='feature23')\n",
    "df_uid = df_uid.merge(df_vec,on='card_id',how='left')\n",
    "\n",
    "df_vec = getWord2Vec(df_data,fea='f1_f3',name='feature13')\n",
    "df_uid = df_uid.merge(df_vec,on='card_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c782735ccd64fed8f075c9001f2428a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_data['f1_f2_f3'] = df_data['feature_1'].astype(np.str)+'_'+df_data['feature_2'].astype(np.str)+'_'+df_data['feature_3'].astype(np.str)\n",
    "df_data['f1_f2'] = df_data['feature_1'].astype(np.str)+'_'+df_data['feature_2'].astype(np.str)\n",
    "df_data['f1_f3'] = df_data['feature_1'].astype(np.str)+'_'+df_data['feature_3'].astype(np.str)\n",
    "df_data['f2_f3'] = df_data['feature_2'].astype(np.str)+'_'+df_data['feature_3'].astype(np.str)\n",
    "\n",
    "df_data = label_encoding(df_data,encodCols=['f1_f2_f3','f1_f2','f1_f3','f2_f3','f1%2','f1-f3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature123_vec_0</th>\n",
       "      <th>feature123_vec_1</th>\n",
       "      <th>feature123_vec_2</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature12_vec_0</th>\n",
       "      <th>feature12_vec_1</th>\n",
       "      <th>feature12_vec_2</th>\n",
       "      <th>feature23_vec_0</th>\n",
       "      <th>feature23_vec_1</th>\n",
       "      <th>feature23_vec_2</th>\n",
       "      <th>feature13_vec_0</th>\n",
       "      <th>feature13_vec_1</th>\n",
       "      <th>feature13_vec_2</th>\n",
       "      <th>f1_f2_f3</th>\n",
       "      <th>f1_f2</th>\n",
       "      <th>f1_f3</th>\n",
       "      <th>f2_f3</th>\n",
       "      <th>f1%2</th>\n",
       "      <th>f1-f3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.989753</td>\n",
       "      <td>-0.914496</td>\n",
       "      <td>-0.934446</td>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>-0.477167</td>\n",
       "      <td>0.741343</td>\n",
       "      <td>-1.473818</td>\n",
       "      <td>-1.045609</td>\n",
       "      <td>-0.028237</td>\n",
       "      <td>-1.154415</td>\n",
       "      <td>-2.019485</td>\n",
       "      <td>-0.750968</td>\n",
       "      <td>-1.655220</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.343062</td>\n",
       "      <td>-0.316953</td>\n",
       "      <td>-1.289168</td>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>-0.939326</td>\n",
       "      <td>0.132757</td>\n",
       "      <td>-0.798275</td>\n",
       "      <td>0.231106</td>\n",
       "      <td>-1.170145</td>\n",
       "      <td>-0.896125</td>\n",
       "      <td>1.439671</td>\n",
       "      <td>-1.047932</td>\n",
       "      <td>-2.180188</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.355321</td>\n",
       "      <td>-0.302104</td>\n",
       "      <td>-1.237209</td>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>-0.865829</td>\n",
       "      <td>0.642678</td>\n",
       "      <td>-0.221978</td>\n",
       "      <td>-0.249298</td>\n",
       "      <td>-0.307864</td>\n",
       "      <td>-1.578842</td>\n",
       "      <td>1.511864</td>\n",
       "      <td>-0.997176</td>\n",
       "      <td>-2.330864</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.353251</td>\n",
       "      <td>-0.659813</td>\n",
       "      <td>-1.224026</td>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>-0.946593</td>\n",
       "      <td>-0.783230</td>\n",
       "      <td>-1.319889</td>\n",
       "      <td>0.142315</td>\n",
       "      <td>-0.306830</td>\n",
       "      <td>-1.526231</td>\n",
       "      <td>1.439671</td>\n",
       "      <td>-1.047932</td>\n",
       "      <td>-2.180188</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.108154</td>\n",
       "      <td>-0.601537</td>\n",
       "      <td>-1.004480</td>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>-1.249601</td>\n",
       "      <td>-0.051592</td>\n",
       "      <td>-0.387711</td>\n",
       "      <td>0.142315</td>\n",
       "      <td>-0.306830</td>\n",
       "      <td>-1.526231</td>\n",
       "      <td>-0.224233</td>\n",
       "      <td>-0.837254</td>\n",
       "      <td>-1.736583</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature123_vec_0  feature123_vec_1  feature123_vec_2          card_id  \\\n",
       "0         -0.989753         -0.914496         -0.934446  C_ID_92a2005557   \n",
       "1          0.343062         -0.316953         -1.289168  C_ID_3d0044924f   \n",
       "2          0.355321         -0.302104         -1.237209  C_ID_d639edf6cd   \n",
       "3          0.353251         -0.659813         -1.224026  C_ID_186d6a6901   \n",
       "4         -0.108154         -0.601537         -1.004480  C_ID_cdbd2c0db2   \n",
       "\n",
       "   feature12_vec_0  feature12_vec_1  feature12_vec_2  feature23_vec_0  \\\n",
       "0        -0.477167         0.741343        -1.473818        -1.045609   \n",
       "1        -0.939326         0.132757        -0.798275         0.231106   \n",
       "2        -0.865829         0.642678        -0.221978        -0.249298   \n",
       "3        -0.946593        -0.783230        -1.319889         0.142315   \n",
       "4        -1.249601        -0.051592        -0.387711         0.142315   \n",
       "\n",
       "   feature23_vec_1  feature23_vec_2  feature13_vec_0  feature13_vec_1  \\\n",
       "0        -0.028237        -1.154415        -2.019485        -0.750968   \n",
       "1        -1.170145        -0.896125         1.439671        -1.047932   \n",
       "2        -0.307864        -1.578842         1.511864        -0.997176   \n",
       "3        -0.306830        -1.526231         1.439671        -1.047932   \n",
       "4        -0.306830        -1.526231        -0.224233        -0.837254   \n",
       "\n",
       "   feature13_vec_2  f1_f2_f3  f1_f2  f1_f3  f2_f3  f1%2  f1-f3  \n",
       "0        -1.655220        13     13      4      3     1      0  \n",
       "1        -2.180188         9      9      3      0     0      0  \n",
       "2        -2.330864         4      4      1      2     0      0  \n",
       "3        -2.180188        11     11      3      4     0      0  \n",
       "4        -1.736583         2      2      0      4     1      1  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uid = df_uid.merge(df_data[['card_id','f1_f2_f3','f1_f2','f1_f3','f2_f3','f1%2','f1-f3']],on='card_id',how='left')\n",
    "df_uid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uid.to_csv('./datasets/df_f1_f2_f3_vec.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### timseq = [15,30,45,60,100,200,300] 效果不行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usecols=['card_id','day_gap','month_lag','purchase_amount','purchase_diff','day_diff','purchase_date','category_3_A','category_3_B','category_3_C',\n",
    "#         'authorized_flag_Y','authorized_flag_N','installments']\n",
    "# df_transactions = pd.read_csv('./datasets/df_transactions.csv',usecols=usecols)\n",
    "# df_uid = pd.read_csv('./datasets/df_data.csv',usecols=['card_id'])\n",
    "# df_transactions = reduce_mem_usage(df_transactions)\n",
    "# df_transactions.sort_values(by=['card_id','purchase_date'],ascending=True,inplace=True)\n",
    "\n",
    "# df_hist_transactions = df_transactions[df_transactions.month_lag<=0]\n",
    "# df_new_transactions = df_transactions[df_transactions.month_lag>0]\n",
    "\n",
    "# for flag,df_features in zip(['hist','new'],[df_hist_transactions,df_new_transactions]):\n",
    "#     print('.........%s.........'%flag)\n",
    "#     if flag=='hist':\n",
    "#         timseq = [15,30,45,60,100,200,300]\n",
    "#     else:\n",
    "#         timeseq = [0]\n",
    "#     for day in timseq:\n",
    "#         df_fea = df_features[df_features.day_gap>(-day)]\n",
    "#         df_uid = getMeanStaticsFeatures(df_uid,df_fea,'card_id',fea='purchase_amount',name='%s_purchaseDayGap%s_mean'%(flag,day))\n",
    "#         df_uid = getMedianStaticsFeatures(df_uid,df_fea,'card_id',fea='purchase_amount',name='%s_purchaseDayGap%s_median'%(flag,day))\n",
    "#         df_uid = getSumStaticsFeatures(df_uid,df_fea,'card_id','purchase_amount',name='%s_purchaseDayGap%s_sum'%(flag,day))\n",
    "#         df_uid = getMaxStaticsFeatures(df_uid,df_fea,['card_id'],'purchase_diff',name='%s_purchaseDiffMax_%s'%(flag,day))\n",
    "#         df_uid = getSumStaticsFeatures(df_uid,df_fea,'card_id','installments',name='%s_installmentsDayGap%s_sum'%(flag,day))\n",
    "#         #day_diff\n",
    "#         df_uid = getMaxStaticsFeatures(df_uid,df_fea,['card_id'],'day_diff',name='%s_DayGapMax_%s'%(flag,day))\n",
    "#         #信用卡分期类别特征\n",
    "#         for cate in ['category_3_A','category_3_B','category_3_C']:\n",
    "#             df_uid = getSumStaticsFeatures(df_uid,df_fea,['card_id'],cate,name='%s_%s_sum_%s'%(flag,cate,day))\n",
    "#         #信用卡授权统计\n",
    "#         for cate in ['Y','N']:\n",
    "#             df_uid = getSumStaticsFeatures(df_uid,df_fea,['card_id'],'authorized_flag_%s'%cate,name='%s_authorized_flag_%s_sum_%s'%(flag,cate,day))\n",
    "# gc.collect()\n",
    "# df_uid = reduce_mem_usage(df_uid)\n",
    "# df_uid.fillna(0,inplace=True)\n",
    "# df_uid.to_csv('./datasets/df_card_purchase_statics.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### installments diff by month 效果不行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 948.35 MB\n",
      "Memory usage after optimization is: 325.99 MB\n",
      "Decreased by 65.6%\n"
     ]
    }
   ],
   "source": [
    "# usecols=['card_id','month_lag','month_gap','installments','month_gap']\n",
    "# df_transactions = pd.read_csv('./datasets/df_transactions.csv',usecols=usecols)\n",
    "# df_uid = pd.read_csv('./datasets/df_data.csv',usecols=['card_id'])\n",
    "# df_transactions = reduce_mem_usage(df_transactions)\n",
    "# df_transactions.sort_values(by=['card_id','month_gap'],ascending=True,inplace=True)\n",
    "\n",
    "# df_hist_transactions = df_transactions[df_transactions.month_lag<=0]\n",
    "# df_new_transactions = df_transactions[df_transactions.month_lag>0]\n",
    "\n",
    "# for flag,df_features in zip(['hist','new'],[df_hist_transactions,df_new_transactions]):\n",
    "#     print('.........%s.........'%flag)\n",
    "#     if flag=='hist':\n",
    "#         timseq = [1,2,3,6,12]\n",
    "#     else:\n",
    "#         timseq = [0]\n",
    "#     for day in timseq:\n",
    "#         df_fea = df_features[df_features.month_gap>(-day)]\n",
    "#         df_temp = df_fea.groupby(['card_id','month_gap'])['installments'].sum().reset_index().rename(columns={'installments':'%s_installment_sum'%flag})\n",
    "#         df_temp['%s_installments_diff'%flag] = df_temp.groupby('card_id')['%s_installment_sum'%flag].apply(lambda series:series.diff(1)).values\n",
    "#         df_temp.fillna(0,inplace=True)\n",
    "#         df_uid = getMaxStaticsFeatures(df_uid,df_temp,group='card_id',fea='%s_installments_diff'%flag,name='%s_installments_diff%s'%(flag,day))\n",
    "# gc.collect()\n",
    "# df_uid = reduce_mem_usage(df_uid)\n",
    "# df_uid.fillna(0,inplace=True)\n",
    "# df_uid.to_csv('./datasets/df_card_installMonthDiff_statics.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
