{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functionUtils import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import datetime\n",
    "import gc\n",
    "DATA_PATH = './datasets/'\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(DATA_PATH+'train.csv')\n",
    "df_test = pd.read_csv(DATA_PATH+'test.csv')\n",
    "df_historical = pd.read_csv(DATA_PATH+'historical_transactions.csv',dtype={'purchase_date':np.str},low_memory=True)\n",
    "df_new_merchant = pd.read_csv(DATA_PATH+'new_merchant_transactions.csv',dtype={'purchase_date':np.str},low_memory=True)\n",
    "\n",
    "df_train['is_test'] = 0\n",
    "df_test['is_test'] = 1\n",
    "#用户在历史和之后的记录中是否出现过\n",
    "for df in [df_train,df_test]:\n",
    "    df['is_in_new_monthlag1'] = df['card_id'].isin(df_new_merchant[df_new_merchant.month_lag==1].card_id).astype(int)\n",
    "    df['is_in_new_monthlag2'] = df['card_id'].isin(df_new_merchant[df_new_merchant.month_lag==2].card_id).astype(int)\n",
    "    df['is_in_historical'] = df['card_id'].isin(df_historical.card_id).astype(int)\n",
    "df_data = pd.concat([df_train,df_test])\n",
    "df_transactions = pd.concat([df_historical,df_new_merchant])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## id类特征\n",
    "df_temp = df_historical.card_id.value_counts().reset_index()\n",
    "df_temp.rename(columns={'index':'card_id','card_id':'hist_card_id_counts'},inplace=True)\n",
    "df_temp['hist_card_id_ratio'] = df_temp['hist_card_id_counts']/df_historical.shape[0]\n",
    "df_data = df_data.merge(df_temp,on='card_id',how='left')\n",
    "\n",
    "df_temp = df_new_merchant.card_id.value_counts().reset_index()\n",
    "df_temp.rename(columns={'index':'card_id','card_id':'new_card_id_counts'},inplace=True)\n",
    "df_temp['new_card_id_ratio'] = df_temp['new_card_id_counts']/df_new_merchant.shape[0]\n",
    "df_data = df_data.merge(df_temp,on='card_id',how='left')\n",
    "df_data['hist_new_card_id_ratio'] = df_data['hist_card_id_counts']/df_data['new_card_id_counts']\n",
    "df_data[['hist_card_id_counts','hist_card_id_ratio','new_card_id_counts','new_card_id_ratio','hist_new_card_id_ratio']].fillna(0,inplace=True)\n",
    "\n",
    "df_temp = df_historical.groupby('card_id')['purchase_amount'].count().reset_index()\n",
    "df_temp.rename(columns={'purchase_amount':'hist_purchase_records'},inplace=True)\n",
    "df_data = df_data.merge(df_temp,on='card_id',how='left')\n",
    "\n",
    "df_temp = df_new_merchant.groupby('card_id')['purchase_amount'].count().reset_index()\n",
    "df_temp.rename(columns={'purchase_amount':'new_purchase_records'},inplace=True)\n",
    "df_data = df_data.merge(df_temp,on='card_id',how='left')\n",
    "\n",
    "df_data['hist_new_purchase_radtio'] = df_data['hist_purchase_records']/df_data['new_purchase_records']\n",
    "\n",
    "del df_temp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 user features:时间特征&统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dateUtils(df=None,timeCol='purchase_date'):\n",
    "    dateHandle = pd.to_datetime(df[timeCol])\n",
    "    df['week'] = dateHandle.dt.week\n",
    "    df['year'] = dateHandle.dt.year\n",
    "    df['month_gap'] = (dateHandle.dt.date - datetime.date(2018,2,28)).dt.days//30\n",
    "    df['day_gap'] = (dateHandle.dt.date - datetime.date(2018,2,28)).dt.days\n",
    "    #cardid用户连续购买之间的时间差\n",
    "    roll = df.groupby(['card_id'])['day_gap'].apply(lambda series:series.diff(1))\n",
    "    df['day_diff'] = roll.values\n",
    "    return df\n",
    "\n",
    "dateHandle = pd.to_datetime(df_data['first_active_month'])\n",
    "df_data['active_year'] = dateHandle.dt.year\n",
    "df_data['active_month'] = dateHandle.dt.month\n",
    "df_data['active_to_base_time'] = (datetime.date(2018,4,30) - dateHandle.dt.date).dt.days\n",
    "\n",
    "#第一次购买距离注册的时间\n",
    "df_temp = df_historical.groupby('card_id')['purchase_date'].min().reset_index()\n",
    "df_temp.rename(columns={'purchase_date':'historical_first_purchase_date'},inplace=True)\n",
    "df_data = df_data.merge(df_temp,on='card_id',how='left')\n",
    "#最后一次购买时间\n",
    "df_temp = df_historical.groupby('card_id')['purchase_date'].max().reset_index()\n",
    "df_temp.rename(columns={'purchase_date':'historical_last_purchase_date'},inplace=True)\n",
    "df_data = df_data.merge(df_temp,on='card_id',how='left')\n",
    "\n",
    "df_temp = df_new_merchant.groupby('card_id')['purchase_date'].min().reset_index()\n",
    "df_temp.rename(columns={'purchase_date':'new_first_purchase_date'},inplace=True)\n",
    "df_data = df_data.merge(df_temp,on='card_id',how='left')\n",
    "#最后一次购买时间\n",
    "df_temp = df_new_merchant.groupby('card_id')['purchase_date'].max().reset_index()\n",
    "df_temp.rename(columns={'purchase_date':'new_last_purchase_date'},inplace=True)\n",
    "df_data = df_data.merge(df_temp,on='card_id',how='left')\n",
    "\n",
    "df_data['historical_first_to_base_time'] = (pd.to_datetime(df_data['historical_first_purchase_date']).dt.date -datetime.date(2018,4,30)).dt.days\n",
    "df_data['historical_last_to_base_time'] = (pd.to_datetime(df_data['historical_last_purchase_date']).dt.date -datetime.date(2018,4,30)).dt.days\n",
    "df_data['historical_last_to_first_time'] = (pd.to_datetime(df_data['historical_last_purchase_date']).dt.date - pd.to_datetime(df_data['historical_first_purchase_date']).dt.date).dt.days\n",
    "df_data['historical_first_active_time'] = (pd.to_datetime(df_data['historical_first_purchase_date']).dt.date - pd.to_datetime(df_data['first_active_month']).dt.date).dt.days\n",
    "df_data['historical_last_active_time'] = (pd.to_datetime(df_data['historical_last_purchase_date']).dt.date - pd.to_datetime(df_data['first_active_month']).dt.date).dt.days\n",
    "\n",
    "df_data['new_first_to_base_time'] = (pd.to_datetime(df_data['new_first_purchase_date']).dt.date - datetime.date(2018,4,30)).dt.days\n",
    "df_data['new_last_to_base_time'] = (pd.to_datetime(df_data['new_last_purchase_date']).dt.date - datetime.date(2018,4,30)).dt.days\n",
    "df_data['new_first_to_active_time'] = (pd.to_datetime(df_data['new_first_purchase_date']).dt.date - pd.to_datetime(df_data['first_active_month']).dt.date).dt.days\n",
    "df_data['new_last_to_active_time'] = (pd.to_datetime(df_data['new_last_purchase_date']).dt.date - pd.to_datetime(df_data['first_active_month']).dt.date).dt.days\n",
    "df_data['new_last_to_first_time'] = (pd.to_datetime(df_data['new_last_purchase_date']).dt.date - pd.to_datetime(df_data['new_first_purchase_date']).dt.date).dt.days\n",
    "\n",
    "df_data['hist_per_time_purchaseCounts'] = df_data['hist_card_id_counts']/df_data['historical_last_to_first_time']\n",
    "df_data['new_per_time_purchaseCounts'] = df_data['new_card_id_counts']/df_data['new_last_to_first_time']\n",
    "\n",
    "\n",
    "df_data.drop(columns=['historical_last_purchase_date','historical_first_purchase_date','new_first_purchase_date','new_last_purchase_date'],inplace=True)\n",
    "\n",
    "del df_train,df_test,df_historical,df_new_merchant,df_temp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#缺失值处理\n",
    "df_transactions['category_2'].fillna(1,inplace=True)\n",
    "df_transactions['category_3'].fillna('B',inplace=True)\n",
    "df_transactions['merchant_id'].fillna(df_transactions['merchant_id'].value_counts().index[0],inplace=True)\n",
    "df_transactions['installments'].replace(999,np.nan,inplace=True)\n",
    "df_transactions['installments'].fillna(df_transactions['installments'].value_counts().index[0],inplace=True)\n",
    "df_transactions['installments'].replace(-1,np.nan,inplace=True)\n",
    "df_transactions['installments'].fillna(1,inplace=True)\n",
    "#交互特征\n",
    "df_transactions['authorized_C1'] = df_transactions['authorized_flag'] + '_' + df_transactions['category_1']\n",
    "df_transactions['C1_3'] = df_transactions['category_1'].astype(np.str) + '_' + df_transactions['category_3'].astype(np.str)\n",
    "df_transactions['state_C2'] = df_transactions['state_id'].astype(np.str) + '_'  + df_transactions['category_2'].astype(np.str)\n",
    "df_transactions['state_city'] = df_transactions['city_id'] + df_transactions['state_id']\n",
    "\n",
    "for cate in ['A','B','C']:\n",
    "    df_transactions['category_3_%s'%cate] = (df_transactions['category_3']==cate) + 0\n",
    "for cate in [1,2,3,4,5]:\n",
    "    df_transactions['category_2_%s'%cate] = (df_transactions['category_2']==cate) + 0\n",
    "for cate in ['Y','N']:\n",
    "    df_transactions['authorized_flag_%s'%cate] = (df_transactions['authorized_flag']==cate) + 0\n",
    "\n",
    "df_transactions['category_1'] = df_transactions['category_1'].map({'Y':1,'N':0})\n",
    "df_transactions['category_3'] = df_transactions['category_3'].map({'A':0,'B':1,'C':2})\n",
    "df_transactions['authorized_flag'] = df_transactions['authorized_flag'].map({'Y':1,'N':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7633977b9b4b3b9452f0616ae21ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 12min 59s, sys: 1min 54s, total: 14min 53s\n",
      "Wall time: 11min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_transactions.sort_values(by=['card_id','merchant_id','purchase_date'],ascending=True,inplace=True)\n",
    "df_transactions = dateUtils(df_transactions,timeCol='purchase_date')\n",
    "df_transactions = label_encoding(df_transactions,['authorized_C1','C1_3','state_subsector_C2','C2_cityId'])\n",
    "df_transactions = downCast_dtype(df_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_historical_transactions = df_transactions[df_transactions.month_lag<=0]\n",
    "df_historical_auth_N = df_historical_transactions[df_historical_transactions.authorized_flag==0]\n",
    "df_historical_auth_Y = df_historical_transactions[df_historical_transactions.authorized_flag==1]\n",
    "df_new_transactions = df_transactions[df_transactions.month_lag>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用户月消费记录\n",
    "def getMonthPurchase(df_data,df_feature,group='month_gap',fea='purchase_amount',name='hist'):\n",
    "    df_purchase = df_feature.groupby(['card_id','month_gap'])['purchase_amount'].sum().reset_index()\n",
    "    df_purchase.rename(columns={'purchase_amount':'purchase_amount_sum_month'},inplace=True)\n",
    "    df_purchase.sort_values(by=['month_gap'],inplace=True,ascending=True)\n",
    "    df_count = df_purchase.groupby(['card_id'])['purchase_amount_sum_month'].count().reset_index()\n",
    "    df_count.rename(columns={'purchase_amount_sum_month':'%s_purchase_counts'%name},inplace=True)\n",
    "\n",
    "    df_temp = df_purchase[['card_id','month_gap','purchase_amount_sum_month']]\n",
    "    df_temp.index = df_temp.card_id\n",
    "    df_temp = df_temp.set_index(['month_gap'],append=True)\n",
    "    df_temp = pd.Series(df_temp['purchase_amount_sum_month'].values.reshape(len(df_temp['purchase_amount_sum_month'])),index=df_temp.index)\n",
    "    df_temp = df_temp.unstack()\n",
    "    df_temp.reset_index(inplace=True)\n",
    "    cols = ['card_id']\n",
    "    for index in list(df_purchase['month_gap'].unique()):\n",
    "        cols.append('%s_month%s_purchase'%(name,index))\n",
    "    df_temp.columns = cols\n",
    "    df_temp = df_temp.merge(df_count,on='card_id',how='left')\n",
    "    df_temp.fillna(0,inplace=True)\n",
    "    df_temp['%s_purchase_mean'%name] = 0\n",
    "    for index in list(df_purchase['month_gap'].unique()):\n",
    "        df_temp['%s_purchase_mean'%name] += df_temp['%s_month%s_purchase'%(name,index)]\n",
    "    if name=='new':\n",
    "        df_temp['%s_purchase_mean'%name] = (df_temp['%s_purchase_mean'%name] - df_temp['%s_month1_purchase'%name])/df_temp['%s_purchase_counts'%name]\n",
    "        df_temp['base_diff_%s_purchase'%name] = df_temp['%s_month1_purchase'%name] - df_temp['%s_purchase_mean'%name]\n",
    "    else:\n",
    "        df_temp['%s_purchase_mean'%name] = (df_temp['%s_purchase_mean'%name] - df_temp['%s_month0_purchase'%name])/df_temp['%s_purchase_counts'%name]\n",
    "        df_temp['base_diff_%s_purchase'%name] = df_temp['%s_month0_purchase'%name] - df_temp['%s_purchase_mean'%name]\n",
    "    \n",
    "    df_temp['base_diff_%s_purchaseRatio'%name] = df_temp['base_diff_%s_purchase'%name]/df_temp['%s_purchase_mean'%name]\n",
    "    df_data = df_data.merge(df_temp,on='card_id',how='left')\n",
    "    \n",
    "    del df_purchase,df_temp,cols,df_count\n",
    "    gc.collect()\n",
    "    \n",
    "    return df_data\n",
    "\n",
    "#周消费记录\n",
    "def getWeekPurchase(df_data,df_feature,group='week',fea='purchase_amount',name='hist'):\n",
    "    df_purchase = df_feature.groupby(['card_id','week'])['purchase_amount'].sum().reset_index()\n",
    "    df_purchase.rename(columns={'purchase_amount':'purchase_sum_week'},inplace=True)\n",
    "    df_purchase.sort_values(by=['week'],inplace=True,ascending=True)\n",
    "    df_count = df_purchase.groupby(['card_id'])['purchase_sum_week'].count().reset_index()\n",
    "    df_count.rename(columns={'purchase_sum_week':'%s_purchase_counts'%name},inplace=True)\n",
    "\n",
    "    df_temp = df_purchase[['card_id','week','purchase_sum_week']]\n",
    "    df_temp.index = df_temp.card_id\n",
    "    df_temp = df_temp.set_index(['week'],append=True)\n",
    "    df_temp = pd.Series(df_temp['purchase_sum_week'].values.reshape(len(df_temp['purchase_sum_week'])),index=df_temp.index)\n",
    "    df_temp = df_temp.unstack()\n",
    "    df_temp.reset_index(inplace=True)\n",
    "    cols = ['card_id']\n",
    "    for index in list(df_purchase['week'].unique()):\n",
    "        cols.append('%s_week%s_purchase'%(name,index))\n",
    "    df_temp.columns = cols\n",
    "    df_temp = df_temp.merge(df_count,on='card_id',how='left')\n",
    "    df_temp.fillna(0,inplace=True)\n",
    "    df_data = df_data.merge(df_temp,on='card_id',how='left')\n",
    "    return df_data\n",
    "\n",
    "df_data = getMonthPurchase(df_data,df_historical_auth_Y,name='AuthY')\n",
    "df_data = getMonthPurchase(df_data,df_historical_auth_N,name='AuthN')\n",
    "df_data = getMonthPurchase(df_data,df_new_transactions,name='new')\n",
    "\n",
    "df_data = getWeekPurchase(df_data,df_historical_auth_Y,name='AuthY')\n",
    "df_data = getWeekPurchase(df_data,df_historical_auth_N,name='AuthN')\n",
    "df_data = getWeekPurchase(df_data,df_new_transactions,name='new')\n",
    "\n",
    "df_data.replace([np.inf,-np.inf],np.nan,inplace=True)\n",
    "df_data.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................histAuth_Y......................\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for flag,df_features in zip(['histAuth_Y','histAuth_N','new'],[df_historical_auth_Y,df_historical_auth_N,df_new_transactions]):\n",
    "    \n",
    "    print(\".................%s......................\"%flag)\n",
    "    if 'hist'in flag:\n",
    "        month_lag = [-12,-6,-3,0]\n",
    "    else:\n",
    "        month_lag = [1,2]\n",
    "    for index in month_lag:\n",
    "        df = df_features[df_features.month_lag>=index]\n",
    "        #购买量\n",
    "        df_data = getMeanStaticsFeatures(df_data,df,['card_id'],'purchase_amount',name='%s_purchaseAmountMean_%s'%(flag,index))\n",
    "        df_data = getMaxStaticsFeatures(df_data,df,['card_id'],'purchase_amount',name='%s_purchaseAmountMax_%s'%(flag,index))\n",
    "        df_data = getMedianStaticsFeatures(df_data,df,['card_id'],'purchase_amount',name='%s_purchaseAmountMedian_%s'%(flag,index))\n",
    "        df_data = getMinStaticsFeatures(df_data,df,['card_id'],'purchase_amount',name='%s_purchaseAmountMin_%s'%(flag,index))\n",
    "        df_data = getSumStaticsFeatures(df_data,df,['card_id'],'purchase_amount',name='%s_purchaseAmountSum_%s'%(flag,index))\n",
    "        df_data = getStdStaticsFeatures(df_data,df,['card_id'],'purchase_amount',name='%s_purcahseAmountStd_%s'%(flag,index))\n",
    "        df_data = getCountsStaticsFeatures(df_data,df,['card_id'],'purchase_amount',name='%s_purcahseAmountCount_%s'%(flag,index))\n",
    "\n",
    "        #分期数\n",
    "        df_data = getMeanStaticsFeatures(df_data,df,['card_id'],'installments',name='%s_installmentsMean_%s'%(flag,index))\n",
    "        df_data = getMaxStaticsFeatures(df_data,df,['card_id'],'installments',name='%s_installmentsMax_%s'%(flag,index))\n",
    "        df_data = getSumStaticsFeatures(df_data,df,['card_id'],'installments',name='%s_installmentsSum_%s'%(flag,index))\n",
    "        df_data = getMinStaticsFeatures(df_data,df,['card_id'],'installments',name='%s_installmentsMin_%s'%(flag,index))\n",
    "        df_data = getStdStaticsFeatures(df_data,df,['card_id'],'installments',name='%s_installmentsStd_%s'%(flag,index))\n",
    "        df_data = getCountsStaticsFeatures(df_data,df,['card_id'],'installments',name='%s_installmentsCount_%s'%(flag,index))\n",
    "\n",
    "#     #month_lag\n",
    "#     df_data = getMinStaticsFeatures(df_data,df_features,['card_id'],'month_lag',name='%s_monthLagMin'%flag)\n",
    "#     df_data = getMaxStaticsFeatures(df_data,df_features,['card_id'],'month_lag',name='%s_monthLagMax'%flag)\n",
    "#     df_data = getCategoryCounts(df_data,df_features,['card_id'],'month_lag',name='%s_monthLag_categoryCounts'%flag)\n",
    "#     df_data = getCategoryCountsRatio(df_data,df_features,['card_id'],'month_lag',name='%s_monthLag_categoryCountsRatio'%flag)\n",
    "    \n",
    "    #day_diff\n",
    "    df_data = getMaxStaticsFeatures(df_data,df_features,['card_id'],'day_diff',name='%s_dayDiffMax'%flag)\n",
    "    df_data = getMinStaticsFeatures(df_data,df_features,['card_id'],'day_diff',name='%s_dayDiffMin'%flag)\n",
    "    df_data = getCategoryFrequenceMax(df_data,df_features,['card_id'],'day_diff',name='%s_dayDiffFrequenceMax'%flag)\n",
    "    df_data = getCategoryCounts(df_data,df_features,['card_id'],'day_diff',name='%s_dayDiff_categoryCounts'%flag)\n",
    "\n",
    "    #day_gap\n",
    "    df_data = getMaxStaticsFeatures(df_data,df_features,['card_id'],'day_gap',name='%s_purchaseToBaseTimeMax'%flag)\n",
    "    df_data = getMinStaticsFeatures(df_data,df_features,['card_id'],'day_gap',name='%s_purchaseToBaseTimeMin'%flag)\n",
    "    df_data = getMeanStaticsFeatures(df_data,df_features,['card_id'],'day_gap',name='%s_purchaseToBaseTimeMean'%flag)\n",
    "    #类别特征\n",
    "    for cate in ['category_3_A','category_3_B','category_3_C']:\n",
    "        df_data = getSumStaticsFeatures(df_data,df_features,['card_id'],cate,name='%s_%s_sum'%(flag,cate))\n",
    "    for cate in [1,2,3,4,5]:\n",
    "        df_data = getSumStaticsFeatures(df_data,df_features,['card_id'],'category_2_%s'%cate,name='%s_category_2_%s_sum'%(flag,cate))\n",
    "    for cate in ['Y','N']:\n",
    "        df_data = getSumStaticsFeatures(df_data,df_features,['card_id'],'authorized_flag_%s'%cate,name='%s_authorized_flag_%s_sum'%(flag,cate))\n",
    "    \n",
    "    categoryCols = ['authorized_flag','merchant_id','city_id','category_1','category_2','category_3','merchant_category_id','subsector_id',\n",
    "                    'state_subsector_C2','C1_3','C2_cityId','authorized_C1']\n",
    "\n",
    "    for fea in categoryCols:\n",
    "        df_data = getCategoryFrequenceMax(df_data,df_features,['card_id'],fea,name='%s_%s_frequenceMax'%(flag,fea))\n",
    "        df_data = getCategoryCounts(df_data,df_features,['card_id'],fea,name='%s_%s_categoryCounts'%(flag,fea))\n",
    "        df_data = getCategoryFrequenceMaxRatio(df_data,df_features,['card_id'],fea,name='%s_%s_frequenceMaxRatio'%(flag,fea))\n",
    "        df_data = getCategoryCountsRatio(df_data,df_features,['card_id'],fea,name='%s_%s_categoryCountsRatio'%(flag,fea))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存用户统计特征\n",
    "df_data.to_csv('./datasets/df_data.csv',index=False)\n",
    "df_transactions.to_csv('./datasets/df_transactions.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_data[df_data.is_test==0]\n",
    "df_test = df_data[df_data.is_test==1]\n",
    "\n",
    "df_train.to_csv('./datasets/df_train.csv',index=False)\n",
    "df_test.to_csv('./datasets/df_test.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
